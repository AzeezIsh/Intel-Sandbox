{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import array_api_strict as np\n",
    "import array_api_compat.numpy as np \n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.asarray(data.drop('label', axis=1), dtype=np.float32)\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = np.reshape(image_data, (-1, 1, image_height, image_width)) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 3 ... 0 9 4]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, size, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.asarray(np.zeros((size, num_classes)))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    # one_hot_encoding[np.arange(size), labels] = 1\n",
    "    for idx, label in enumerate(labels):\n",
    "        one_hot_encoding[idx, label] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label']\n",
    "size = len(labels)\n",
    "labels = list(labels)\n",
    "labels = np.asarray(labels)\n",
    "print(labels)\n",
    "# Labels --> one hot\n",
    "\n",
    "one_hot_encoding = labels_to_one_hot(labels, size)\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Dims of the input\n",
    "    num_images, num_channels, input_height, input_width = X.shape\n",
    "    filter_height, filter_width = conv1.shape[2], conv1.shape[3]\n",
    "\n",
    "    # Dims of the output post-filter\n",
    "    output_height = (input_height - filter_height + 2 * pad) // stride + 1\n",
    "    output_width = (input_width - filter_width + 2 * pad) // stride + 1\n",
    "\n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((num_channels * filter_height * filter_width, output_width * output_height * num_images))\n",
    "\n",
    "    col_idx = 0  # Current column in the output array\n",
    "\n",
    "    # Iterate over each image in the batch\n",
    "    for i in range(num_images):\n",
    "        # Current image\n",
    "        image = X[i, :, :, :]\n",
    "        \n",
    "        # Slide filter over the image, considering the padding\n",
    "        for y in range(-pad, input_height - filter_height + pad + 1, stride):\n",
    "            for x in range(-pad, input_width - filter_width + pad + 1, stride):\n",
    "                # Initialize a matrix to hold the unrolled filter region\n",
    "                filter_region = np.zeros((num_channels, filter_height, filter_width))\n",
    "                \n",
    "                # Calculate the start and end points on the original image\n",
    "                y_start, x_start = max(0, y), max(0, x)\n",
    "                y_end, x_end = min(input_height, y + filter_height), min(input_width, x + filter_width)\n",
    "\n",
    "                # Calculate the start and end points on the filter region\n",
    "                filter_y_start, filter_x_start = max(0, -y), max(0, -x)\n",
    "                filter_y_end, filter_x_end = filter_y_start + (y_end - y_start), filter_x_start + (x_end - x_start)\n",
    "\n",
    "                # Copy the valid parts of the image to the filter region\n",
    "                filter_region[:, filter_y_start:filter_y_end, filter_x_start:filter_x_end] = \\\n",
    "                    image[:, y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Flatten and store in im2col_vector\n",
    "                # print(np.reshape(filter_region, -1))\n",
    "                im2col_vector[:, col_idx:col_idx + 1] = np.reshape(filter_region, (-1, 1))\n",
    "                col_idx += 1\n",
    "\n",
    "    return im2col_vector\n",
    "\n",
    "# Usage\n",
    "# X is your input data array: shape (num_images, channels, height, width)\n",
    "# conv1 is your filter array: shape (num_output_channels, input_channels, filter_height, filter_width)\n",
    "# stride and pad are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col(X, conv1, stride, pad):\n",
    "#     # Pad around images to preserve size after convolution\n",
    "#     X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "#     X = X_padded\n",
    "    \n",
    "#     # Dims of the output post-filter\n",
    "#     new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "#     new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "#     # Arr for unique transformed matrix\n",
    "#     im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "#     c = 0  # Curr column in the output array\n",
    "    \n",
    "#     # Iterate over each image in the batch\n",
    "#     for position in range(X.shape[0]):\n",
    "#         # Current image\n",
    "#         image_position = X[position, :, :, :]\n",
    "        \n",
    "#         # Vertical slide down the image, with \"stride\" steps \n",
    "#         for height in range(0, image_position.shape[1], stride):\n",
    "#             # Select a horizontal slice that matches filter height\n",
    "#             image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "#             # Next iteration if slice's height < than filter height\n",
    "#             if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide down the image, with \"stride\" steps \n",
    "#             for width in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice portion that matches the filter width\n",
    "#                 image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "#                 # If portion's width < filter width\n",
    "#                 if image_square.shape[2] < conv1.shape[3]:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Flatten and store \n",
    "#                 im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "#                 c += 1\n",
    " \n",
    "#     return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "X_batch = data_array[0:10,:,:,:]\n",
    "import math\n",
    "import random\n",
    "\n",
    "conv1 = [[[[random.gauss(0, 1) for _ in range(5)]\n",
    "           for _ in range(5)]\n",
    "          for _ in range(1)]\n",
    "         for _ in range(2)]\n",
    "conv1 = np.asarray(conv1)\n",
    "X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "conv1_reshaped = np.reshape(conv1, (conv1.shape[0],-1))\n",
    "X_conv = conv1_reshaped@X_im2col\n",
    "# print(X_conv,X_batch.shape[0])\n",
    "#print(np.hsplit(X_conv,X_batch.shape[0]))\n",
    "X_conv = np.asarray(X_conv)\n",
    "X_conv = np.reshape(X_conv, (X_batch.shape[0], conv1.shape[0], 24, 24))\n",
    "print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = np.reshape(test_array[:, i:i + 1, :, :], -1)\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5760)\n",
      "(2, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "delta_conv = [[[[\n",
    "    random.random() for _ in range(24)\n",
    "] for _ in range(24)] for _ in range(2)] for _ in range(10)]\n",
    "delta_conv = np.asarray(delta_conv)\n",
    "delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "print(delta_conv_reshape.shape)\n",
    "conv1_delta = np.reshape((delta_conv_reshape@X_batch_im2col.T),(2,1,5,5))\n",
    "print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import array_api_strict as np\n",
    "import array_api_compat.numpy as np\n",
    "\n",
    "data_arr = np.zeros((10,10))\n",
    "\n",
    "slice = np.asarray([1,2])\n",
    "\n",
    "data_slice = data_arr[slice,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: array-api-compat in /home/aishaqui/NumpyExamples/.venv/lib/python3.10/site-packages (1.6)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1600 into shape (32,2,24,24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m conv1\u001b[38;5;241m.\u001b[39mreshape(conv1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n\u001b[0;32m---> 68\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m### Pass through ReLU\u001b[39;00m\n\u001b[1;32m     72\u001b[0m X_relu \u001b[38;5;241m=\u001b[39m ReLU(X_conv)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1600 into shape (32,2,24,24)"
     ]
    }
   ],
   "source": [
    "# !python -m pip install array-api-compat\n",
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = [[[[\n",
    "    random.random() for _ in range(24)\n",
    "] for _ in range(24)] for _ in range(1)] for _ in range(2)]\n",
    "conv1 = np.asarray(conv1, dtype=np.float32)\n",
    "conv1 = conv1*math.sqrt(0.2)\n",
    "W1in = [[random.random() for _ in range(288)] for _ in range(60)]\n",
    "W1in = np.asarray(W1in, dtype=np.float32)\n",
    "W1 = W1in/math.sqrt(288)\n",
    "B0 = np.zeros((60,1))/math.sqrt(288)\n",
    "W2in = [[random.random() for _ in range(60)] for _ in range(10)]\n",
    "W2in = np.asarray(W2in, dtype=np.float32)\n",
    "W2 = W2in/math.sqrt(60)\n",
    "B1 = np.zeros((10,1))/math.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    indices = list(range(data_array.shape[0]))\n",
    "    random.shuffle(indices)\n",
    "    permutation = np.asarray(indices)\n",
    "    # copy each dimension/index i into data_array_train (allocate for both onehot/data array)\n",
    "    # data_array_train = data_array[permutation,...]\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,...]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['Conv1'] = beta1 * momentums.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['Conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['Conv1'] = beta2 * velocities.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['Conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['Conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m one_hot_encoding_train[start:end,:]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m### First Convolutional Layer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m X_im2col \u001b[38;5;241m=\u001b[39m im2col(X\u001b[38;5;241m=\u001b[39mX_batch, conv1\u001b[38;5;241m=\u001b[39m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1'"
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "parameters, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=parameters['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = parameters['conv1'].reshape(parameters['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Define dictionaries for parameters and gradients\n",
    "        parameters = {'W1': W1, 'B0': B0, 'W2': W2, 'B1': B1, 'Conv1': conv1}\n",
    "        grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        parameters, velocities, momentums = update_with_adam(parameters, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters\n",
    "        W1, B0, W2, B1, conv1 = parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
