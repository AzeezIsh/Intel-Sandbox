{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import array_api_strict as np\n",
    "import array_api_compat.numpy as np \n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.asarray(data.drop('label', axis=1), dtype=np.float32)\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = np.reshape(image_data, (-1, 1, image_height, image_width)) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 5 9 ... 6 6 0]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, size, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.asarray(np.zeros((size, num_classes)))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    # one_hot_encoding[np.arange(size), labels] = 1\n",
    "    for idx, label in enumerate(labels):\n",
    "        one_hot_encoding[idx, label] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label']\n",
    "size = len(labels)\n",
    "labels = list(labels)\n",
    "labels = np.asarray(labels)\n",
    "print(labels)\n",
    "# Labels --> one hot\n",
    "\n",
    "one_hot_encoding = labels_to_one_hot(labels, size)\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Dims of the input\n",
    "    num_images, num_channels, input_height, input_width = X.shape\n",
    "    filter_height, filter_width = conv1.shape[2], conv1.shape[3]\n",
    "\n",
    "    # Dims of the output post-filter\n",
    "    output_height = (input_height - filter_height + 2 * pad) // stride + 1\n",
    "    output_width = (input_width - filter_width + 2 * pad) // stride + 1\n",
    "\n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((num_channels * filter_height * filter_width, output_width * output_height * num_images))\n",
    "\n",
    "    col_idx = 0  # Current column in the output array\n",
    "\n",
    "    # Iterate over each image in the batch\n",
    "    for i in range(num_images):\n",
    "        # Current image\n",
    "        image = X[i, :, :, :]\n",
    "        \n",
    "        # Slide filter over the image, considering the padding\n",
    "        for y in range(-pad, input_height - filter_height + pad + 1, stride):\n",
    "            for x in range(-pad, input_width - filter_width + pad + 1, stride):\n",
    "                # Initialize a matrix to hold the unrolled filter region\n",
    "                filter_region = np.zeros((num_channels, filter_height, filter_width))\n",
    "                \n",
    "                # Calculate the start and end points on the original image\n",
    "                y_start, x_start = max(0, y), max(0, x)\n",
    "                y_end, x_end = min(input_height, y + filter_height), min(input_width, x + filter_width)\n",
    "\n",
    "                # Calculate the start and end points on the filter region\n",
    "                filter_y_start, filter_x_start = max(0, -y), max(0, -x)\n",
    "                filter_y_end, filter_x_end = filter_y_start + (y_end - y_start), filter_x_start + (x_end - x_start)\n",
    "\n",
    "                # Copy the valid parts of the image to the filter region\n",
    "                filter_region[:, filter_y_start:filter_y_end, filter_x_start:filter_x_end] = \\\n",
    "                    image[:, y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Flatten and store in im2col_vector\n",
    "                # print(np.reshape(filter_region, -1))\n",
    "                im2col_vector[:, col_idx:col_idx + 1] = np.reshape(filter_region, (-1, 1))\n",
    "                col_idx += 1\n",
    "\n",
    "    return im2col_vector\n",
    "\n",
    "# Usage\n",
    "# X is your input data array: shape (num_images, channels, height, width)\n",
    "# conv1 is your filter array: shape (num_output_channels, input_channels, filter_height, filter_width)\n",
    "# stride and pad are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col(X, conv1, stride, pad):\n",
    "#     # Pad around images to preserve size after convolution\n",
    "#     X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "#     X = X_padded\n",
    "    \n",
    "#     # Dims of the output post-filter\n",
    "#     new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "#     new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "#     # Arr for unique transformed matrix\n",
    "#     im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "#     c = 0  # Curr column in the output array\n",
    "    \n",
    "#     # Iterate over each image in the batch\n",
    "#     for position in range(X.shape[0]):\n",
    "#         # Current image\n",
    "#         image_position = X[position, :, :, :]\n",
    "        \n",
    "#         # Vertical slide down the image, with \"stride\" steps \n",
    "#         for height in range(0, image_position.shape[1], stride):\n",
    "#             # Select a horizontal slice that matches filter height\n",
    "#             image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "#             # Next iteration if slice's height < than filter height\n",
    "#             if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide down the image, with \"stride\" steps \n",
    "#             for width in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice portion that matches the filter width\n",
    "#                 image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "#                 # If portion's width < filter width\n",
    "#                 if image_square.shape[2] < conv1.shape[3]:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Flatten and store \n",
    "#                 im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "#                 c += 1\n",
    " \n",
    "#     return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "X_batch = data_array[0:10,:,:,:]\n",
    "import math\n",
    "import random\n",
    "\n",
    "conv1 = [[[[random.gauss(0, 1) for _ in range(5)]\n",
    "           for _ in range(5)]\n",
    "          for _ in range(1)]\n",
    "         for _ in range(2)]\n",
    "conv1 = np.asarray(conv1)\n",
    "X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "conv1_reshaped = np.reshape(conv1, (conv1.shape[0],-1))\n",
    "X_conv = conv1_reshaped@X_im2col\n",
    "# print(X_conv,X_batch.shape[0])\n",
    "#print(np.hsplit(X_conv,X_batch.shape[0]))\n",
    "X_conv = np.asarray(X_conv)\n",
    "X_conv = np.reshape(X_conv, (X_batch.shape[0], conv1.shape[0], 24, 24))\n",
    "print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = np.reshape(test_array[:, i:i + 1, :, :], -1)\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5760)\n",
      "(2, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "delta_conv = [[[[\n",
    "    random.random() for _ in range(24)\n",
    "] for _ in range(24)] for _ in range(2)] for _ in range(10)]\n",
    "delta_conv = np.asarray(delta_conv)\n",
    "delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "print(delta_conv_reshape.shape)\n",
    "conv1_delta = np.reshape((delta_conv_reshape@X_batch_im2col.T),(2,1,5,5))\n",
    "print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import array_api_strict as np\n",
    "import array_api_compat.numpy as np\n",
    "\n",
    "data_arr = np.zeros((10,10))\n",
    "\n",
    "slice = np.asarray([1,2])\n",
    "\n",
    "data_slice = data_arr[slice,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Train Accuracy\n",
      "31.65 %\n",
      "Test Accuracy\n",
      "32.1 %\n",
      "-------------------------\n",
      "Epoch : 2\n",
      "Train Accuracy\n",
      "34.57 %\n",
      "Test Accuracy\n",
      "34.7 %\n",
      "-------------------------\n",
      "Epoch : 3\n",
      "Train Accuracy\n",
      "47.65 %\n",
      "Test Accuracy\n",
      "44.9 %\n",
      "-------------------------\n",
      "Epoch : 4\n",
      "Train Accuracy\n",
      "41.23 %\n",
      "Test Accuracy\n",
      "41.1 %\n",
      "-------------------------\n",
      "Epoch : 5\n",
      "Train Accuracy\n",
      "56.23 %\n",
      "Test Accuracy\n",
      "56.4 %\n",
      "-------------------------\n",
      "Epoch : 6\n",
      "Train Accuracy\n",
      "60.88 %\n",
      "Test Accuracy\n",
      "61.6 %\n",
      "-------------------------\n",
      "Epoch : 7\n",
      "Train Accuracy\n",
      "52.62 %\n",
      "Test Accuracy\n",
      "53.3 %\n",
      "-------------------------\n",
      "Epoch : 8\n",
      "Train Accuracy\n",
      "58.25 %\n",
      "Test Accuracy\n",
      "60.4 %\n",
      "-------------------------\n",
      "Epoch : 9\n",
      "Train Accuracy\n",
      "40.6 %\n",
      "Test Accuracy\n",
      "40.1 %\n",
      "-------------------------\n",
      "Epoch : 10\n",
      "Train Accuracy\n",
      "37.55 %\n",
      "Test Accuracy\n",
      "36.7 %\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# !python -m pip install array-api-compat\n",
    "import array_api_compat.numpy as np\n",
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = [[[[\n",
    "    random.random() for _ in range(5)\n",
    "] for _ in range(5)] for _ in range(1)] for _ in range(2)]\n",
    "conv1 = np.asarray(conv1, dtype=np.float32)\n",
    "conv1 = conv1*math.sqrt(0.2)\n",
    "W1in = [[random.random() for _ in range(288)] for _ in range(60)]\n",
    "W1in = np.asarray(W1in, dtype=np.float32)\n",
    "W1 = W1in/math.sqrt(288)\n",
    "B0 = np.zeros((60,1))/math.sqrt(288)\n",
    "W2in = [[random.random() for _ in range(60)] for _ in range(10)]\n",
    "W2in = np.asarray(W2in, dtype=np.float32)\n",
    "W2 = W2in/math.sqrt(60)\n",
    "B1 = np.zeros((10,1))/math.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    indices = list(range(data_array.shape[0]))\n",
    "    random.shuffle(indices)\n",
    "    permutation = np.asarray(indices)\n",
    "    # copy each dimension/index i into data_array_train (allocate for both onehot/data array)\n",
    "    # data_array_train = data_array[permutation,...]\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,...]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = X_conv.reshape(32, 2, 24, 24) \n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['Conv1'] = beta1 * momentums.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['Conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['Conv1'] = beta2 * velocities.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['Conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['Conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m one_hot_encoding_train[start:end,:]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m### First Convolutional Layer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m X_im2col \u001b[38;5;241m=\u001b[39m im2col(X\u001b[38;5;241m=\u001b[39mX_batch, conv1\u001b[38;5;241m=\u001b[39m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1'"
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "parameters, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=parameters['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = parameters['conv1'].reshape(parameters['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Define dictionaries for parameters and gradients\n",
    "        parameters = {'W1': W1, 'B0': B0, 'W2': W2, 'B1': B1, 'Conv1': conv1}\n",
    "        grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        parameters, velocities, momentums = update_with_adam(parameters, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters\n",
    "        W1, B0, W2, B1, conv1 = parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
