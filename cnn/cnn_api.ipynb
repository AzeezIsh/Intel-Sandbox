{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import array_api_strict as np\n",
    "#import array_api_compat.numpy as np \n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.asarray(data.drop('label', axis=1), dtype=np.float32)\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = np.reshape(image_data, (-1, 1, image_height, image_width)) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 8 ... 4 4 5]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, size, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.asarray(np.zeros((size, num_classes)))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    # one_hot_encoding[np.arange(size), labels] = 1\n",
    "    for idx, label in enumerate(labels):\n",
    "        one_hot_encoding[idx, label] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label']\n",
    "size = len(labels)\n",
    "labels = list(labels)\n",
    "labels = np.asarray(labels)\n",
    "print(labels)\n",
    "# Labels --> one hot\n",
    "\n",
    "one_hot_encoding = labels_to_one_hot(labels, size)\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa1ElEQVR4nO3dcXCU9b3v8c+GJCtosjGEZLMSaECFViC9pZLmohRLDiSdw4BwzgG1veBwYKDBW0ytDh0FtZ1Ji2eoRw/qnHtbqGdELT0CV29LR4MJV5vQIcJwOK0pSVMJQxKUO2RDkCWQ3/2D67YrifQJu/lmw/s188yQ3eeX/fr4jG8fdvPE55xzAgBgkKVYDwAAuDYRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLVeoBP6+3t1YkTJ5SRkSGfz2c9DgDAI+ecurq6FAqFlJLS/3XOkAvQiRMnVFBQYD0GAOAqtba2auzYsf0+P+QClJGRIUm6Q19XqtKMpwEAeHVBPXpHv4z+97w/CQvQli1b9NRTT6m9vV1FRUV69tlnNWPGjCuu++Sv3VKVplQfAQKApPP/7zB6pbdREvIhhFdffVWVlZXauHGj3nvvPRUVFWnevHk6efJkIl4OAJCEEhKgzZs3a+XKlbr//vv1hS98QS+88IJGjRqln/70p4l4OQBAEop7gM6fP6+GhgaVlpb++UVSUlRaWqq6urrL9o9EIgqHwzEbAGD4i3uAPvroI128eFF5eXkxj+fl5am9vf2y/auqqhQIBKIbn4ADgGuD+Q+irl+/Xp2dndGttbXVeiQAwCCI+6fgcnJyNGLECHV0dMQ83tHRoWAweNn+fr9ffr8/3mMAAIa4uF8Bpaena/r06aquro4+1tvbq+rqapWUlMT75QAASSohPwdUWVmpZcuW6ctf/rJmzJihp59+Wt3d3br//vsT8XIAgCSUkAAtWbJEH374oTZs2KD29nZ98Ytf1J49ey77YAIA4Nrlc8456yH+UjgcViAQ0Gwt4E4IAJCELrge1Wi3Ojs7lZmZ2e9+5p+CAwBcmwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATqdYDABgePvj5VM9r3r/j3xIwSfKZF/qi9QgmuAICAJggQAAAE3EP0OOPPy6fzxezTZ48Od4vAwBIcgl5D+i2227TW2+99ecXSeWtJgBArISUITU1VcFgMBHfGgAwTCTkPaCjR48qFAppwoQJuu+++3Ts2LF+941EIgqHwzEbAGD4i3uAiouLtW3bNu3Zs0fPP/+8WlpadOedd6qrq6vP/auqqhQIBKJbQUFBvEcCAAxBPuecS+QLnD59WuPHj9fmzZu1YsWKy56PRCKKRCLRr8PhsAoKCjRbC5TqS0vkaADiiJ8DGrjh9nNAF1yParRbnZ2dyszM7He/hH86ICsrS7feequampr6fN7v98vv9yd6DADAEJPwnwM6c+aMmpublZ+fn+iXAgAkkbgH6KGHHlJtba3+9Kc/6Te/+Y3uvvtujRgxQvfcc0+8XwoAkMTi/ldwx48f1z333KNTp05pzJgxuuOOO1RfX68xY8bE+6UAAEks7gF65ZVX4v0tAUjqWvIVz2va5lxMwCR9e+AL1YP2WhgeuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi4b+QDkB8dBR7X9Pyt/8j/oP04187Q57X/LcPZiVgkmQUth7ABFdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHdsAHExT+/uNDzmvH/+n78B0HS4AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUgxYB3//b96XtN9k/O8ZuKG9zyvcZGI5zVD3cR/P+d5zS0X1gzotf73kn/yvGbEAA75xVP/1/siDBtcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKXTyW95vKipJYxe1eF4zKvW85zVdI0Z4XuP9lqdDn+/dQ57XjLtu+oBe68O/GzmgdYAXXAEBAEwQIACACc8B2rdvn+bPn69QKCSfz6ddu3bFPO+c04YNG5Sfn6+RI0eqtLRUR48ejde8AIBhwnOAuru7VVRUpC1btvT5/KZNm/TMM8/ohRde0P79+3X99ddr3rx5OnfO+y/TAgAMX54/hFBeXq7y8vI+n3PO6emnn9ajjz6qBQsWSJJefPFF5eXladeuXVq6dOnVTQsAGDbi+h5QS0uL2tvbVVpaGn0sEAiouLhYdXV1fa6JRCIKh8MxGwBg+ItrgNrb2yVJeXl5MY/n5eVFn/u0qqoqBQKB6FZQUBDPkQAAQ5T5p+DWr1+vzs7O6Nba2mo9EgBgEMQ1QMFgUJLU0dER83hHR0f0uU/z+/3KzMyM2QAAw19cA1RYWKhgMKjq6uroY+FwWPv371dJSUk8XwoAkOQ8fwruzJkzampqin7d0tKiQ4cOKTs7W+PGjdO6dev0gx/8QLfccosKCwv12GOPKRQKaeHChfGcGwCQ5DwH6MCBA7rrrruiX1dWVkqSli1bpm3btunhhx9Wd3e3Vq1apdOnT+uOO+7Qnj17dN1118VvagBA0vMcoNmzZ8u5/m/16PP59OSTT+rJJ5+8qsEweA4++tygvdY//HHOoL0WgKHN/FNwAIBrEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADCRaj0AktdvIz2e1xxpz/e8Znxvk+c1AIY+roAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBQDtvSXaz2vmfzPH3leczES8bwGwNDHFRAAwAQBAgCY8Bygffv2af78+QqFQvL5fNq1a1fM88uXL5fP54vZysrK4jUvAGCY8Byg7u5uFRUVacuWLf3uU1ZWpra2tuj28ssvX9WQAIDhx/OHEMrLy1VeXv6Z+/j9fgWDwQEPBQAY/hLyHlBNTY1yc3M1adIkrVmzRqdOnep330gkonA4HLMBAIa/uAeorKxML774oqqrq/WjH/1ItbW1Ki8v18WLF/vcv6qqSoFAILoVFBTEeyQAwBAU958DWrp0afTPU6dO1bRp0zRx4kTV1NRozpw5l+2/fv16VVZWRr8Oh8NECACuAQn/GPaECROUk5OjpqamPp/3+/3KzMyM2QAAw1/CA3T8+HGdOnVK+fn5iX4pAEAS8fxXcGfOnIm5mmlpadGhQ4eUnZ2t7OxsPfHEE1q8eLGCwaCam5v18MMP6+abb9a8efPiOjgAILl5DtCBAwd01113Rb/+5P2bZcuW6fnnn9fhw4f1s5/9TKdPn1YoFNLcuXP1/e9/X36/P35TAwCSnucAzZ49W865fp//9a9/fVUDIXn4Pxzhec3FPzQnYBIAyYh7wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN64dkQnnPK/pvfO/eF6T8u5hz2vUe9H7GgCDiisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyPFgDXc9S+e1/zDTUs8r0mZ7/e8pvfsWc9rAAwuroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBQDduOIUd7X+L3fJLTL84rh6dQ/lnheM/abfxzQa01K+3hA6wAvuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1LoSweWDGjdqpvfifMkySnl+us9r+mcP9XzGv/fdXhe8/i4/+V5jSQt/M9vel6T9ccLA3otXLu4AgIAmCBAAAATngJUVVWl22+/XRkZGcrNzdXChQvV2NgYs8+5c+dUUVGh0aNH64YbbtDixYvV0eH9rw4AAMObpwDV1taqoqJC9fX1evPNN9XT06O5c+equ7s7us+DDz6o119/XTt27FBtba1OnDihRYsWxX1wAEBy8/QhhD179sR8vW3bNuXm5qqhoUGzZs1SZ2enfvKTn2j79u362te+JknaunWrPv/5z6u+vl5f+cpX4jc5ACCpXdV7QJ2dnZKk7OxsSVJDQ4N6enpUWloa3Wfy5MkaN26c6urq+vwekUhE4XA4ZgMADH8DDlBvb6/WrVunmTNnasqUKZKk9vZ2paenKysrK2bfvLw8tbe39/l9qqqqFAgEoltBQcFARwIAJJEBB6iiokJHjhzRK6+8clUDrF+/Xp2dndGttbX1qr4fACA5DOgHUdeuXas33nhD+/bt09ixY6OPB4NBnT9/XqdPn465Curo6FAwGOzze/n9fvn9/oGMAQBIYp6ugJxzWrt2rXbu3Km9e/eqsLAw5vnp06crLS1N1dXV0ccaGxt17NgxlZSUxGdiAMCw4OkKqKKiQtu3b9fu3buVkZERfV8nEAho5MiRCgQCWrFihSorK5Wdna3MzEw98MADKikp4RNwAIAYngL0/PPPS5Jmz54d8/jWrVu1fPlySdKPf/xjpaSkaPHixYpEIpo3b56ee+65uAwLABg+fM45Zz3EXwqHwwoEApqtBUr1pVmPg8/wh//5Zc9r7rztD57XnPr7DM9r3Mcfe14zUO6mXM9rZvzbf3heUzn6gOc1647P9bxGkk7+fcDzmgutxwf0Whh+Lrge1Wi3Ojs7lZmZ2e9+3AsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJgb0G1GBgXok/9ee12z+xd94XtPjBu//rTJTWzyvWZ613/OakvrVntfkPzew3zac/uF/Dmgd4AVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GigEb83/SPK9ZEfqm5zV7p233vGZUSrrnNQPVduGM5zVl7630vCZrxw2e16Turfe8RpJ6B7QK8IYrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABDcjxYDd+LM6z2u6u4s9rzn74x7Pa0Zp8G5G+scLozyvyXnW+5rU6oHdWBQYqrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSDKrrf7Hf85r7fjEzAZPYSlWD9QiAOa6AAAAmCBAAwISnAFVVVen2229XRkaGcnNztXDhQjU2NsbsM3v2bPl8vpht9erVcR0aAJD8PAWotrZWFRUVqq+v15tvvqmenh7NnTtX3d3dMfutXLlSbW1t0W3Tpk1xHRoAkPw8fQhhz549MV9v27ZNubm5amho0KxZs6KPjxo1SsFgMD4TAgCGpat6D6izs1OSlJ2dHfP4Sy+9pJycHE2ZMkXr16/X2bNn+/0ekUhE4XA4ZgMADH8D/hh2b2+v1q1bp5kzZ2rKlCnRx++9916NHz9eoVBIhw8f1iOPPKLGxka99tprfX6fqqoqPfHEEwMdAwCQpHzOOTeQhWvWrNGvfvUrvfPOOxo7dmy/++3du1dz5sxRU1OTJk6ceNnzkUhEkUgk+nU4HFZBQYFma4FSfWkDGQ0AYOiC61GNdquzs1OZmZn97jegK6C1a9fqjTfe0L59+z4zPpJUXFwsSf0GyO/3y+/3D2QMAEAS8xQg55weeOAB7dy5UzU1NSosLLzimkOHDkmS8vPzBzQgAGB48hSgiooKbd++Xbt371ZGRoba29slSYFAQCNHjlRzc7O2b9+ur3/96xo9erQOHz6sBx98ULNmzdK0adMS8g8AAEhOnt4D8vl8fT6+detWLV++XK2trfrGN76hI0eOqLu7WwUFBbr77rv16KOPfubfA/6lcDisQCDAe0AAkKQS8h7QlVpVUFCg2tpaL98SAHCN4l5wAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATqdYDfJpzTpJ0QT2SMx4GAODZBfVI+vN/z/sz5ALU1dUlSXpHvzSeBABwNbq6uhQIBPp93ueulKhB1tvbqxMnTigjI0M+ny/muXA4rIKCArW2tiozM9NoQnsch0s4DpdwHC7hOFwyFI6Dc05dXV0KhUJKSen/nZ4hdwWUkpKisWPHfuY+mZmZ1/QJ9gmOwyUch0s4DpdwHC6xPg6fdeXzCT6EAAAwQYAAACaSKkB+v18bN26U3++3HsUUx+ESjsMlHIdLOA6XJNNxGHIfQgAAXBuS6goIADB8ECAAgAkCBAAwQYAAACaSJkBbtmzR5z73OV133XUqLi7Wb3/7W+uRBt3jjz8un88Xs02ePNl6rITbt2+f5s+fr1AoJJ/Pp127dsU875zThg0blJ+fr5EjR6q0tFRHjx61GTaBrnQcli9fftn5UVZWZjNsglRVVen2229XRkaGcnNztXDhQjU2Nsbsc+7cOVVUVGj06NG64YYbtHjxYnV0dBhNnBh/zXGYPXv2ZefD6tWrjSbuW1IE6NVXX1VlZaU2btyo9957T0VFRZo3b55OnjxpPdqgu+2229TW1hbd3nnnHeuREq67u1tFRUXasmVLn89v2rRJzzzzjF544QXt379f119/vebNm6dz584N8qSJdaXjIEllZWUx58fLL788iBMmXm1trSoqKlRfX68333xTPT09mjt3rrq7u6P7PPjgg3r99de1Y8cO1dbW6sSJE1q0aJHh1PH31xwHSVq5cmXM+bBp0yajifvhksCMGTNcRUVF9OuLFy+6UCjkqqqqDKcafBs3bnRFRUXWY5iS5Hbu3Bn9ure31wWDQffUU09FHzt9+rTz+/3u5ZdfNphwcHz6ODjn3LJly9yCBQtM5rFy8uRJJ8nV1tY65y79u09LS3M7duyI7vP73//eSXJ1dXVWYybcp4+Dc8599atfdd/+9rfthvorDPkroPPnz6uhoUGlpaXRx1JSUlRaWqq6ujrDyWwcPXpUoVBIEyZM0H333adjx45Zj2SqpaVF7e3tMedHIBBQcXHxNXl+1NTUKDc3V5MmTdKaNWt06tQp65ESqrOzU5KUnZ0tSWpoaFBPT0/M+TB58mSNGzduWJ8Pnz4On3jppZeUk5OjKVOmaP369Tp79qzFeP0acjcj/bSPPvpIFy9eVF5eXszjeXl5ev/9942mslFcXKxt27Zp0qRJamtr0xNPPKE777xTR44cUUZGhvV4Jtrb2yWpz/Pjk+euFWVlZVq0aJEKCwvV3Nys733veyovL1ddXZ1GjBhhPV7c9fb2at26dZo5c6amTJki6dL5kJ6erqysrJh9h/P50NdxkKR7771X48ePVygU0uHDh/XII4+osbFRr732muG0sYZ8gPBn5eXl0T9PmzZNxcXFGj9+vH7+859rxYoVhpNhKFi6dGn0z1OnTtW0adM0ceJE1dTUaM6cOYaTJUZFRYWOHDlyTbwP+ln6Ow6rVq2K/nnq1KnKz8/XnDlz1NzcrIkTJw72mH0a8n8Fl5OToxEjRlz2KZaOjg4Fg0GjqYaGrKws3XrrrWpqarIexcwn5wDnx+UmTJignJycYXl+rF27Vm+88YbefvvtmF/fEgwGdf78eZ0+fTpm/+F6PvR3HPpSXFwsSUPqfBjyAUpPT9f06dNVXV0dfay3t1fV1dUqKSkxnMzemTNn1NzcrPz8fOtRzBQWFioYDMacH+FwWPv377/mz4/jx4/r1KlTw+r8cM5p7dq12rlzp/bu3avCwsKY56dPn660tLSY86GxsVHHjh0bVufDlY5DXw4dOiRJQ+t8sP4UxF/jlVdecX6/323bts397ne/c6tWrXJZWVmuvb3derRB9Z3vfMfV1NS4lpYW9+6777rS0lKXk5PjTp48aT1aQnV1dbmDBw+6gwcPOklu8+bN7uDBg+6DDz5wzjn3wx/+0GVlZbndu3e7w4cPuwULFrjCwkL38ccfG08eX591HLq6utxDDz3k6urqXEtLi3vrrbfcl770JXfLLbe4c+fOWY8eN2vWrHGBQMDV1NS4tra26Hb27NnoPqtXr3bjxo1ze/fudQcOHHAlJSWupKTEcOr4u9JxaGpqck8++aQ7cOCAa2lpcbt373YTJkxws2bNMp48VlIEyDnnnn32WTdu3DiXnp7uZsyY4err661HGnRLlixx+fn5Lj093d10001uyZIlrqmpyXqshHv77bedpMu2ZcuWOecufRT7sccec3l5ec7v97s5c+a4xsZG26ET4LOOw9mzZ93cuXPdmDFjXFpamhs/frxbuXLlsPuftL7++SW5rVu3Rvf5+OOP3be+9S134403ulGjRrm7777btbW12Q2dAFc6DseOHXOzZs1y2dnZzu/3u5tvvtl997vfdZ2dnbaDfwq/jgEAYGLIvwcEABieCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT/w9P2HYcqY/HcwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Dims of the input\n",
    "    num_images, num_channels, input_height, input_width = X.shape\n",
    "    filter_height, filter_width = conv1.shape[2], conv1.shape[3]\n",
    "\n",
    "    # Dims of the output post-filter\n",
    "    output_height = (input_height - filter_height + 2 * pad) // stride + 1\n",
    "    output_width = (input_width - filter_width + 2 * pad) // stride + 1\n",
    "\n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((num_channels * filter_height * filter_width, output_width * output_height * num_images))\n",
    "\n",
    "    col_idx = 0  # Current column in the output array\n",
    "\n",
    "    # Iterate over each image in the batch\n",
    "    for i in range(num_images):\n",
    "        # Current image\n",
    "        image = X[i, :, :, :]\n",
    "        \n",
    "        # Slide filter over the image, considering the padding\n",
    "        for y in range(-pad, input_height - filter_height + pad + 1, stride):\n",
    "            for x in range(-pad, input_width - filter_width + pad + 1, stride):\n",
    "                # Initialize a matrix to hold the unrolled filter region\n",
    "                filter_region = np.zeros((num_channels, filter_height, filter_width))\n",
    "                \n",
    "                # Calculate the start and end points on the original image\n",
    "                y_start, x_start = max(0, y), max(0, x)\n",
    "                y_end, x_end = min(input_height, y + filter_height), min(input_width, x + filter_width)\n",
    "\n",
    "                # Calculate the start and end points on the filter region\n",
    "                filter_y_start, filter_x_start = max(0, -y), max(0, -x)\n",
    "                filter_y_end, filter_x_end = filter_y_start + (y_end - y_start), filter_x_start + (x_end - x_start)\n",
    "\n",
    "                # Copy the valid parts of the image to the filter region\n",
    "                filter_region[:, filter_y_start:filter_y_end, filter_x_start:filter_x_end] = \\\n",
    "                    image[:, y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Flatten and store in im2col_vector\n",
    "                # print(np.reshape(filter_region, -1))\n",
    "                im2col_vector[:, col_idx:col_idx + 1] = np.reshape(filter_region, (-1, 1))\n",
    "                col_idx += 1\n",
    "\n",
    "    return im2col_vector\n",
    "\n",
    "# Usage\n",
    "# X is your input data array: shape (num_images, channels, height, width)\n",
    "# conv1 is your filter array: shape (num_output_channels, input_channels, filter_height, filter_width)\n",
    "# stride and pad are integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def im2col(X, conv1, stride, pad):\n",
    "#     # Pad around images to preserve size after convolution\n",
    "#     X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "#     X = X_padded\n",
    "    \n",
    "#     # Dims of the output post-filter\n",
    "#     new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "#     new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "#     # Arr for unique transformed matrix\n",
    "#     im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "#     c = 0  # Curr column in the output array\n",
    "    \n",
    "#     # Iterate over each image in the batch\n",
    "#     for position in range(X.shape[0]):\n",
    "#         # Current image\n",
    "#         image_position = X[position, :, :, :]\n",
    "        \n",
    "#         # Vertical slide down the image, with \"stride\" steps \n",
    "#         for height in range(0, image_position.shape[1], stride):\n",
    "#             # Select a horizontal slice that matches filter height\n",
    "#             image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "#             # Next iteration if slice's height < than filter height\n",
    "#             if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide down the image, with \"stride\" steps \n",
    "#             for width in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice portion that matches the filter width\n",
    "#                 image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "#                 # If portion's width < filter width\n",
    "#                 if image_square.shape[2] < conv1.shape[3]:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Flatten and store \n",
    "#                 im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "#                 c += 1\n",
    " \n",
    "#     return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "X_batch = data_array[0:10,:,:,:]\n",
    "import math\n",
    "import random\n",
    "\n",
    "conv1 = [[[[random.gauss(0, 1) for _ in range(5)]\n",
    "           for _ in range(5)]\n",
    "          for _ in range(1)]\n",
    "         for _ in range(2)]\n",
    "conv1 = np.asarray(conv1)\n",
    "X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "conv1_reshaped = np.reshape(conv1, (conv1.shape[0],-1))\n",
    "X_conv = conv1_reshaped@X_im2col\n",
    "# print(X_conv,X_batch.shape[0])\n",
    "#print(np.hsplit(X_conv,X_batch.shape[0]))\n",
    "X_conv = np.asarray(X_conv)\n",
    "X_conv = np.reshape(X_conv, (X_batch.shape[0], conv1.shape[0], 24, 24))\n",
    "print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = np.reshape(test_array[:, i:i + 1, :, :], -1)\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5760)\n",
      "(2, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "delta_conv = [[[[\n",
    "    random.random() for _ in range(24)\n",
    "] for _ in range(24)] for _ in range(2)] for _ in range(10)]\n",
    "delta_conv = np.asarray(delta_conv)\n",
    "delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "print(delta_conv_reshape.shape)\n",
    "conv1_delta = np.reshape((delta_conv_reshape@X_batch_im2col.T),(2,1,5,5))\n",
    "print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Single-axes index [1 2] is a non-zero-dimensional integer array, but advanced integer indexing is not specified in the Array API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m data_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m data_slice \u001b[38;5;241m=\u001b[39m \u001b[43mdata_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/array_api_strict/_array_object.py:588\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03mPerforms the operation __getitem__.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Note: Only indices required by the spec are allowed. See the\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# docstring of _validate_index\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Array):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;66;03m# Indexing self._array with array_api_strict arrays can be erroneous\u001b[39;00m\n\u001b[1;32m    591\u001b[0m     key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39m_array\n",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/array_api_strict/_array_object.py:438\u001b[0m, in \u001b[0;36mArray._validate_index\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    433\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle-axes index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a boolean array and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, but masking is only specified in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray API when the array is the sole index.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         )\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m i\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m _integer_dtypes \u001b[38;5;129;01mand\u001b[39;00m i\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 438\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    439\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle-axes index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a non-zero-dimensional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minteger array, but advanced integer indexing is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified in the Array API.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle-axes index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a tuple, but nested tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are not specified in the Array API.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: Single-axes index [1 2] is a non-zero-dimensional integer array, but advanced integer indexing is not specified in the Array API."
     ]
    }
   ],
   "source": [
    "import array_api_strict as np\n",
    "#import array_api_compat.numpy as np\n",
    "\n",
    "data_arr = np.zeros((10,10))\n",
    "\n",
    "slice = np.asarray([1,2])\n",
    "\n",
    "data_slice = data_arr[slice,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Array' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m X_im2col \u001b[38;5;241m=\u001b[39m im2col(X\u001b[38;5;241m=\u001b[39mX_batch,conv1\u001b[38;5;241m=\u001b[39mconv1,stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     81\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(conv1)\n\u001b[0;32m---> 82\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mconv1_reshaped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m     83\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n\u001b[1;32m     84\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m X_conv\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m24\u001b[39m) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Array' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# !python -m pip install array-api-compat\n",
    "#import array_api_compat.numpy as np\n",
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = [[[[\n",
    "    random.random() for _ in range(5)\n",
    "] for _ in range(5)] for _ in range(1)] for _ in range(2)]\n",
    "conv1 = np.asarray(conv1, dtype=np.float32)\n",
    "conv1 = conv1*math.sqrt(0.2)\n",
    "conv1 = np.asarray(conv1, dtype=np.float32)\n",
    "W1in = [[random.random() for _ in range(288)] for _ in range(60)]\n",
    "W1in = np.asarray(W1in, dtype=np.float32)\n",
    "W1 = W1in/math.sqrt(288)\n",
    "B0 = np.zeros((60,1))/math.sqrt(288)\n",
    "W2in = [[random.random() for _ in range(60)] for _ in range(10)]\n",
    "W2in = np.asarray(W2in, dtype=np.float32)\n",
    "W2 = W2in/math.sqrt(60)\n",
    "B1 = np.zeros((10,1))/math.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    indices = list(range(data_array.shape[0]))\n",
    "    random.shuffle(indices)\n",
    "    permutation = np.asarray(indices)\n",
    "    n_permuted = permutation.shape[0]\n",
    "    # copy each dimension/index i into data_array_train (allocate for both onehot/data array)\n",
    "    # data_array_train = data_array[permutation,...]\n",
    "    data_array_train = np.zeros_like(data_array)\n",
    "    one_hot_encoding_train = np.zeros_like(one_hot_encoding)\n",
    "    for i in range(n_permuted):\n",
    "        #print(i)\n",
    "        #print(permutation[i])\n",
    "        #print(data_array_train.shape)\n",
    "        #print(data_array_train[i, :, :, :].shape)\n",
    "        #print(data_array[p_idx, :, :, :].shape)\n",
    "        p_idx = permutation[i]\n",
    "        data_array_train[i, :, :, :] = data_array[p_idx, :, :, :]\n",
    "        one_hot_encoding_train[i, :] = one_hot_encoding[p_idx, :]\n",
    "\n",
    "    #data_array_train = data_array[permutation,:,:,:]\n",
    "\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(2, 25)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = X_conv.reshape(32, 2, 24, 24) \n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['Conv1'] = beta1 * momentums.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['Conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['Conv1'] = beta2 * velocities.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['Conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['Conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m one_hot_encoding_train[start:end,:]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m### First Convolutional Layer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m X_im2col \u001b[38;5;241m=\u001b[39m im2col(X\u001b[38;5;241m=\u001b[39mX_batch, conv1\u001b[38;5;241m=\u001b[39m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1'"
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "parameters, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=parameters['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = parameters['conv1'].reshape(parameters['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Define dictionaries for parameters and gradients\n",
    "        parameters = {'W1': W1, 'B0': B0, 'W2': W2, 'B1': B1, 'Conv1': conv1}\n",
    "        grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        parameters, velocities, momentums = update_with_adam(parameters, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters\n",
    "        W1, B0, W2, B1, conv1 = parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
