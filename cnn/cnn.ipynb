{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "data['row_number'] = range(0,data.shape[0])\n",
    "\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1,random_state=42)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "for label in range(10):\n",
    "    if label==0:\n",
    "        tmp = data[data['label']==label].head(600)\n",
    "    else:\n",
    "        curr = data[data['label']==label].head(600)\n",
    "        tmp = pd.concat([tmp,curr])\n",
    "data_train = tmp\n",
    "trainRowNums = tmp['row_number'].values\n",
    "test_set = data.loc[~data['row_number'].isin(trainRowNums)]\n",
    "\n",
    "## Create one hot encoding\n",
    "one_hot = pd.get_dummies(data_train['label'].unique())\n",
    "one_hot['label'] = one_hot.index\n",
    "\n",
    "data_train = pd.merge(data_train,one_hot)\n",
    "data_test = test_set.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## Test set with 120 entries per class\n",
    "for label in range(10):\n",
    "    if label==0:\n",
    "        tmp = data_test[data_test['label']==label].head(120)\n",
    "    else:\n",
    "        curr = data_test[data_test['label']==label].head(120)\n",
    "        tmp = pd.concat([tmp,curr])\n",
    "data_test = tmp\n",
    "data_test = pd.merge(data_test,one_hot)\n",
    "data_train.drop('label',axis=1,inplace=True)\n",
    "\n",
    "data_test.drop('label',axis=1,inplace=True)\n",
    "\n",
    "## Create the train and test set and normalize the inputs\n",
    "# X_train = np.array(data_train.drop([0,1,2,3,4,5,6,7,8,9,'row_number'],axis=1).values)/255\n",
    "# y_train = np.array(data_train[[0,1,2,3,4,5,6,7,8,9]].values)\n",
    "# X_test = np.array(data_test.drop([0,1,2,3,4,5,6,7,8,9,'row_number'],axis=1).values)/255\n",
    "# y_test = np.array(data_test[[0,1,2,3,4,5,6,7,8,9]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize, and pixel entries range from 0 to 255\n",
    "# First 10 cols are targets (ytrain/ytest) and the rest is input data\n",
    "X_train = np.transpose(data_train.iloc[:, 11:].values / 255)\n",
    "y_train = np.transpose(data_train.iloc[:, :10].values)\n",
    "X_test = np.transpose(data_test.iloc[:, 11:].values / 255)\n",
    "y_test = np.transpose(data_test.iloc[:, :10].values)\n",
    "X_train_reshape = np.zeros((X_train.shape[1],1,28,28))\n",
    "for i in range(X_train.shape[1]):\n",
    "    temp = X_train[:,i]\n",
    "    temp = np.ravel(temp)\n",
    "    temp = temp.reshape(28,28)\n",
    "    X_train_reshape[i,0,:,:] = temp\n",
    "    \n",
    "X_train= X_train_reshape  \n",
    "\n",
    "X_test_reshape = np.zeros((X_test.shape[1],1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape the input vectors to 28X28 NumPy arrays\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    temp = X_test[:,i]\n",
    "    temp = np.ravel(temp)\n",
    "    temp = temp.reshape(28,28)\n",
    "    X_test_reshape[i,0,:,:] = temp\n",
    "\n",
    "X_test= X_test_reshape\n",
    "\n",
    "conv1 = np.random.randn(2,1,5,5) * np.sqrt(1. / 5)\n",
    "\n",
    "stride = 1\n",
    "filter_h = conv1.shape[2]\n",
    "filter_w = conv1.shape[3]\n",
    "new_channels = conv1.shape[0]\n",
    "## Get resultant Width and Height of Image\n",
    "\n",
    "image_data = X_train\n",
    "result_h = int(((image_data.shape[2]-filter_h)/stride) + 1)\n",
    "result_w = int(((image_data.shape[3]-filter_w)/stride) + 1)\n",
    "\n",
    "## Out 0 matrix\n",
    "result_conv1 = np.random.rand(image_data.shape[0],new_channels,result_h,result_w)\n",
    "\n",
    "# Iterate over each image in the dataset\n",
    "for image_position in range(image_data.shape[0]):\n",
    "    image_selected = image_data[image_position,:,:,:]\n",
    "    \n",
    "    # Each filter in conv layer\n",
    "    for filter_position in range(conv1.shape[0]):\n",
    "        filter_selected = conv1[filter_position,:,:,:]\n",
    "        \n",
    "        # Vertical slide across the image\n",
    "        for i in range(0, image_selected.shape[1], stride):\n",
    "            # Vertical slice matching filter height\n",
    "            image_rectangle = image_selected[:,i:i+filter_h,:]\n",
    "            # If its height is less than the filter's height skip\n",
    "            if image_rectangle.shape[1] < filter_h:\n",
    "                continue\n",
    "            \n",
    "            # Horizontal slide across the vertical slice\n",
    "            for j in range(0, image_rectangle.shape[2], stride):\n",
    "                # Slice matching the filter's width\n",
    "                image_portion = image_rectangle[:,:,j:j+filter_w]\n",
    "                # Skip if width less than the filter's width\n",
    "                if image_portion.shape[2] < filter_w:\n",
    "                    continue\n",
    "                \n",
    "                # Apply filter to selected image portion\n",
    "                convolution_result = np.multiply(filter_selected, image_portion)\n",
    "                # Sum convolution output and store it in the result array\n",
    "                result_conv1[image_position, filter_position, i, j] = np.sum(convolution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Pad around images to preserve size after convolution\n",
    "    X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    X = X_padded\n",
    "    \n",
    "    # Dims of the output post-filter\n",
    "    new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "    new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "    c = 0  # Curr column in the output array\n",
    "    \n",
    "    # Iterate over each image in the batch\n",
    "    for position in range(X.shape[0]):\n",
    "        # Current image\n",
    "        image_position = X[position, :, :, :]\n",
    "        \n",
    "        # Vertical slide down the image, with \"stride\" steps \n",
    "        for height in range(0, image_position.shape[1], stride):\n",
    "            # Select a horizontal slice that matches filter height\n",
    "            image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "            # Next iteration if slice's height < than filter height\n",
    "            if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "                continue\n",
    "            \n",
    "            # Horizontal slide down the image, with \"stride\" steps \n",
    "            for width in range(0, image_rectangle.shape[2], stride):\n",
    "                # Slice portion that matches the filter width\n",
    "                image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "                # If portion's width < filter width\n",
    "                if image_square.shape[2] < conv1.shape[3]:\n",
    "                    continue\n",
    "                \n",
    "                # Flatten and store \n",
    "                im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "                c += 1\n",
    " \n",
    "    return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4 into shape (1,1,24,24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m conv1_col \u001b[38;5;241m=\u001b[39m conv1\u001b[38;5;241m.\u001b[39mreshape(conv1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m X_result \u001b[38;5;241m=\u001b[39m conv1_col\u001b[38;5;129m@X_im2col\u001b[39m\n\u001b[0;32m----> 8\u001b[0m X_result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresult_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresult_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_result)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4 into shape (1,1,24,24)"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,0,0],[1,2,3],[3,4,5]])\n",
    "X = X.reshape(1,1,3,3)\n",
    "conv1 = np.array([[1,0],[0,1]])\n",
    "conv1 = conv1.reshape(1,1,2,2)\n",
    "X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "conv1_col = conv1.reshape(conv1.shape[0],-1)\n",
    "X_result = conv1_col@X_im2col\n",
    "X_result = np.array(np.hsplit(X_result, X.shape[0])).reshape((X.shape[0],conv1.shape[0],result_h,result_w))\n",
    "print(X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i)) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
