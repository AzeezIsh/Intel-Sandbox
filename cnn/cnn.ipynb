{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.array(data.drop('label', axis=1))\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = image_data.reshape(-1, 1, image_height, image_width) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.zeros((len(labels), num_classes))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    one_hot_encoding[np.arange(len(labels)), labels] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label'].tolist()\n",
    "\n",
    "# Labels --> one hot\n",
    "one_hot_encoding = labels_to_one_hot(labels)\n",
    "print(one_hot_encoding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbp0lEQVR4nO3df3BV9f3n8deFJBeQ5KYhJDcpIQZUaAXSLYWYghRLvkDsMKDsfP21U3AdGGhwiqnVSVdF2u6mxVnKVzfCzLaFOitg+Y7A6tfBxWjCWAMuEZayrVmSbzRQSFB2khuChEA++wfrtRcS8VzuzTsJz8fMmSH3nk/u2+MZn57cm4PPOecEAEAfG2I9AADgxkSAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAiQTrAa7U3d2tkydPKjk5WT6fz3ocAIBHzjm1t7crOztbQ4b0fp3T7wJ08uRJ5eTkWI8BALhOx48f15gxY3p9vt8FKDk5WZI0U3crQYnG0wAAvLqoLr2rN8L/Pe9N3AJUUVGh5557Ts3NzcrPz9cLL7yg6dOnX3Pd5z92S1CiEnwECAAGnP9/h9FrvY0Slw8hvPLKKyotLdWaNWv0wQcfKD8/X/PmzdPp06fj8XIAgAEoLgFav369li1bpocffljf/OY3tWnTJo0YMUK///3v4/FyAIABKOYBunDhgmpra1VUVPTFiwwZoqKiItXU1Fy1f2dnp0KhUMQGABj8Yh6gTz/9VJcuXVJmZmbE45mZmWpubr5q//LycgUCgfDGJ+AA4MZg/ouoZWVlamtrC2/Hjx+3HgkA0Adi/im49PR0DR06VC0tLRGPt7S0KBgMXrW/3++X3++P9RgAgH4u5ldASUlJmjp1qiorK8OPdXd3q7KyUoWFhbF+OQDAABWX3wMqLS3VkiVL9J3vfEfTp0/Xhg0b1NHRoYcffjgeLwcAGIDiEqD77rtPn3zyiZ555hk1NzfrW9/6lvbs2XPVBxMAADcun3POWQ/x90KhkAKBgGZrIXdCAIAB6KLrUpV2q62tTSkpKb3uZ/4pOADAjYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiIeYCeffZZ+Xy+iG3ixImxfhkAwACXEI9vevvtt+utt9764kUS4vIyAIABLC5lSEhIUDAYjMe3BgAMEnF5D+jYsWPKzs7WuHHj9NBDD6mpqanXfTs7OxUKhSI2AMDgF/MAFRQUaMuWLdqzZ482btyoxsZG3XnnnWpvb+9x//LycgUCgfCWk5MT65EAAP2Qzznn4vkCra2tys3N1fr16/XII49c9XxnZ6c6OzvDX4dCIeXk5Gi2FirBlxjP0QAAcXDRdalKu9XW1qaUlJRe94v7pwNSU1N12223qb6+vsfn/X6//H5/vMcAAPQzcf89oLNnz6qhoUFZWVnxfikAwAAS8wA9/vjjqq6u1kcffaT33ntP99xzj4YOHaoHHngg1i8FABjAYv4juBMnTuiBBx7QmTNnNHr0aM2cOVP79+/X6NGjY/1SAIABLOYB2r59e6y/JTDofPSLQs9rnvi3Oz2v2fHv5nheI0mu9n9HtQ7wgnvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm4v4X0qH/a/2h9xtjStLpmRdjPEnPxm+95HnN0KoPYj+IsTuGN3pe89yT0f0/ZmfrNM9rRjR6/xuMx/7TYc9rus+d87wG/RNXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDB3bAR9V2t35j7T57XrG/5B89r/tSU73lNzrnJntdIkt7/c3TrPBp5wvuaLf/3u57XvHPHRu8vJCkrYaTnNb/8dKLnNf/y8WzPaxI+c57X4Asjdh6wHiGMKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0XUormx6MkHRnteM/Q/t3pe8/GUoZ7XSFLuP0a1zLOMPxzyvOZQ3b/xvObNTX/zvEaSlqac9rzmp6O838j1h7866HnNJe5Fel1W7JxpPUIYV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRjrIfPLfJ3heM7QuutPgr89N8rxm5HHvN+FMHJoXxZpLntf0pe7z5z2vSfrzR57XbPyPiz2vkaTtDzd5XrNn4r94XjM2IdHzmnF7/73nNYEDwzyvGawy9J71CGFcAQEATBAgAIAJzwHat2+fFixYoOzsbPl8Pu3atSvieeecnnnmGWVlZWn48OEqKirSsWPHYjUvAGCQ8Bygjo4O5efnq6Kiosfn161bp+eff16bNm3SgQMHdNNNN2nevHk6H8XPvAEAg5fnd5+Li4tVXFzc43POOW3YsEFPPfWUFi5cKEl66aWXlJmZqV27dun++++/vmkBAINGTN8DamxsVHNzs4qKisKPBQIBFRQUqKampsc1nZ2dCoVCERsAYPCLaYCam5slSZmZmRGPZ2Zmhp+7Unl5uQKBQHjLycmJ5UgAgH7K/FNwZWVlamtrC2/Hjx+3HgkA0AdiGqBgMChJamlpiXi8paUl/NyV/H6/UlJSIjYAwOAX0wDl5eUpGAyqsrIy/FgoFNKBAwdUWFgYy5cCAAxwnj8Fd/bsWdXX14e/bmxs1OHDh5WWlqaxY8dq9erV+uUvf6lbb71VeXl5evrpp5Wdna1FixbFcm4AwADnOUAHDx7UXXfdFf66tLRUkrRkyRJt2bJFTzzxhDo6OrR8+XK1trZq5syZ2rNnj4YN415MAIAv+JxzznqIvxcKhRQIBDRbC5Xg836jwhvdmycPe16T//4DUb1W8n/z/n7dyN3eb0ba9OR3PK/5LKfL8xpJSqv1fmPW4JsnPK+5+HH//rDN6VXf9bxmwgMfel7z29w3PK+58z+Vel6T8WL/uQHnjeCi61KVdqutre1L39c3/xQcAODGRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPeb/2LQed/Td8W1bplWTM8rzn5QbbnNTdv9H6X5RNLJnpeI0n//B/WeV7zw09+4nnNiH5+N+yM/+L97tF/+1uB5zWfbLjoeQ0GD66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUUSvN3Ot5zfpt/+B5TWf3UM9rfhB4zfMaAH2LKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I4UebrozqnVVRybGeJKePTnzDc9rVqT+LarXauyKahmAKHAFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4Gak0Ht7J0W17rana2I8Sc9+/V/v9rwmceZrUb3WiQtp3l+r41JUrwXc6LgCAgCYIEAAABOeA7Rv3z4tWLBA2dnZ8vl82rVrV8TzS5culc/ni9jmz58fq3kBAIOE5wB1dHQoPz9fFRUVve4zf/58nTp1Krxt27btuoYEAAw+nj+EUFxcrOLi4i/dx+/3KxgMRj0UAGDwi8t7QFVVVcrIyNCECRO0cuVKnTlzptd9Ozs7FQqFIjYAwOAX8wDNnz9fL730kiorK/XrX/9a1dXVKi4u1qVLPX9Utby8XIFAILzl5OTEeiQAQD8U898Duv/++8N/njx5sqZMmaLx48erqqpKc+bMuWr/srIylZaWhr8OhUJECABuAHH/GPa4ceOUnp6u+vr6Hp/3+/1KSUmJ2AAAg1/cA3TixAmdOXNGWVlZ8X4pAMAA4vlHcGfPno24mmlsbNThw4eVlpamtLQ0rV27VosXL1YwGFRDQ4OeeOIJ3XLLLZo3b15MBwcADGyeA3Tw4EHddddd4a8/f/9myZIl2rhxo44cOaI//OEPam1tVXZ2tubOnatf/OIX8vv9sZsaADDgeQ7Q7Nmz5Zzr9fk333zzugYCrvTN8k88r9nxtas/8PJV+C71fm73Zti//h/Pa7h9KcC94AAARggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi5n8lN2xN+N1Kz2vGVF2IwySxc/FfP+qz1/J+L2x8LvkvZzyv+cFvn/C8Zuz/bPe8hn+v/RNXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GOsjc/HSN9Qi4UbWGPC8ZfTjN85qOMSM8rxnhm+x5jSTp/T9Htw5fCVdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKICY6pt/sec3aDb/1vCY3wftNT4sPrPS8RpJy/zGqZfiKuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwM1Lo9KrvRrWuPdd5XnPrs0c8r+nu6PC8Bn2vO8HneU00NxbNSxzpec2IYRc8r0H8cQUEADBBgAAAJjwFqLy8XNOmTVNycrIyMjK0aNEi1dXVRexz/vx5lZSUaNSoURo5cqQWL16slpaWmA4NABj4PAWourpaJSUl2r9/v/bu3auuri7NnTtXHX/3M/rHHntMr732mnbs2KHq6mqdPHlS9957b8wHBwAMbJ4+hLBnz56Ir7ds2aKMjAzV1tZq1qxZamtr0+9+9ztt3bpV3//+9yVJmzdv1je+8Q3t379fd9xxR+wmBwAMaNf1HlBbW5skKS0tTZJUW1urrq4uFRUVhfeZOHGixo4dq5qamh6/R2dnp0KhUMQGABj8og5Qd3e3Vq9erRkzZmjSpEmSpObmZiUlJSk1NTVi38zMTDU3N/f4fcrLyxUIBMJbTk5OtCMBAAaQqANUUlKio0ePavv27dc1QFlZmdra2sLb8ePHr+v7AQAGhqh+EXXVqlV6/fXXtW/fPo0ZMyb8eDAY1IULF9Ta2hpxFdTS0qJgMNjj9/L7/fL7/dGMAQAYwDxdATnntGrVKu3cuVNvv/228vLyIp6fOnWqEhMTVVlZGX6srq5OTU1NKiwsjM3EAIBBwdMVUElJibZu3ardu3crOTk5/L5OIBDQ8OHDFQgE9Mgjj6i0tFRpaWlKSUnRo48+qsLCQj4BBwCI4ClAGzdulCTNnj074vHNmzdr6dKlkqTf/OY3GjJkiBYvXqzOzk7NmzdPL774YkyGBQAMHp4C5Ny1bz45bNgwVVRUqKKiIuqh0Ldap3RFte7OyXXX3ukKnw6L4v0+bkYKDErcCw4AYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSLAeADeYbmc9AQa4+R/+wPMa9z9GxWESXC+ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFH1riM96AgxwLf+c63lNxovvxWESXC+ugAAAJggQAMCEpwCVl5dr2rRpSk5OVkZGhhYtWqS6urqIfWbPni2fzxexrVixIqZDAwAGPk8Bqq6uVklJifbv36+9e/eqq6tLc+fOVUdHR8R+y5Yt06lTp8LbunXrYjo0AGDg8/QhhD179kR8vWXLFmVkZKi2tlazZs0KPz5ixAgFg8HYTAgAGJSu6z2gtrY2SVJaWlrE4y+//LLS09M1adIklZWV6dy5c71+j87OToVCoYgNADD4Rf0x7O7ubq1evVozZszQpEmTwo8/+OCDys3NVXZ2to4cOaInn3xSdXV1evXVV3v8PuXl5Vq7dm20YwAABqioA1RSUqKjR4/q3XffjXh8+fLl4T9PnjxZWVlZmjNnjhoaGjR+/Pirvk9ZWZlKS0vDX4dCIeXk5EQ7FgBggIgqQKtWrdLrr7+uffv2acyYMV+6b0FBgSSpvr6+xwD5/X75/f5oxgAADGCeAuSc06OPPqqdO3eqqqpKeXl511xz+PBhSVJWVlZUAwIABidPASopKdHWrVu1e/duJScnq7m5WZIUCAQ0fPhwNTQ0aOvWrbr77rs1atQoHTlyRI899phmzZqlKVOmxOUfAAAwMHkK0MaNGyVd/mXTv7d582YtXbpUSUlJeuutt7RhwwZ1dHQoJydHixcv1lNPPRWzgQEAg4PnH8F9mZycHFVXV1/XQACAG4PPXasqfSwUCikQCGi2FirBl2g9DgDAo4uuS1Xarba2NqWkpPS6HzcjBQCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwESC9QBXcs5Jki6qS3LGwwAAPLuoLklf/Pe8N/0uQO3t7ZKkd/WG8SQAgOvR3t6uQCDQ6/M+d61E9bHu7m6dPHlSycnJ8vl8Ec+FQiHl5OTo+PHjSklJMZrQHsfhMo7DZRyHyzgOl/WH4+CcU3t7u7KzszVkSO/v9PS7K6AhQ4ZozJgxX7pPSkrKDX2CfY7jcBnH4TKOw2Uch8usj8OXXfl8jg8hAABMECAAgIkBFSC/3681a9bI7/dbj2KK43AZx+EyjsNlHIfLBtJx6HcfQgAA3BgG1BUQAGDwIEAAABMECABgggABAEwMmABVVFTo5ptv1rBhw1RQUKD333/feqQ+9+yzz8rn80VsEydOtB4r7vbt26cFCxYoOztbPp9Pu3btinjeOadnnnlGWVlZGj58uIqKinTs2DGbYePoWsdh6dKlV50f8+fPtxk2TsrLyzVt2jQlJycrIyNDixYtUl1dXcQ+58+fV0lJiUaNGqWRI0dq8eLFamlpMZo4Pr7KcZg9e/ZV58OKFSuMJu7ZgAjQK6+8otLSUq1Zs0YffPCB8vPzNW/ePJ0+fdp6tD53++2369SpU+Ht3XfftR4p7jo6OpSfn6+Kiooen1+3bp2ef/55bdq0SQcOHNBNN92kefPm6fz58308aXxd6zhI0vz58yPOj23btvXhhPFXXV2tkpIS7d+/X3v37lVXV5fmzp2rjo6O8D6PPfaYXnvtNe3YsUPV1dU6efKk7r33XsOpY++rHAdJWrZsWcT5sG7dOqOJe+EGgOnTp7uSkpLw15cuXXLZ2dmuvLzccKq+t2bNGpefn289hilJbufOneGvu7u7XTAYdM8991z4sdbWVuf3+922bdsMJuwbVx4H55xbsmSJW7hwock8Vk6fPu0kuerqaufc5X/3iYmJbseOHeF9/vrXvzpJrqamxmrMuLvyODjn3Pe+9z334x//2G6or6DfXwFduHBBtbW1KioqCj82ZMgQFRUVqaamxnAyG8eOHVN2drbGjRunhx56SE1NTdYjmWpsbFRzc3PE+REIBFRQUHBDnh9VVVXKyMjQhAkTtHLlSp05c8Z6pLhqa2uTJKWlpUmSamtr1dXVFXE+TJw4UWPHjh3U58OVx+FzL7/8stLT0zVp0iSVlZXp3LlzFuP1qt/djPRKn376qS5duqTMzMyIxzMzM/Xhhx8aTWWjoKBAW7Zs0YQJE3Tq1CmtXbtWd955p44ePark5GTr8Uw0NzdLUo/nx+fP3Sjmz5+ve++9V3l5eWpoaNDPfvYzFRcXq6amRkOHDrUeL+a6u7u1evVqzZgxQ5MmTZJ0+XxISkpSampqxL6D+Xzo6ThI0oMPPqjc3FxlZ2fryJEjevLJJ1VXV6dXX33VcNpI/T5A+EJxcXH4z1OmTFFBQYFyc3P1xz/+UY888ojhZOgP7r///vCfJ0+erClTpmj8+PGqqqrSnDlzDCeLj5KSEh09evSGeB/0y/R2HJYvXx7+8+TJk5WVlaU5c+aooaFB48eP7+sxe9TvfwSXnp6uoUOHXvUplpaWFgWDQaOp+ofU1FTddtttqq+vtx7FzOfnAOfH1caNG6f09PRBeX6sWrVKr7/+ut55552Iv74lGAzqwoULam1tjdh/sJ4PvR2HnhQUFEhSvzof+n2AkpKSNHXqVFVWVoYf6+7uVmVlpQoLCw0ns3f27Fk1NDQoKyvLehQzeXl5CgaDEedHKBTSgQMHbvjz48SJEzpz5sygOj+cc1q1apV27typt99+W3l5eRHPT506VYmJiRHnQ11dnZqamgbV+XCt49CTw4cPS1L/Oh+sPwXxVWzfvt35/X63ZcsW95e//MUtX77cpaamuubmZuvR+tRPfvITV1VV5RobG92f/vQnV1RU5NLT093p06etR4ur9vZ2d+jQIXfo0CEnya1fv94dOnTIffzxx8455371q1+51NRUt3v3bnfkyBG3cOFCl5eX5z777DPjyWPry45De3u7e/zxx11NTY1rbGx0b731lvv2t7/tbr31Vnf+/Hnr0WNm5cqVLhAIuKqqKnfq1Knwdu7cufA+K1ascGPHjnVvv/22O3jwoCssLHSFhYWGU8fetY5DfX29+/nPf+4OHjzoGhsb3e7du924cePcrFmzjCePNCAC5JxzL7zwghs7dqxLSkpy06dPd/v377ceqc/dd999LisryyUlJbmvf/3r7r777nP19fXWY8XdO++84yRdtS1ZssQ5d/mj2E8//bTLzMx0fr/fzZkzx9XV1dkOHQdfdhzOnTvn5s6d60aPHu0SExNdbm6uW7Zs2aD7n7Se/vkluc2bN4f3+eyzz9yPfvQj97Wvfc2NGDHC3XPPPe7UqVN2Q8fBtY5DU1OTmzVrlktLS3N+v9/dcsst7qc//alra2uzHfwK/HUMAAAT/f49IADA4ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPh/q66fcaVfsBwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize, and pixel entries range from 0 to 255\n",
    "# # First 10 cols are targets (ytrain/ytest) and the rest is input data\n",
    "# X_train = np.transpose(data_train.iloc[:, 11:].values / 255)\n",
    "# y_train = np.transpose(data_train.iloc[:, :10].values)\n",
    "# X_test = np.transpose(data_test.iloc[:, 11:].values / 255)\n",
    "# y_test = np.transpose(data_test.iloc[:, :10].values)\n",
    "# X_train_reshape = np.zeros((X_train.shape[1],1,28,28))\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     temp = X_train[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_train_reshape[i,0,:,:] = temp\n",
    "    \n",
    "# X_train= X_train_reshape  \n",
    "\n",
    "# X_test_reshape = np.zeros((X_test.shape[1],1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape the input vectors to 28X28 NumPy arrays\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# for i in range(X_test.shape[1]):\n",
    "#     temp = X_test[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_test_reshape[i,0,:,:] = temp\n",
    "\n",
    "# X_test= X_test_reshape\n",
    "\n",
    "# conv1 = np.random.randn(2,1,5,5) * np.sqrt(1. / 5)\n",
    "\n",
    "# stride = 1\n",
    "# filter_h = conv1.shape[2]\n",
    "# filter_w = conv1.shape[3]\n",
    "# new_channels = conv1.shape[0]\n",
    "# ## Get resultant Width and Height of Image\n",
    "\n",
    "# image_data = X_train\n",
    "# result_h = int(((image_data.shape[2]-filter_h)/stride) + 1)\n",
    "# result_w = int(((image_data.shape[3]-filter_w)/stride) + 1)\n",
    "\n",
    "# ## Out 0 matrix\n",
    "# result_conv1 = np.random.rand(image_data.shape[0],new_channels,result_h,result_w)\n",
    "\n",
    "# # Iterate over each image in the dataset\n",
    "# for image_position in range(image_data.shape[0]):\n",
    "#     image_selected = image_data[image_position,:,:,:]\n",
    "    \n",
    "#     # Each filter in conv layer\n",
    "#     for filter_position in range(conv1.shape[0]):\n",
    "#         filter_selected = conv1[filter_position,:,:,:]\n",
    "        \n",
    "#         # Vertical slide across the image\n",
    "#         for i in range(0, image_selected.shape[1], stride):\n",
    "#             # Vertical slice matching filter height\n",
    "#             image_rectangle = image_selected[:,i:i+filter_h,:]\n",
    "#             # If its height is less than the filter's height skip\n",
    "#             if image_rectangle.shape[1] < filter_h:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide across the vertical slice\n",
    "#             for j in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice matching the filter's width\n",
    "#                 image_portion = image_rectangle[:,:,j:j+filter_w]\n",
    "#                 # Skip if width less than the filter's width\n",
    "#                 if image_portion.shape[2] < filter_w:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Apply filter to selected image portion\n",
    "#                 convolution_result = np.multiply(filter_selected, image_portion)\n",
    "#                 # Sum convolution output and store it in the result array\n",
    "#                 result_conv1[image_position, filter_position, i, j] = np.sum(convolution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Pad around images to preserve size after convolution\n",
    "    X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    X = X_padded\n",
    "    \n",
    "    # Dims of the output post-filter\n",
    "    new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "    new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "    c = 0  # Curr column in the output array\n",
    "    \n",
    "    # Iterate over each image in the batch\n",
    "    for position in range(X.shape[0]):\n",
    "        # Current image\n",
    "        image_position = X[position, :, :, :]\n",
    "        \n",
    "        # Vertical slide down the image, with \"stride\" steps \n",
    "        for height in range(0, image_position.shape[1], stride):\n",
    "            # Select a horizontal slice that matches filter height\n",
    "            image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "            # Next iteration if slice's height < than filter height\n",
    "            if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "                continue\n",
    "            \n",
    "            # Horizontal slide down the image, with \"stride\" steps \n",
    "            for width in range(0, image_rectangle.shape[2], stride):\n",
    "                # Slice portion that matches the filter width\n",
    "                image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "                # If portion's width < filter width\n",
    "                if image_square.shape[2] < conv1.shape[3]:\n",
    "                    continue\n",
    "                \n",
    "                # Flatten and store \n",
    "                im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "                c += 1\n",
    " \n",
    "    return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "X_batch = data_array[0:10,:,:,:]\n",
    "conv1 = np.random.randn(2,1,5,5)\n",
    "\n",
    "X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "X_conv = conv1_reshaped@X_im2col\n",
    "X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = test_array[:, i:i + 1, :, :].ravel()\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5760)\n",
      "(2, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "delta_conv = np.random.rand(10,2,24,24)\n",
    "delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "print(delta_conv_reshape.shape)\n",
    "conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "Train Accuracy\n",
      "93.47 %\n",
      "Test Accuracy\n",
      "94.0 %\n",
      "-------------------------\n",
      "Epoch : 1\n",
      "Train Accuracy\n",
      "95.67 %\n",
      "Test Accuracy\n",
      "96.0 %\n",
      "-------------------------\n",
      "Epoch : 2\n",
      "Train Accuracy\n",
      "96.42 %\n",
      "Test Accuracy\n",
      "96.0 %\n",
      "-------------------------\n",
      "Epoch : 3\n",
      "Train Accuracy\n",
      "97.25 %\n",
      "Test Accuracy\n",
      "96.7 %\n",
      "-------------------------\n",
      "Epoch : 4\n",
      "Train Accuracy\n",
      "97.07 %\n",
      "Test Accuracy\n",
      "96.6 %\n",
      "-------------------------\n",
      "Epoch : 5\n",
      "Train Accuracy\n",
      "97.87 %\n",
      "Test Accuracy\n",
      "97.1 %\n",
      "-------------------------\n",
      "Epoch : 6\n",
      "Train Accuracy\n",
      "98.0 %\n",
      "Test Accuracy\n",
      "96.7 %\n",
      "-------------------------\n",
      "Epoch : 7\n",
      "Train Accuracy\n",
      "98.43 %\n",
      "Test Accuracy\n",
      "97.1 %\n",
      "-------------------------\n",
      "Epoch : 8\n",
      "Train Accuracy\n",
      "98.55 %\n",
      "Test Accuracy\n",
      "97.1 %\n",
      "-------------------------\n",
      "Epoch : 9\n",
      "Train Accuracy\n",
      "98.73 %\n",
      "Test Accuracy\n",
      "97.3 %\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = np.random.randn(2,1,5,5)*np.sqrt(1./5.)\n",
    "W1 = np.random.rand(60,288)/np.sqrt(288)\n",
    "B0 = np.zeros((60,1))/np.sqrt(288)\n",
    "W2 = np.random.rand(10,60)/np.sqrt(60)\n",
    "B1 = np.zeros((10,1))/np.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['Conv1'] = beta1 * momentums.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['Conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['Conv1'] = beta2 * velocities.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['Conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['Conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Train Accuracy\n",
      "91.48 %\n",
      "Test Accuracy\n",
      "91.8 %\n",
      "-------------------------\n",
      "Epoch : 2\n",
      "Train Accuracy\n",
      "94.25 %\n",
      "Test Accuracy\n",
      "94.2 %\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 70\u001b[0m\n\u001b[1;32m     66\u001b[0m X_maxpool \u001b[38;5;241m=\u001b[39m maxpool_multiple(X_relu,stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m### Get the indices of maxpool\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m max_indices \u001b[38;5;241m=\u001b[39m \u001b[43mmaxpool_indices_multiple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_relu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m### Flatten the maxpool output\u001b[39;00m\n\u001b[1;32m     73\u001b[0m input_shape, num_channels, input_width, input_height \u001b[38;5;241m=\u001b[39m X_maxpool\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[89], line 35\u001b[0m, in \u001b[0;36mmaxpool_indices_multiple\u001b[0;34m(input_image, stride, filter_height, filter_width)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Go through each image\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Add vector of maxpool idx to curr image\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     positional_vector\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmaxpool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m positional_vector\n",
      "Cell \u001b[0;32mIn[89], line 25\u001b[0m, in \u001b[0;36mmaxpool_indices\u001b[0;34m(input_image, stride, filter_height, filter_width)\u001b[0m\n\u001b[1;32m     23\u001b[0m image_square \u001b[38;5;241m=\u001b[39m image_rectangle[:,:,width:width\u001b[38;5;241m+\u001b[39mfilter_width]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Max val within square \u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m a,b,c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munravel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_square\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_square\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Store map and max val\u001b[39;00m\n\u001b[1;32m     27\u001b[0m positional_vector\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m0\u001b[39m,channel,\u001b[38;5;28mint\u001b[39m(b)\u001b[38;5;241m+\u001b[39mheight,\u001b[38;5;28mint\u001b[39m(c)\u001b[38;5;241m+\u001b[39mwidth,\u001b[38;5;241m0\u001b[39m,channel,x,y])\n",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/numpy/core/multiarray.py:1030\u001b[0m, in \u001b[0;36munravel_index\u001b[0;34m(indices, shape, order)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;03m    ravel_multi_index(multi_index, dims, mode='raise', order='C')\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    1621\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m multi_index\n\u001b[0;32m-> 1030\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39munravel_index)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munravel_index\u001b[39m(indices, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m    unravel_index(indices, shape, order='C')\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (indices,)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "parameters, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=parameters['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = parameters['conv1'].reshape(parameters['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Define dictionaries for parameters and gradients\n",
    "        parameters = {'W1': W1, 'B0': B0, 'W2': W2, 'B1': B1, 'Conv1': conv1}\n",
    "        grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        parameters, velocities, momentums = update_with_adam(parameters, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters\n",
    "        W1, B0, W2, B1, conv1 = parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
