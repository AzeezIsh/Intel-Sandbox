{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import array_api_strict as np\n",
    "\n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.asarray(data.drop('label', axis=1), dtype=np.float32)\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = np.reshape(image_data, (-1, 1, image_height, image_width)) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 6, 0, 4, 0, 0, 5, 0, 8, 6, 9, 4, 9, 0, 6, 1, 7, 9, 6, 1, 6, 0, 3, 8, 1, 4, 2, 6, 1, 7, 7, 0, 2, 5, 0, 1, 0, 5, 1, 6, 3, 5, 9, 2, 8, 4, 4, 3, 8, 7, 9, 3, 9, 1, 3, 9, 0, 8, 8, 7, 0, 9, 5, 9, 4, 8, 3, 7, 4, 7, 4, 8, 5, 6, 4, 0, 6, 1, 6, 9, 0, 6, 8, 6, 5, 9, 0, 7, 7, 2, 9, 1, 9, 1, 3, 9, 4, 4, 9, 1, 1, 5, 6, 3, 8, 6, 0, 6, 0, 6, 8, 8, 2, 1, 0, 1, 7, 9, 7, 1, 1, 0, 4, 2, 7, 9, 8, 7, 7, 9, 9, 6, 9, 5, 7, 2, 9, 3, 2, 4, 1, 6, 3, 3, 6, 5, 3, 9, 6, 1, 6, 4, 2, 1, 3, 4, 6, 9, 8, 8, 5, 3, 2, 0, 3, 0, 3, 5, 2, 4, 7, 9, 7, 6, 5, 1, 4, 3, 3, 1, 5, 1, 6, 1, 1, 5, 5, 1, 2, 4, 1, 5, 7, 9, 8, 3, 3, 5, 7, 9, 0, 8, 5, 2, 3, 4, 7, 8, 7, 8, 3, 6, 0, 5, 5, 1, 6, 2, 7, 2, 9, 1, 8, 8, 1, 2, 4, 0, 0, 9, 5, 0, 5, 9, 1, 8, 7, 7, 7, 2, 6, 7, 3, 6, 3, 9, 0, 8, 5, 6, 3, 6, 7, 0, 1, 5, 2, 9, 0, 3, 3, 5, 5, 9, 5, 4, 6, 8, 1, 0, 2, 8, 4, 8, 8, 8, 1, 5, 7, 4, 5, 3, 4, 7, 3, 4, 0, 0, 9, 3, 6, 1, 3, 0, 6, 3, 2, 3, 6, 1, 8, 1, 8, 4, 1, 3, 3, 9, 4, 7, 7, 5, 7, 9, 3, 0, 0, 5, 6, 2, 4, 8, 9, 7, 8, 4, 9, 0, 1, 5, 3, 7, 3, 6, 4, 1, 5, 8, 1, 5, 9, 4, 7, 3, 5, 8, 9, 7, 0, 9, 4, 7, 9, 2, 3, 3, 1, 4, 8, 3, 8, 9, 2, 2, 8, 4, 1, 7, 9, 3, 9, 9, 9, 5, 3, 7, 2, 9, 6, 8, 0, 3, 3, 8, 2, 0, 8, 2, 9, 6, 9, 4, 6, 7, 4, 7, 9, 9, 5, 4, 8, 0, 6, 2, 8, 6, 0, 2, 2, 8, 8, 9, 7, 4, 4, 2, 3, 8, 9, 6, 3, 3, 8, 6, 9, 2, 1, 9, 6, 1, 3, 6, 7, 9, 8, 3, 2, 8, 5, 4, 2, 1, 0, 8, 9, 0, 5, 2, 4, 5, 5, 8, 7, 1, 3, 1, 2, 5, 2, 1, 0, 2, 9, 5, 9, 0, 9, 7, 2, 4, 8, 0, 4, 8, 6, 2, 9, 7, 1, 1, 8, 3, 2, 1, 3, 4, 8, 2, 2, 7, 8, 0, 7, 4, 8, 8, 2, 4, 3, 2, 5, 3, 7, 3, 6, 5, 1, 0, 2, 9, 8, 0, 8, 3, 2, 9, 4, 5, 3, 0, 7, 3, 9, 7, 5, 2, 6, 4, 9, 7, 5, 8, 6, 3, 4, 7, 3, 1, 5, 7, 5, 2, 0, 2, 3, 4, 3, 4, 4, 7, 4, 9, 8, 9, 9, 6, 9, 0, 9, 7, 3, 7, 9, 8, 3, 7, 2, 9, 2, 1, 1, 3, 5, 3, 6, 9, 4, 3, 8, 5, 7, 2, 6, 5, 4, 1, 1, 3, 7, 1, 2, 1, 2, 0, 0, 2, 7, 0, 7, 8, 4, 7, 4, 5, 4, 0, 3, 6, 2, 4, 4, 8, 8, 5, 3, 1, 8, 4, 8, 0, 8, 2, 2, 3, 1, 8, 3, 3, 0, 1, 2, 1, 1, 9, 0, 5, 0, 4, 8, 8, 4, 0, 6, 1, 7, 6, 5, 2, 9, 9, 3, 2, 3, 7, 5, 6, 1, 6, 4, 1, 1, 2, 0, 5, 5, 9, 4, 6, 2, 2, 6, 3, 3, 4, 8, 4, 6, 1, 9, 6, 6, 4, 3, 4, 7, 4, 3, 0, 2, 2, 4, 5, 5, 5, 2, 5, 6, 3, 9, 6, 4, 2, 2, 2, 6, 9, 2, 6, 4, 8, 1, 9, 4, 2, 8, 3, 2, 9, 6, 8, 4, 5, 5, 7, 6, 2, 0, 2, 6, 9, 7, 3, 6, 8, 2, 7, 5, 6, 4, 2, 1, 0, 8, 0, 7, 3, 4, 8, 9, 3, 4, 8, 5, 5, 7, 6, 4, 8, 0, 4, 2, 9, 3, 1, 7, 9, 2, 3, 9, 8, 2, 2, 0, 0, 7, 9, 9, 3, 7, 9, 6, 9, 8, 9, 4, 3, 2, 9, 6, 3, 6, 3, 7, 1, 2, 5, 7, 5, 5, 0, 8, 3, 5, 1, 2, 5, 1, 1, 1, 5, 3, 8, 7, 9, 5, 5, 6, 3, 4, 4, 9, 7, 7, 6, 1, 5, 8, 8, 6, 6, 7, 4, 4, 1, 5, 7, 5, 8, 8, 2, 8, 6, 7, 7, 1, 9, 9, 7, 5, 7, 1, 9, 4, 4, 5, 2, 0, 4, 3, 8, 1, 8, 1, 1, 2, 7, 4, 5, 2, 2, 8, 5, 2, 3, 2, 2, 1, 4, 7, 0, 0, 7, 6, 5, 8, 4, 9, 8, 1, 6, 8, 2, 4, 4, 5, 4, 2, 2, 9, 6, 0, 3, 2, 0, 2, 8, 5, 1, 4, 7, 6, 3, 6, 0, 1, 8, 9, 9, 6, 3, 4, 9, 8, 4, 5, 5, 6, 6, 1, 9, 7, 1, 2, 7, 9, 4, 0, 5, 7, 3, 4, 9, 5, 5, 0, 4, 4, 5, 9, 8, 7, 8, 6, 2, 0, 4, 8, 0, 6, 8, 5, 2, 6, 2, 2, 0, 4, 6, 1, 6, 8, 7, 9, 9, 9, 4, 0, 4, 2, 4, 1, 2, 7, 0, 4, 8, 6, 0, 6, 4, 6, 1, 0, 6, 5, 4, 7, 8, 1, 8, 5, 8, 7, 7, 0, 4, 8, 1, 2, 8, 7, 1, 5, 9, 7, 0, 2, 2, 8, 8, 7, 0, 3, 5, 1, 6, 1, 1, 9, 9, 2, 4, 8, 5, 4, 4, 5, 2, 5, 0, 0, 6, 2, 8, 6, 4, 8, 4, 3, 0, 1, 1, 0, 1, 8, 2, 6, 3, 2, 4, 3, 2, 7, 5, 2, 8, 3, 6, 8, 0, 2, 4, 9, 8, 1, 5, 8, 6, 6, 8, 7, 3, 3, 7, 1, 9, 7, 1, 0, 1, 0, 8, 7, 4, 9, 6, 9, 4, 2, 1, 1, 9, 1, 9, 4, 9, 5, 7, 6, 2, 0, 3, 0, 6, 9, 9, 1, 7, 9, 2, 8, 0, 3, 0, 9, 4, 5, 1, 2, 8, 8, 9, 0, 9, 6, 3, 6, 1, 9, 1, 0, 6, 5, 5, 0, 1, 4, 8, 2, 7, 7, 7, 8, 6, 1, 3, 8, 8, 8, 1, 6, 7, 2, 7, 4, 7, 8, 3, 4, 7, 1, 6, 5, 9, 6, 1, 6, 5, 1, 0, 4, 3, 5, 2, 7, 0, 8, 6, 7, 9, 8, 2, 1, 0, 0, 0, 3, 3, 3, 5, 2, 7, 2, 6, 2, 5, 6, 2, 6, 5, 5, 7, 2, 0, 1, 0, 6, 7, 6, 6, 4, 3, 9, 9, 9, 3, 1, 1, 8, 4, 1, 1, 0, 6, 3, 2, 5, 6, 2, 6, 0, 7, 1, 8, 0, 5, 6, 0, 0, 4, 0, 0, 6, 0, 1, 9, 1, 5, 5, 3, 0, 2, 5, 4, 0, 6, 2, 5, 5, 9, 8, 1, 8, 0, 3, 7, 6, 3, 1, 4, 5, 3, 7, 1, 1, 7, 9, 5, 8, 5, 5, 3, 9, 9, 8, 9, 8, 0, 8, 6, 4, 2, 2, 2, 1, 8, 8, 3, 8, 2, 1, 6, 4, 4, 8, 2, 6, 1, 3, 2, 9, 8, 1, 8, 3, 4, 2, 2, 9, 5, 6, 1, 0, 1, 8, 8, 0, 7, 7, 3, 7, 8, 0, 8, 5, 5, 9, 5, 6, 0, 5, 8, 2, 9, 3, 2, 8, 4, 0, 4, 5, 4, 1, 1, 3, 0, 8, 0, 3, 2, 3, 2, 7, 7, 6, 9, 7, 3, 8, 5, 3, 7, 2, 6, 0, 8, 7, 7, 3, 5, 5, 9, 5, 7, 4, 3, 7, 8, 3, 6, 6, 9, 5, 7, 2, 0, 6, 5, 5, 9, 3, 3, 6, 7, 5, 5, 5, 3, 1, 6, 0, 0, 4, 9, 8, 0, 6, 9, 9, 3, 6, 3, 7, 8, 6, 3, 9, 2, 8, 1, 7, 0, 7, 1, 3, 2, 0, 9, 8, 4, 1, 6, 2, 3, 4, 3, 9, 4, 5, 1, 4, 2, 6, 2, 0, 6, 6, 0, 9, 4, 7, 8, 4, 8, 4, 4, 5, 4, 8, 1, 4, 3, 3, 7, 5, 4, 9, 6, 3, 2, 3, 9, 9, 5, 6, 4, 2, 8, 8, 0, 3, 9, 2, 2, 0, 5, 0, 2, 3, 2, 4, 9, 5, 1, 9, 6, 4, 1, 9, 2, 4, 9, 9, 1, 1, 1, 3, 6, 7, 0, 2, 0, 5, 6, 9, 7, 8, 1, 6, 8, 1, 3, 2, 3, 3, 4, 0, 4, 7, 6, 9, 6, 7, 1, 8, 5, 1, 7, 3, 8, 2, 4, 4, 3, 9, 2, 5, 3, 2, 9, 3, 5, 1, 8, 9, 3, 9, 4, 4, 5, 6, 1, 6, 2, 7, 7, 4, 5, 6, 3, 0, 6, 8, 2, 3, 8, 5, 8, 9, 3, 1, 5, 9, 5, 7, 7, 8, 6, 6, 8, 5, 1, 4, 4, 5, 4, 5, 8, 5, 8, 7, 6, 9, 9, 2, 2, 0, 7, 9, 3, 6, 9, 7, 1, 8, 1, 3, 9, 7, 0, 3, 3, 3, 9, 2, 1, 9, 3, 3, 2, 8, 7, 4, 2, 0, 8, 1, 4, 0, 5, 7, 4, 8, 0, 5, 3, 2, 2, 5, 5, 6, 8, 2, 0, 6, 3, 4, 5, 6, 0, 9, 3, 6, 1, 5, 2, 8, 7, 5, 7, 9, 7, 6, 0, 0, 8, 9, 4, 1, 2, 1, 4, 6, 6, 8, 8, 6, 9, 1, 1, 2, 0, 6, 4, 6, 7, 6, 4, 4, 7, 4, 0, 4, 4, 6, 9, 3, 7, 2, 9, 0, 6, 0, 7, 6, 4, 6, 5, 7, 2, 5, 8, 7, 8, 7, 9, 0, 5, 7, 1, 7, 1, 7, 3, 6, 7, 2, 7, 6, 7, 9, 7, 2, 4, 6, 4, 5, 6, 5, 2, 0, 7, 8, 3, 7, 5, 4, 1, 2, 8, 0, 2, 5, 8, 4, 8, 2, 4, 9, 7, 8, 2, 3, 0, 4, 4, 4, 2, 3, 4, 7, 6, 0, 2, 9, 2, 4, 7, 3, 6, 8, 1, 9, 6, 0, 7, 6, 4, 4, 0, 6, 6, 3, 9, 5, 2, 3, 5, 5, 6, 9, 2, 6, 3, 9, 5, 4, 2, 5, 1, 2, 1, 1, 9, 3, 0, 8, 9, 8, 1, 8, 4, 3, 6, 5, 7, 7, 5, 1, 4, 1, 2, 8, 9, 0, 7, 1, 9, 1, 0, 5, 5, 1, 5, 0, 8, 7, 5, 4, 8, 8, 7, 7, 6, 1, 7, 8, 0, 5, 7, 0, 2, 2, 9, 6, 1, 6, 3, 9, 8, 9, 3, 8, 1, 0, 8, 5, 9, 2, 2, 2, 4, 1, 4, 0, 1, 1, 8, 7, 3, 3, 5, 2, 1, 7, 4, 0, 0, 0, 9, 8, 7, 8, 6, 9, 3, 6, 4, 2, 1, 6, 7, 7, 0, 4, 1, 0, 3, 0, 9, 4, 7, 6, 9, 3, 6, 6, 0, 6, 7, 2, 2, 5, 1, 9, 0, 0, 9, 2, 5, 4, 7, 0, 1, 2, 2, 9, 4, 3, 5, 2, 0, 6, 3, 6, 3, 3, 9, 9, 0, 2, 1, 7, 5, 2, 3, 5, 2, 3, 4, 7, 8, 3, 1, 1, 6, 2, 2, 0, 5, 7, 6, 9, 8, 7, 2, 2, 9, 4, 3, 9, 7, 8, 5, 2, 0, 5, 0, 5, 2, 0, 8, 9, 9, 9, 9, 4, 5, 8, 0, 1, 4, 3, 7, 0, 4, 0, 2, 5, 4, 6, 1, 2, 4, 0, 2, 6, 8, 8, 0, 2, 0, 1, 8, 8, 1, 7, 6, 2, 2, 7, 0, 8, 9, 6, 7, 3, 9, 2, 4, 3, 7, 3, 6, 7, 7, 8, 0, 6, 7, 2, 9, 0, 9, 5, 6, 0, 3, 6, 1, 7, 5, 6, 5, 3, 5, 7, 5, 6, 2, 0, 5, 2, 1, 9, 1, 2, 4, 5, 7, 1, 6, 7, 2, 2, 8, 1, 3, 3, 4, 2, 5, 4, 1, 8, 8, 3, 9, 5, 8, 5, 5, 4, 3, 9, 5, 0, 3, 5, 9, 4, 3, 9, 6, 6, 7, 5, 5, 1, 6, 6, 3, 1, 0, 5, 9, 1, 7, 6, 4, 8, 1, 7, 6, 3, 6, 1, 0, 7, 9, 4, 7, 5, 1, 1, 9, 0, 2, 7, 5, 0, 5, 8, 1, 3, 7, 1, 2, 2, 8, 2, 3, 2, 4, 0, 1, 6, 4, 5, 9, 1, 2, 4, 9, 8, 5, 2, 7, 5, 8, 8, 1, 7, 3, 1, 3, 4, 2, 7, 7, 9, 9, 4, 3, 6, 0, 9, 3, 7, 3, 2, 8, 4, 5, 7, 1, 9, 3, 0, 4, 8, 9, 3, 0, 6, 9, 5, 2, 9, 9, 6, 8, 3, 1, 4, 5, 0, 2, 2, 2, 6, 3, 1, 2, 0, 7, 4, 5, 5, 6, 4, 9, 1, 9, 2, 8, 5, 3, 0, 5, 8, 4, 5, 4, 3, 8, 9, 3, 8, 1, 5, 5, 5, 4, 0, 2, 2, 0, 4, 4, 3, 1, 4, 1, 6, 7, 3, 0, 2, 2, 0, 8, 8, 8, 6, 2, 9, 6, 5, 0, 4, 2, 0, 4, 0, 2, 1, 3, 9, 6, 9, 0, 3, 3, 3, 4, 9, 6, 3, 0, 0, 0, 7, 5, 9, 9, 7, 9, 9, 6, 6, 3, 2, 4, 4, 8, 7, 9, 6, 3, 5, 2, 2, 5, 1, 3, 0, 0, 4, 4, 7, 5, 9, 5, 2, 8, 7, 3, 2, 5, 3, 9, 1, 6, 9, 6, 7, 8, 0, 8, 6, 8, 0, 2, 9, 9, 6, 7, 8, 8, 5, 0, 2, 2, 6, 7, 7, 0, 0, 7, 1, 4, 5, 8, 5, 6, 6, 1, 2, 0, 5, 7, 2, 3, 8, 7, 6, 2, 2, 7, 0, 4, 3, 8, 9, 9, 2, 9, 1, 1, 5, 3, 2, 9, 4, 5, 8, 3, 8, 5, 7, 4, 5, 8, 2, 1, 3, 6, 8, 8, 1, 8, 9, 1, 8, 6, 7, 3, 4, 4, 7, 5, 2, 1, 3, 3, 3, 5, 1, 0, 7, 4, 2, 6, 9, 4, 4, 1, 9, 4, 8, 3, 0, 8, 0, 2, 3, 2, 0, 2, 8, 7, 7, 8, 2, 6, 5, 0, 8, 2, 9, 3, 0, 0, 9, 4, 5, 1, 4, 3, 1, 8, 5, 1, 9, 0, 7, 0, 8, 2, 0, 2, 7, 4, 7, 3, 3, 3, 5, 9, 0, 2, 8, 9, 2, 5, 7, 5, 7, 4, 8, 2, 3, 0, 7, 7, 1, 4, 9, 1, 1, 5, 9, 5, 5, 7, 7, 1, 7, 3, 5, 2, 8, 5, 3, 6, 7, 6, 3, 2, 6, 0, 3, 8, 8, 5, 9, 6, 3, 6, 3, 8, 2, 1, 5, 5, 0, 3, 5, 2, 6, 8, 5, 5, 1, 5, 8, 9, 5, 4, 9, 1, 2, 3, 1, 9, 8, 7, 3, 4, 9, 9, 7, 7, 7, 0, 6, 4, 7, 2, 1, 5, 3, 7, 8, 5, 6, 4, 7, 6, 3, 5, 5, 3, 0, 1, 7, 9, 7, 3, 3, 2, 4, 2, 8, 4, 3, 5, 0, 0, 8, 2, 0, 5, 4, 6, 8, 2, 9, 7, 2, 0, 0, 2, 7, 1, 4, 3, 6, 3, 5, 5, 7, 7, 5, 3, 4, 1, 3, 6, 7, 4, 2, 4, 9, 0, 6, 9, 0, 0, 8, 8, 8, 1, 9, 9, 9, 4, 2, 9, 0, 0, 2, 3, 4, 0, 7, 2, 2, 8, 4, 5, 2, 7, 6, 3, 0, 6, 3, 3, 7, 9, 1, 4, 6, 9, 7, 9, 2, 2, 9, 4, 0, 8, 0, 1, 4, 1, 9, 0, 4, 1, 0, 6, 8, 4, 4, 3, 7, 1, 6, 4, 0, 2, 4, 6, 4, 4, 4, 8, 2, 4, 8, 0, 6, 5, 1, 5, 2, 3, 9, 5, 7, 5, 7, 4, 3, 5, 3, 0, 3, 3, 3, 5, 5, 8, 8, 6, 5, 9, 6, 7, 7, 3, 6, 7, 2, 8, 3, 7, 0, 0, 7, 2, 4, 6, 2, 3, 7, 8, 0, 0, 3, 6, 1, 8, 6, 1, 4, 9, 8, 6, 3, 8, 4, 3, 5, 3, 7, 4, 3, 2, 4, 4, 1, 0, 4, 6, 9, 4, 5, 7, 7, 3, 8, 1, 2, 8, 1, 4, 8, 9, 4, 7, 4, 9, 0, 9, 6, 8, 1, 2, 4, 5, 0, 8, 8, 3, 2, 5, 3, 8, 5, 2, 5, 9, 4, 5, 2, 2, 0, 8, 9, 9, 5, 7, 4, 2, 3, 7, 4, 2, 4, 3, 0, 3, 9, 0, 4, 0, 0, 5, 2, 1, 0, 5, 4, 0, 9, 8, 0, 5, 9, 3, 4, 2, 8, 7, 4, 1, 3, 6, 0, 1, 3, 1, 9, 9, 5, 5, 5, 7, 7, 2, 0, 8, 7, 4, 2, 3, 1, 4, 9, 6, 2, 7, 6, 9, 0, 8, 5, 5, 4, 3, 1, 4, 1, 2, 2, 2, 5, 7, 9, 5, 2, 3, 0, 7, 7, 6, 2, 2, 1, 5, 8, 6, 0, 7, 8, 6, 3, 8, 0, 6, 7, 7, 9, 6, 3, 0, 1, 7, 1, 0, 8, 6, 5, 1, 9, 2, 7, 6, 0, 9, 1, 9, 7, 6, 5, 1, 5, 5, 2, 2, 2, 6, 0, 4, 7, 6, 1, 6, 9, 2, 9, 0, 3, 2, 0, 7, 1, 8, 7, 8, 5, 3, 0, 1, 1, 1, 0, 4, 6, 8, 2, 6, 9, 7, 8, 1, 0, 0, 1, 8, 9, 2, 5, 9, 3, 7, 1, 6, 2, 3, 2, 1, 4, 1, 9, 7, 2, 9, 6, 1, 5, 6, 8, 3, 4, 2, 0, 8, 0, 1, 1, 8, 0, 3, 0, 1, 7, 5, 7, 8, 4, 8, 3, 3, 0, 0, 4, 8, 0, 1, 4, 6, 6, 3, 5, 9, 8, 0, 0, 8, 9, 4, 5, 9, 3, 0, 8, 7, 9, 8, 6, 6, 5, 9, 1, 3, 3, 6, 5, 4, 3, 3, 9, 7, 4, 1, 9, 6, 5, 7, 0, 3, 6, 4, 5, 8, 0, 5, 5, 2, 8, 3, 7, 8, 4, 7, 5, 4, 6, 8, 9, 1, 4, 0, 2, 4, 0, 0, 3, 1, 5, 7, 3, 1, 5, 9, 4, 1, 5, 6, 3, 0, 7, 4, 8, 3, 2, 8, 4, 5, 2, 0, 3, 5, 1, 3, 3, 7, 2, 5, 4, 2, 8, 6, 6, 1, 1, 9, 3, 5, 1, 4, 2, 6, 6, 1, 5, 8, 3, 7, 4, 8, 9, 5, 0, 2, 8, 9, 3, 3, 5, 6, 2, 2, 0, 5, 5, 9, 3, 9, 1, 9, 6, 0, 6, 0, 8, 9, 2, 7, 3, 0, 4, 6, 0, 7, 5, 6, 7, 5, 1, 5, 7, 6, 9, 0, 1, 0, 3, 0, 3, 6, 9, 7, 0, 7, 8, 9, 6, 3, 8, 5, 5, 4, 1, 2, 8, 1, 4, 0, 3, 0, 0, 7, 1, 5, 3, 9, 7, 6, 1, 8, 6, 5, 8, 6, 7, 1, 5, 1, 1, 9, 5, 2, 0, 5, 6, 5, 0, 2, 3, 2, 6, 5, 4, 8, 4, 1, 5, 2, 9, 3, 4, 6, 4, 7, 2, 1, 9, 7, 6, 9, 4, 4, 1, 5, 2, 2, 1, 3, 6, 6, 6, 2, 7, 2, 2, 2, 0, 8, 3, 7, 7, 5, 1, 5, 3, 6, 7, 0, 5, 4, 1, 0, 0, 9, 8, 7, 5, 3, 2, 7, 4, 3, 1, 9, 0, 7, 0, 5, 6, 8, 9, 4, 0, 3, 1, 3, 8, 6, 4, 6, 3, 3, 2, 6, 8, 4, 9, 4, 1, 0, 7, 8, 8, 5, 4, 0, 0, 2, 6, 2, 1, 9, 0, 8, 5, 4, 9, 8, 9, 1, 7, 6, 4, 9, 3, 7, 3, 0, 6, 3, 7, 5, 4, 0, 2, 7, 4, 7, 4, 0, 6, 8, 2, 3, 9, 0, 9, 2, 1, 1, 2, 0, 6, 4, 6, 4, 8, 3, 4, 8, 3, 5, 6, 4, 9, 8, 4, 0, 6, 1, 2, 0, 9, 8, 9, 9, 7, 0, 9, 4, 3, 8, 0, 6, 7, 5, 1, 6, 6, 3, 4, 1, 2, 3, 4, 9, 0, 9, 7, 3, 6, 2, 4, 0, 4, 3, 4, 9, 9, 7, 0, 3, 0, 3, 9, 2, 4, 9, 9, 3, 5, 6, 9, 6, 4, 5, 5, 8, 3, 3, 5, 3, 4, 1, 5, 9, 0, 2, 5, 4, 1, 0, 2, 8, 1, 5, 7, 2, 6, 5, 9, 8, 7, 6, 3, 1, 0, 5, 4, 8, 3, 9, 8, 3, 7, 2, 8, 1, 8, 5, 2, 1, 7, 5, 6, 5, 8, 5, 9, 1, 3, 7, 3, 2, 7, 1, 1, 1, 3, 8, 7, 7, 8, 1, 1, 3, 7, 1, 1, 6, 6, 0, 0, 1, 6, 2, 7, 7, 5, 8, 0, 4, 9, 6, 6, 7, 7, 0, 2, 3, 7, 1, 9, 6, 7, 5, 1, 2, 1, 5, 9, 6, 5, 4, 5, 4, 6, 0, 1, 6, 6, 6, 7, 9, 5, 2, 9, 6, 9, 6, 7, 6, 8, 9, 5, 0, 4, 2, 6, 0, 4, 3, 6, 2, 4, 5, 5, 5, 2, 6, 8, 8, 0, 4, 1, 7, 6, 0, 7, 2, 4, 3, 0, 5, 0, 5, 4, 1, 5, 2, 0, 7, 3, 4, 6, 6, 3, 2, 5, 8, 5, 3, 8, 0, 5, 7, 6, 6, 3, 1, 4, 9, 8, 4, 9, 3, 5, 8, 8, 0, 1, 4, 6, 8, 4, 7, 5, 8, 3, 4, 9, 0, 7, 3, 9, 2, 1, 4, 9, 7, 0, 6, 0, 2, 7, 9, 5, 8, 3, 1, 7, 5, 2, 1, 2, 2, 0, 7, 7, 9, 1, 9, 3, 9, 0, 9, 5, 3, 3, 3, 9, 8, 4, 5, 7, 7, 2, 8, 5, 7, 2, 8, 9, 8, 6, 9, 6, 9, 6, 8, 2, 0, 7, 5, 0, 6, 2, 5, 8, 3, 9, 3, 1, 4, 1, 1, 2, 0, 7, 9, 8, 7, 3, 9, 8, 5, 0, 2, 1, 8, 9, 0, 7, 3, 4, 7, 2, 7, 9, 7, 6, 6, 3, 3, 4, 1, 8, 6, 7, 9, 8, 9, 6, 1, 3, 7, 5, 5, 4, 2, 7, 8, 0, 7, 2, 1, 0, 0, 3, 9, 2, 4, 9, 9, 9, 4, 1, 3, 7, 7, 3, 6, 7, 2, 3, 6, 0, 8, 2, 8, 4, 3, 1, 9, 2, 8, 7, 4, 7, 2, 5, 1, 7, 8, 0, 6, 6, 3, 7, 0, 9, 3, 7, 4, 6, 2, 1, 5, 8, 8, 3, 5, 3, 4, 5, 8, 0, 7, 5, 9, 6, 7, 5, 7, 7, 4, 0, 6, 1, 9, 4, 3, 8, 8, 0, 0, 2, 9, 0, 3, 8, 9, 0, 2, 8, 3, 2, 2, 9, 9, 8, 0, 7, 7, 1, 9, 8, 8, 0, 6, 0, 2, 4, 8, 5, 4, 9, 3, 8, 9, 8, 0, 2, 6, 8, 8, 4, 3, 0, 3, 4, 1, 9, 4, 6, 2, 8, 1, 9, 3, 6, 8, 5, 0, 5, 2, 0, 1, 3, 3, 8, 3, 3, 2, 3, 5, 5, 2, 3, 7, 7, 3, 8, 2, 2, 0, 6, 7, 3, 5, 0, 3, 1, 3, 7, 3, 0, 8, 7, 3, 1, 1, 6, 8, 7, 2, 6, 3, 4, 3, 8, 6, 1, 4, 8, 6, 1, 9, 7, 8, 7, 6, 5, 0, 3, 6, 8, 7, 0, 9, 7, 0, 8, 0, 4, 4, 6, 7, 5, 8, 8, 8, 6, 5, 3, 2, 4, 1, 1, 5, 2, 5, 1, 5, 1, 6, 5, 0, 1, 8, 7, 6, 8, 6, 1, 8, 5, 4, 2, 4, 1, 2, 4, 7, 5, 2, 9, 1, 4, 4, 4, 3, 3, 4, 5, 3, 0, 8, 0, 9, 5, 6, 4, 6, 8, 5, 6, 0, 2, 6, 5, 2, 8, 2, 6, 6, 9, 1, 7, 2, 4, 7, 8, 8, 3, 7, 8, 6, 0, 9, 9, 1, 1, 3, 6, 6, 2, 2, 8, 3, 9, 1, 0, 2, 9, 9, 0, 2, 3, 4, 4, 6, 1, 3, 4, 5, 3, 2, 4, 0, 9, 4, 1, 4, 8, 3, 0, 2, 4, 4, 1, 8, 2, 4, 7, 6, 8, 6, 5, 3, 9, 8, 9, 6, 0, 2, 7, 1, 0, 6, 3, 8, 9, 8, 6, 0, 0, 8, 1, 8, 3, 0, 1, 2, 2, 1, 8, 1, 9, 3, 9, 0, 3, 3, 3, 0, 1, 0, 3, 6, 1, 8, 1, 6, 9, 3, 5, 4, 8, 4, 8, 6, 4, 6, 9, 2, 3, 6, 4, 0, 5, 0, 4, 4, 2, 2, 9, 4, 3, 1, 5, 3, 8, 4, 8, 2, 6, 7, 6, 5, 0, 8, 1, 1, 7, 6, 4, 2, 1, 4, 1, 6, 3, 2, 0, 0, 7, 2, 2, 7, 9, 8, 4, 9, 0, 6, 1, 5, 4, 6, 4, 9, 1, 9, 8, 7, 0, 2, 9, 4, 7, 2, 1, 3, 0, 6, 9, 2, 5, 0, 9, 0, 9, 5, 7, 1, 0, 6, 9, 6, 1, 5, 1, 7, 1, 7, 4, 7, 0, 3, 7, 7, 5, 6, 9, 6, 5, 5, 1, 7, 2, 6, 5, 0, 1, 9, 1, 4, 9, 3, 1, 7, 2, 7, 2, 7, 2, 8, 1, 3, 5, 9, 8, 3, 9, 5, 9, 1, 0, 9, 7, 9, 9, 8, 6, 7, 7, 5, 4, 6, 8, 8, 6, 7, 1, 3, 0, 5, 6, 7, 3, 1, 9, 3, 1, 7, 4, 1, 5, 9, 5, 8, 0, 2, 6, 6, 9, 9, 7, 2, 7, 4, 2, 3, 0, 6, 8, 1, 1, 2, 2, 4, 8, 9, 0, 2, 4, 7, 6, 4, 1, 3, 3, 3, 2, 3, 1, 8, 5, 3, 3, 7, 5, 6, 0, 4, 2, 8, 1, 3, 6, 1, 0, 7, 4, 4, 0, 3, 2, 8, 3, 3, 0, 9, 9, 4, 7, 9, 1, 7, 8, 4, 7, 8, 3, 6, 0, 4, 2, 0, 6, 9, 8, 3, 5, 5, 5, 9, 3, 5, 9, 4, 6, 2, 8, 3, 5, 2, 4, 9, 6, 5, 9, 7, 0, 1, 9, 4, 9, 8, 1, 0, 1, 3, 6, 4, 8, 4, 9, 1, 1, 5, 0, 4, 2, 4, 7, 7, 1, 2, 2, 6, 4, 3, 5, 6, 9, 9, 2, 7, 2, 8, 0, 1, 9, 3, 7, 1, 8, 8, 2, 8, 5, 2, 7, 4, 1, 2, 9, 9, 5, 6, 1, 4, 9, 9, 7, 5, 1, 2, 1, 7, 3, 0, 5, 2, 5, 6, 4, 4, 9, 6, 2, 9, 6, 6, 5, 0, 1, 1, 1, 0, 1, 5, 6, 9, 1, 8, 7, 4, 0, 1, 3, 8, 0, 5, 2, 3, 4, 8, 2, 2, 0, 9, 7, 2, 0, 3, 7, 1, 0, 3, 0, 0, 7, 4, 8, 1, 8, 7, 0, 8, 9, 9, 0, 3, 4, 3, 0, 2, 6, 2, 5, 3, 2, 1, 4, 1, 0, 1, 5, 6, 3, 0, 7, 8, 4, 1, 4, 5, 6, 9, 2, 5, 5, 5, 4, 6, 9, 1, 1, 1, 7, 4, 3, 2, 6, 5, 2, 6, 7, 7, 7, 5, 1, 5, 6, 8, 7, 1, 7, 9, 7, 2, 9, 6, 3, 6, 0, 0, 6, 5, 9, 4, 6, 4, 9, 5, 5, 0, 9, 3, 6, 6, 7, 2, 7, 1, 6, 7, 8, 1, 7, 7, 8, 4, 8, 2, 4, 8, 5, 5, 6, 7, 1, 9, 9, 5, 7, 3, 9, 2, 1, 2, 8, 1, 3, 6, 8, 3, 3, 8, 7, 0, 1, 6, 0, 9, 4, 0, 7, 7, 2, 7, 2, 9, 3, 3, 2, 2, 5, 8, 6, 0, 2, 2, 3, 3, 2, 4, 5, 1, 9, 0, 0, 5, 4, 7, 2, 4, 1, 2, 8, 6, 4, 3, 9, 0, 8, 6, 7, 1, 5, 5, 2, 7, 0, 4, 6, 1, 2, 5, 4, 5, 5, 3, 7, 3, 1, 0, 2, 6, 0, 1, 8, 4, 3, 1, 5, 7, 2, 0, 1, 1, 7, 9, 7, 2, 0, 6, 5, 6, 2, 9, 8, 4, 9, 9, 4, 2, 4, 3, 6, 5, 2, 8, 7, 9, 7, 0, 6, 1, 5, 2, 5, 2, 0, 9, 2, 0, 9, 7, 1, 0, 8, 1, 1, 8, 0, 4, 6, 4, 6, 3, 3, 9, 7, 0, 1, 0, 0, 1, 7, 7, 3, 8, 1, 5, 4, 0, 4, 4, 8, 8, 1, 7, 0, 7, 5, 7, 0, 8, 7, 8, 0, 1, 9, 2, 0, 0, 4, 7, 8, 6, 0, 5, 5, 6, 1, 9, 7, 8, 3, 4, 3, 3, 8, 4, 6, 7, 7, 7, 9, 9, 0, 4, 4, 5, 1, 6, 1, 6, 6, 1, 4, 6, 0, 4, 0, 0, 4, 4, 2, 4, 3, 5, 9, 8, 1, 2, 2, 6, 5, 3, 7, 2, 1, 6, 5, 0, 1, 2, 7, 4, 6, 7, 5, 3, 4, 3, 5, 4, 7, 5, 6, 8, 7, 8, 7, 8, 8, 4, 3, 5, 3, 2, 8, 8, 4, 9, 5, 6, 5, 0, 4, 6, 6, 3, 9, 6, 4, 9, 6, 3, 0, 7, 9, 3, 2, 8, 8, 0, 7, 6, 3, 7, 2, 6, 2, 5, 7, 1, 8, 1, 5, 6, 1, 5, 0, 2, 7, 7, 7, 6, 3, 5, 6, 4, 4, 0, 8, 5, 0, 4, 4, 2, 7, 9, 1, 5, 7, 0, 4, 2, 7, 6, 7, 6, 8, 2, 1, 5, 5, 7, 3, 3, 1, 3, 0, 3, 0, 3, 6, 1, 9, 2, 5, 3, 1, 8, 1, 9, 2, 6, 1, 7, 4, 6, 0, 1, 4, 3, 0, 1, 3, 6, 1, 2, 9, 1, 0, 1, 8, 6, 9, 8, 7, 3, 0, 7, 4, 0, 2, 5, 3, 8, 8, 3, 2, 8, 1, 1, 1, 8, 2, 3, 5, 4, 8, 2, 9, 4, 1, 2, 2, 8, 8, 6, 9, 9, 5, 7, 1, 1, 9, 7, 7, 0, 7, 1, 0, 4, 8, 4, 7, 3, 8, 8, 7, 7, 8, 8, 4, 6, 0, 4, 1, 0, 6, 6, 4, 3, 7, 4, 7, 6, 2, 5, 4, 1, 8, 2, 0, 2, 9, 9, 7, 4, 6, 9, 2, 5, 4, 0, 5, 9, 2, 0, 7, 3, 7, 5, 1, 0, 6, 3, 6, 7, 9, 9, 2, 8, 1, 2, 0, 7, 8, 4, 9, 8, 7, 1, 4, 1, 5, 0, 4, 4, 1, 4, 4, 2, 1, 5, 1, 8, 5, 5, 5, 5, 3, 0, 1, 4, 0, 0, 7, 9, 2, 5, 7, 1, 0, 2, 0, 7, 9, 8, 9, 8, 8, 6, 9, 5, 2, 6, 1, 0, 4, 4, 1, 6, 1, 3, 7, 1, 0, 6, 9, 0, 4, 8, 3, 5, 9, 4, 6, 4, 3, 3, 3, 3, 6, 3, 5, 0, 0, 2, 9, 9, 9, 8, 4, 4, 6, 1, 3, 1, 4, 0, 3, 8, 4, 2, 9, 6, 4, 2, 5, 2, 9, 0, 3, 6, 8, 3, 5, 1, 5, 4, 9, 8, 4, 0, 1, 6, 2, 3, 6, 2, 0, 3, 8, 1, 5, 2, 4, 7, 7, 9, 6, 8, 5, 6, 7, 1, 9, 6, 1, 7, 0, 6, 2, 4, 1, 1, 3, 2, 7, 2, 9, 9, 0, 9, 6, 0, 8, 5, 5, 2, 6, 4, 1, 4, 6, 0, 9, 9, 8, 7, 3, 1, 2, 6, 2, 1, 7, 1, 3, 9, 0, 8, 0, 1, 0, 1, 5, 3, 5, 0, 0, 5, 3, 9, 4, 0, 3, 0, 5, 0, 9, 0, 1, 2, 4, 8, 5, 7, 5, 7, 6, 5, 2, 1, 6, 4, 4, 2, 9, 2, 1, 3, 7, 0, 3, 9, 7, 7, 8, 0, 9, 2, 3, 9, 8, 8, 8, 8, 4, 5, 6, 3, 4, 4, 0, 5, 3, 8, 9, 1, 5, 2, 2, 6, 1, 4, 9, 8, 9, 4, 6, 9, 9, 0, 0, 4, 8, 8, 7, 5, 1, 8, 9, 0, 1, 6, 6, 0, 4, 3, 8, 7, 8, 5, 1, 2, 4, 6, 6, 7, 5, 1, 0, 3, 5, 1, 3, 5, 7, 4, 5, 0, 6, 6, 6, 0, 7, 7, 4, 9, 5, 0, 8, 7, 5, 0, 7, 9, 7, 9, 9, 0, 4, 6, 3, 7, 3, 1, 1, 2, 4, 1, 6, 9, 7, 4, 0, 6, 7, 8, 4, 8, 8, 4, 1, 3, 7, 7, 9, 0, 1, 0, 5, 1, 8, 5, 4, 7, 0, 9, 5, 1, 8, 2, 3, 5, 9, 3, 4, 9, 6, 8, 9, 5, 1, 2, 5, 0, 0, 5, 6, 3, 3, 0, 8, 8, 0, 3, 0, 4, 3, 4, 0, 5, 9, 8, 5, 8, 5, 7, 4, 9, 5, 9, 4, 0, 1, 2, 2, 9, 9, 8, 2, 3, 8, 8, 2, 9, 0, 7, 0, 1, 6, 8, 5, 2, 6, 1, 3, 9, 1, 0, 5, 6, 1, 8, 2, 9, 0, 7, 6, 6, 8, 9, 6, 6, 4, 1, 5, 6, 9, 4, 2, 4, 2, 8, 9, 1, 3, 8, 4, 7, 5, 8, 9, 4, 2, 2, 8, 2, 1, 0, 1, 5, 2, 7, 0, 1, 2, 4, 9, 8, 2, 0, 4, 9, 3, 0, 2, 9, 6, 6, 3, 6, 5, 9, 1, 1, 7, 0, 1, 6, 0, 2, 4, 7, 1, 9, 5, 4, 1, 1, 2, 2, 5, 7, 1, 7, 1, 3, 0, 9, 8, 8, 5, 1, 5, 2, 4, 4, 1, 3, 5, 8, 3, 4, 9, 3, 6, 5, 1, 0, 6, 4, 6, 8, 1, 4, 0, 6, 3, 0, 2, 5, 1, 3, 4, 8, 6, 4, 8, 6, 4, 2, 6, 5, 4, 1, 1, 2, 7, 8, 1, 0, 7, 5, 9, 8, 9, 7, 0, 3, 0, 6, 1, 6, 6, 7, 9, 6, 4, 3, 9, 5, 4, 4, 8, 5, 1, 3, 7, 8, 5, 5, 9, 8, 0, 9, 9, 6, 2, 5, 6, 7, 1, 8, 3, 1, 6, 3, 3, 3, 6, 2, 1, 6, 2, 1, 5, 0, 6, 8, 3, 3, 7, 5, 7, 3, 5, 9, 1, 4, 5, 6, 1, 0, 2, 3, 5, 6, 8, 4, 6, 9, 5, 6, 7, 0, 0, 7, 3, 6, 9, 9, 4, 6, 5, 9, 5, 2, 7, 1, 7, 1, 4, 6, 1, 9, 0, 2, 5, 6, 5, 8, 1, 5, 6, 7, 2, 7, 8, 7, 8, 4, 5, 0, 4, 8, 6, 1, 8, 5, 7]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.zeros((len(labels), num_classes))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    one_hot_encoding[np.arange(len(labels)), labels] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label'].tolist()\n",
    "print(labels)\n",
    "# Labels --> one hot\n",
    "one_hot_encoding = labels_to_one_hot(labels)\n",
    "print(one_hot_encoding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAa8ElEQVR4nO3df3BU9f3v8dfyIwtosmkIySYl0AACLT/itwhpLkqxZEjSe7mgTC/+6HzBcXDA4BRSqzcdFVFn0uKM9auTwnSmhTojoM4IfPVaOhhM+FoTOkQYBmtzSW4ssZCg3Ek2BAmRfO4fXLfflQR6wm7e2eX5mDkzZPd8sm+PR56e7HLwOeecAAAYZMOsBwAA3JgIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHCeoCv6+3t1alTp5ScnCyfz2c9DgDAI+ecOjs7lZ2drWHD+r/OGXIBOnXqlHJycqzHAABcp5aWFo0fP77f54dcgJKTkyVJt+uHGqGRxtMAALz6Uj16X++Efz/vT8wCVFlZqeeff16tra3Ky8vTyy+/rHnz5l1z3Vc/dhuhkRrhI0AAEHf+/x1Gr/U2Skw+hPDaa6+prKxMGzdu1Icffqi8vDwVFRXpzJkzsXg5AEAcikmAXnjhBa1evVoPPPCAvvOd72jr1q0aM2aMfve738Xi5QAAcSjqAbp48aLq6+tVWFj4jxcZNkyFhYWqra29Yv/u7m6FQqGIDQCQ+KIeoM8//1yXLl1SZmZmxOOZmZlqbW29Yv+KigoFAoHwxifgAODGYP4HUcvLy9XR0RHeWlparEcCAAyCqH8KLj09XcOHD1dbW1vE421tbQoGg1fs7/f75ff7oz0GAGCIi/oVUFJSkubMmaOqqqrwY729vaqqqlJBQUG0Xw4AEKdi8ueAysrKtHLlSt12222aN2+eXnzxRXV1demBBx6IxcsBAOJQTAK0YsUKffbZZ3rqqafU2tqqW2+9Vfv27bvigwkAgBuXzznnrIf4z0KhkAKBgBZqKXdCAIA49KXrUbX2qqOjQykpKf3uZ/4pOADAjYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcJ6AOBaml79F89rGu/cFoNJomfyrjWe10wpq4vBJIAdroAAACYIEADARNQD9PTTT8vn80Vs06dPj/bLAADiXEzeA5oxY4befffdf7zICN5qAgBEikkZRowYoWAwGItvDQBIEDF5D+jEiRPKzs7WpEmTdP/99+vkyZP97tvd3a1QKBSxAQASX9QDlJ+fr+3bt2vfvn3asmWLmpubdccdd6izs7PP/SsqKhQIBMJbTk5OtEcCAAxBUQ9QSUmJfvSjH2n27NkqKirSO++8o/b2dr3++ut97l9eXq6Ojo7w1tLSEu2RAABDUMw/HZCamqqpU6eqsbGxz+f9fr/8fn+sxwAADDEx/3NA586dU1NTk7KysmL9UgCAOBL1AD366KOqqanRJ598og8++EB33XWXhg8frnvvvTfaLwUAiGNR/xHcp59+qnvvvVdnz57VuHHjdPvtt6uurk7jxo2L9ksBAOJY1AO0a9euaH9LIOGU3HHE85r/9Zu5MZikb7f8vsfzGt+fjkZ/ECQ07gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI+V9IB1wv57yvqe++OKDX+rfWwgGtGwx3zGoYtNeqXzDT85qcCzM8r3H1H3leg8TBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDdsDHk+n/c1//P/LB/Qa438H10DWpdobnrlM89rGqYEPK+Z+qDnJUggXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSmGPOe8r1k/cf+AXuvRrT/yvGbiL3o9r3H1H3leM5hGjfB+Y9GN8//d85qX/v1Oz2vG/fcGz2swNHEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakSEj/dcyFAa2blb/F85p/zdzgeY3f84qhb1XKGe9rbnvN85oi3ep5DYYmroAAACYIEADAhOcAHTx4UEuWLFF2drZ8Pp/27NkT8bxzTk899ZSysrI0evRoFRYW6sSJE9GaFwCQIDwHqKurS3l5eaqsrOzz+c2bN+ull17S1q1bdejQId10000qKirShQsD+5k8ACAxef4QQklJiUpKSvp8zjmnF198UU888YSWLl0qSXrllVeUmZmpPXv26J577rm+aQEACSOq7wE1NzertbVVhYWF4ccCgYDy8/NVW1vb55ru7m6FQqGIDQCQ+KIaoNbWVklSZmZmxOOZmZnh576uoqJCgUAgvOXk5ERzJADAEGX+Kbjy8nJ1dHSEt5aWFuuRAACDIKoBCgaDkqS2traIx9va2sLPfZ3f71dKSkrEBgBIfFENUG5uroLBoKqqqsKPhUIhHTp0SAUFBdF8KQBAnPP8Kbhz586psbEx/HVzc7OOHj2qtLQ0TZgwQevXr9dzzz2nW265Rbm5uXryySeVnZ2tZcuWRXNuAECc8xygw4cP68477wx/XVZWJklauXKltm/frscee0xdXV166KGH1N7erttvv1379u3TqFGjojc1ACDueQ7QwoUL5Zzr93mfz6dnnnlGzzzzzHUNBnzF5/O+5nzvxQG91idf3ux5je9S//89AOif+afgAAA3JgIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwfDdsYLBd5ebr/frJ3++89k59+N/PzfC85qb6Js9rLnleASQeroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBSD6pNnCzyvcWe93430z/V5ntdIUvCtDzyv4caiwMBwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpBhUDQ9u8bxmxssPe14T/JX3m4ri+nx88bznNR98MSkGkyBecAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqQAouL+Yw94XpOxaSC/BX00gDUYirgCAgCYIEAAABOeA3Tw4EEtWbJE2dnZ8vl82rNnT8Tzq1atks/ni9iKi4ujNS8AIEF4DlBXV5fy8vJUWVnZ7z7FxcU6ffp0eNu5c+d1DQkASDye3wEsKSlRSUnJVffx+/0KBoMDHgoAkPhi8h5QdXW1MjIyNG3aNK1du1Znz57td9/u7m6FQqGIDQCQ+KIeoOLiYr3yyiuqqqrSL3/5S9XU1KikpESXLl3qc/+KigoFAoHwlpOTE+2RAABDUNT/HNA999wT/vWsWbM0e/ZsTZ48WdXV1Vq0aNEV+5eXl6usrCz8dSgUIkIAcAOI+cewJ02apPT0dDU2Nvb5vN/vV0pKSsQGAEh8MQ/Qp59+qrNnzyorKyvWLwUAiCOefwR37ty5iKuZ5uZmHT16VGlpaUpLS9OmTZu0fPlyBYNBNTU16bHHHtOUKVNUVFQU1cEBAPHNc4AOHz6sO++8M/z1V+/frFy5Ulu2bNGxY8f0+9//Xu3t7crOztbixYv17LPPyu/3R29qAEDc8xyghQsXyjnX7/N//OMfr2sgAPEp1DnG85px9UdiMAniBfeCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImo/5XcwNX8698WeF5z06n+775+IxmePtbzmq6CyQN6rWmpH3le8/fPUgf0WrhxcQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqQYVJ//N++nXNq5Dz2vScTbl34xJ9fzmmf/7TcDeq3bki56XjO7ceqAXgs3Lq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUg+rS2f9rPULccsN9ntd8a8S5Ab3WjH3rPa/J3ZWIt4BFLHEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakGFRnHv4vntdk1nZ4XuOOfOR5zWBy82/1vKalcLjnNWN83m9gKknpH4z0vGbku7UDei3cuLgCAgCYIEAAABOeAlRRUaG5c+cqOTlZGRkZWrZsmRoaGiL2uXDhgkpLSzV27FjdfPPNWr58udra2qI6NAAg/nkKUE1NjUpLS1VXV6f9+/erp6dHixcvVldXV3ifDRs26K233tIbb7yhmpoanTp1SnfffXfUBwcAxDdPH0LYt29fxNfbt29XRkaG6uvrtWDBAnV0dOi3v/2tduzYoR/84AeSpG3btunb3/626urq9L3vfS96kwMA4tp1vQfU0XH500lpaWmSpPr6evX09KiwsDC8z/Tp0zVhwgTV1vb9CZnu7m6FQqGIDQCQ+AYcoN7eXq1fv17z58/XzJkzJUmtra1KSkpSampqxL6ZmZlqbW3t8/tUVFQoEAiEt5ycnIGOBACIIwMOUGlpqY4fP65du3Zd1wDl5eXq6OgIby0tLdf1/QAA8WFAfxB13bp1evvtt3Xw4EGNHz8+/HgwGNTFixfV3t4ecRXU1tamYDDY5/fy+/3y+/0DGQMAEMc8XQE557Ru3Trt3r1bBw4cUG5ubsTzc+bM0ciRI1VVVRV+rKGhQSdPnlRBQUF0JgYAJARPV0ClpaXasWOH9u7dq+Tk5PD7OoFAQKNHj1YgENCDDz6osrIypaWlKSUlRY888ogKCgr4BBwAIIKnAG3ZskWStHDhwojHt23bplWrVkmSfvWrX2nYsGFavny5uru7VVRUpF//+tdRGRYAkDg8Bcg5d819Ro0apcrKSlVWVg54KCSuI094/5+Rb//mYc9rck+meV4zmP56n/f3PT9e9rLnNW2Xrv3fbF+GfTmgZYAn3AsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJgb0N6ICg+nRFW96XlNTNDUGk0TP82N3el6zpf0Wz2tee67Y8xpJSv+Pk57XcANteMUVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRYsh7MNA6KGsG07q/53tec2DvHM9rJu7+0PMaSfrywoUBrQO84AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUgBA3/4j3/xvGbKcx94XtPreQUweLgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSDKqi7FutRxgSpqjOegTAHFdAAAATBAgAYMJTgCoqKjR37lwlJycrIyNDy5YtU0NDQ8Q+CxculM/ni9jWrFkT1aEBAPHPU4BqampUWlqquro67d+/Xz09PVq8eLG6uroi9lu9erVOnz4d3jZv3hzVoQEA8c/ThxD27dsX8fX27duVkZGh+vp6LViwIPz4mDFjFAwGozMhACAhXdd7QB0dHZKktLS0iMdfffVVpaena+bMmSovL9f58+f7/R7d3d0KhUIRGwAg8Q34Y9i9vb1av3695s+fr5kzZ4Yfv++++zRx4kRlZ2fr2LFjevzxx9XQ0KA333yzz+9TUVGhTZs2DXQMAECc8jnn3EAWrl27Vn/4wx/0/vvva/z48f3ud+DAAS1atEiNjY2aPHnyFc93d3eru7s7/HUoFFJOTo4WaqlG+EYOZDQAgKEvXY+qtVcdHR1KSUnpd78BXQGtW7dOb7/9tg4ePHjV+EhSfn6+JPUbIL/fL7/fP5AxAABxzFOAnHN65JFHtHv3blVXVys3N/eaa44ePSpJysrKGtCAAIDE5ClApaWl2rFjh/bu3avk5GS1trZKkgKBgEaPHq2mpibt2LFDP/zhDzV27FgdO3ZMGzZs0IIFCzR79uyY/AMAAOKTp/eAfD5fn49v27ZNq1atUktLi3784x/r+PHj6urqUk5Oju666y498cQTV/054H8WCoUUCAR4DwgA4lRM3gO6VqtycnJUU1Pj5VsCAG5Q3AsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBihPUAX+eckyR9qR7JGQ8DAPDsS/VI+sfv5/0ZcgHq7OyUJL2vd4wnAQBcj87OTgUCgX6f97lrJWqQ9fb26tSpU0pOTpbP54t4LhQKKScnRy0tLUpJSTGa0B7H4TKOw2Uch8s4DpcNhePgnFNnZ6eys7M1bFj/7/QMuSugYcOGafz48VfdJyUl5YY+wb7CcbiM43AZx+EyjsNl1sfhalc+X+FDCAAAEwQIAGAirgLk9/u1ceNG+f1+61FMcRwu4zhcxnG4jONwWTwdhyH3IQQAwI0hrq6AAACJgwABAEwQIACACQIEADARNwGqrKzUt771LY0aNUr5+fn685//bD3SoHv66afl8/kitunTp1uPFXMHDx7UkiVLlJ2dLZ/Ppz179kQ875zTU089paysLI0ePVqFhYU6ceKEzbAxdK3jsGrVqivOj+LiYpthY6SiokJz585VcnKyMjIytGzZMjU0NETsc+HCBZWWlmrs2LG6+eabtXz5crW1tRlNHBv/zHFYuHDhFefDmjVrjCbuW1wE6LXXXlNZWZk2btyoDz/8UHl5eSoqKtKZM2esRxt0M2bM0OnTp8Pb+++/bz1SzHV1dSkvL0+VlZV9Pr9582a99NJL2rp1qw4dOqSbbrpJRUVFunDhwiBPGlvXOg6SVFxcHHF+7Ny5cxAnjL2amhqVlpaqrq5O+/fvV09PjxYvXqyurq7wPhs2bNBbb72lN954QzU1NTp16pTuvvtuw6mj7585DpK0evXqiPNh8+bNRhP3w8WBefPmudLS0vDXly5dctnZ2a6iosJwqsG3ceNGl5eXZz2GKUlu9+7d4a97e3tdMBh0zz//fPix9vZ25/f73c6dOw0mHBxfPw7OObdy5Uq3dOlSk3msnDlzxklyNTU1zrnL/+5Hjhzp3njjjfA+H3/8sZPkamtrrcaMua8fB+ec+/73v+9+8pOf2A31TxjyV0AXL15UfX29CgsLw48NGzZMhYWFqq2tNZzMxokTJ5Sdna1Jkybp/vvv18mTJ61HMtXc3KzW1taI8yMQCCg/P/+GPD+qq6uVkZGhadOmae3atTp79qz1SDHV0dEhSUpLS5Mk1dfXq6enJ+J8mD59uiZMmJDQ58PXj8NXXn31VaWnp2vmzJkqLy/X+fPnLcbr15C7GenXff7557p06ZIyMzMjHs/MzNRf//pXo6ls5Ofna/v27Zo2bZpOnz6tTZs26Y477tDx48eVnJxsPZ6J1tZWSerz/PjquRtFcXGx7r77buXm5qqpqUk///nPVVJSotraWg0fPtx6vKjr7e3V+vXrNX/+fM2cOVPS5fMhKSlJqampEfsm8vnQ13GQpPvuu08TJ05Udna2jh07pscff1wNDQ168803DaeNNOQDhH8oKSkJ/3r27NnKz8/XxIkT9frrr+vBBx80nAxDwT333BP+9axZszR79mxNnjxZ1dXVWrRokeFksVFaWqrjx4/fEO+DXk1/x+Ghhx4K/3rWrFnKysrSokWL1NTUpMmTJw/2mH0a8j+CS09P1/Dhw6/4FEtbW5uCwaDRVENDamqqpk6dqsbGRutRzHx1DnB+XGnSpElKT09PyPNj3bp1evvtt/Xee+9F/PUtwWBQFy9eVHt7e8T+iXo+9Hcc+pKfny9JQ+p8GPIBSkpK0pw5c1RVVRV+rLe3V1VVVSooKDCczN65c+fU1NSkrKws61HM5ObmKhgMRpwfoVBIhw4duuHPj08//VRnz55NqPPDOad169Zp9+7dOnDggHJzcyOenzNnjkaOHBlxPjQ0NOjkyZMJdT5c6zj05ejRo5I0tM4H609B/DN27drl/H6/2759u/vLX/7iHnroIZeamupaW1utRxtUP/3pT111dbVrbm52f/rTn1xhYaFLT093Z86csR4tpjo7O92RI0fckSNHnCT3wgsvuCNHjri//e1vzjnnfvGLX7jU1FS3d+9ed+zYMbd06VKXm5vrvvjiC+PJo+tqx6Gzs9M9+uijrra21jU3N7t3333Xffe733W33HKLu3DhgvXoUbN27VoXCARcdXW1O336dHg7f/58eJ81a9a4CRMmuAMHDrjDhw+7goICV1BQYDh19F3rODQ2NrpnnnnGHT582DU3N7u9e/e6SZMmuQULFhhPHikuAuSccy+//LKbMGGCS0pKcvPmzXN1dXXWIw26FStWuKysLJeUlOS++c1vuhUrVrjGxkbrsWLuvffec5Ku2FauXOmcu/xR7CeffNJlZmY6v9/vFi1a5BoaGmyHjoGrHYfz58+7xYsXu3HjxrmRI0e6iRMnutWrVyfc/6T19c8vyW3bti28zxdffOEefvhh941vfMONGTPG3XXXXe706dN2Q8fAtY7DyZMn3YIFC1xaWprz+/1uypQp7mc/+5nr6OiwHfxr+OsYAAAmhvx7QACAxESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmPh/Qz52Kf2sv+IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize, and pixel entries range from 0 to 255\n",
    "# # First 10 cols are targets (ytrain/ytest) and the rest is input data\n",
    "# X_train = np.transpose(data_train.iloc[:, 11:].values / 255)\n",
    "# y_train = np.transpose(data_train.iloc[:, :10].values)\n",
    "# X_test = np.transpose(data_test.iloc[:, 11:].values / 255)\n",
    "# y_test = np.transpose(data_test.iloc[:, :10].values)\n",
    "# X_train_reshape = np.zeros((X_train.shape[1],1,28,28))\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     temp = X_train[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_train_reshape[i,0,:,:] = temp\n",
    "    \n",
    "# X_train= X_train_reshape  \n",
    "\n",
    "# X_test_reshape = np.zeros((X_test.shape[1],1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape the input vectors to 28X28 NumPy arrays\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# for i in range(X_test.shape[1]):\n",
    "#     temp = X_test[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_test_reshape[i,0,:,:] = temp\n",
    "\n",
    "# X_test= X_test_reshape\n",
    "\n",
    "# conv1 = np.random.randn(2,1,5,5) * np.sqrt(1. / 5)\n",
    "\n",
    "# stride = 1\n",
    "# filter_h = conv1.shape[2]\n",
    "# filter_w = conv1.shape[3]\n",
    "# new_channels = conv1.shape[0]\n",
    "# ## Get resultant Width and Height of Image\n",
    "\n",
    "# image_data = X_train\n",
    "# result_h = int(((image_data.shape[2]-filter_h)/stride) + 1)\n",
    "# result_w = int(((image_data.shape[3]-filter_w)/stride) + 1)\n",
    "\n",
    "# ## Out 0 matrix\n",
    "# result_conv1 = np.random.rand(image_data.shape[0],new_channels,result_h,result_w)\n",
    "\n",
    "# # Iterate over each image in the dataset\n",
    "# for image_position in range(image_data.shape[0]):\n",
    "#     image_selected = image_data[image_position,:,:,:]\n",
    "    \n",
    "#     # Each filter in conv layer\n",
    "#     for filter_position in range(conv1.shape[0]):\n",
    "#         filter_selected = conv1[filter_position,:,:,:]\n",
    "        \n",
    "#         # Vertical slide across the image\n",
    "#         for i in range(0, image_selected.shape[1], stride):\n",
    "#             # Vertical slice matching filter height\n",
    "#             image_rectangle = image_selected[:,i:i+filter_h,:]\n",
    "#             # If its height is less than the filter's height skip\n",
    "#             if image_rectangle.shape[1] < filter_h:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide across the vertical slice\n",
    "#             for j in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice matching the filter's width\n",
    "#                 image_portion = image_rectangle[:,:,j:j+filter_w]\n",
    "#                 # Skip if width less than the filter's width\n",
    "#                 if image_portion.shape[2] < filter_w:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Apply filter to selected image portion\n",
    "#                 convolution_result = np.multiply(filter_selected, image_portion)\n",
    "#                 # Sum convolution output and store it in the result array\n",
    "#                 result_conv1[image_position, filter_position, i, j] = np.sum(convolution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Pad around images to preserve size after convolution\n",
    "    X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    X = X_padded\n",
    "    \n",
    "    # Dims of the output post-filter\n",
    "    new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "    new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "    c = 0  # Curr column in the output array\n",
    "    \n",
    "    # Iterate over each image in the batch\n",
    "    for position in range(X.shape[0]):\n",
    "        # Current image\n",
    "        image_position = X[position, :, :, :]\n",
    "        \n",
    "        # Vertical slide down the image, with \"stride\" steps \n",
    "        for height in range(0, image_position.shape[1], stride):\n",
    "            # Select a horizontal slice that matches filter height\n",
    "            image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "            # Next iteration if slice's height < than filter height\n",
    "            if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "                continue\n",
    "            \n",
    "            # Horizontal slide down the image, with \"stride\" steps \n",
    "            for width in range(0, image_rectangle.shape[2], stride):\n",
    "                # Slice portion that matches the filter width\n",
    "                image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "                # If portion's width < filter width\n",
    "                if image_square.shape[2] < conv1.shape[3]:\n",
    "                    continue\n",
    "                \n",
    "                # Flatten and store \n",
    "                im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "                c += 1\n",
    " \n",
    "    return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.37106565  1.12768462 -0.8048434  -0.79017783  0.18209459]\n",
      "   [ 0.16708235  0.04141345 -0.20079704 -0.55870287  0.07777834]\n",
      "   [ 0.54922007  2.22093474  0.00437107 -0.71912252 -0.5679382 ]\n",
      "   [-0.0576312   0.89277904 -0.76653975  0.11664642  0.65422096]\n",
      "   [ 0.55353645  0.27286695 -0.38427533  1.39966648  0.99610059]]]\n",
      "\n",
      "\n",
      " [[[ 1.46106177 -1.78412576 -1.84578162 -2.57067866 -0.09580785]\n",
      "   [ 1.04962546 -1.3690686   2.14921053  0.80195868 -0.88701769]\n",
      "   [ 2.01644304 -0.07624258  2.66633901  1.05161732 -0.9089157 ]\n",
      "   [-0.59088509 -0.36679355 -1.10250079  1.76115281 -1.4630214 ]\n",
      "   [ 0.45024742  0.51089144  0.19737229  1.0684736   1.14258941]]]]\n",
      "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])]\n",
      "(10, 2, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "X_batch = data_array[0:10,:,:,:]\n",
    "conv1 = np.random.randn(2,1,5,5)\n",
    "print(conv1)\n",
    "X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "X_conv = conv1_reshaped@X_im2col\n",
    "print(np.hsplit(X_conv,X_batch.shape[0]))\n",
    "X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = test_array[:, i:i + 1, :, :].ravel()\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.64882061 0.03386654 0.1268834  ... 0.81906949 0.87509184\n",
      "    0.84731556]\n",
      "   [0.95906235 0.30429289 0.21433463 ... 0.54665622 0.12740287\n",
      "    0.58345335]\n",
      "   [0.14547732 0.6616917  0.65786608 ... 0.31980889 0.187178\n",
      "    0.2713972 ]\n",
      "   ...\n",
      "   [0.60775909 0.7261934  0.86259315 ... 0.53781696 0.42534793\n",
      "    0.10330748]\n",
      "   [0.2555859  0.68694946 0.06395592 ... 0.59652289 0.16077657\n",
      "    0.94887431]\n",
      "   [0.98569527 0.29118199 0.15885513 ... 0.63245839 0.91273236\n",
      "    0.73242894]]\n",
      "\n",
      "  [[0.51778369 0.12284925 0.59438613 ... 0.01640615 0.32659538\n",
      "    0.85737164]\n",
      "   [0.10866608 0.16783224 0.24755022 ... 0.12969668 0.3372252\n",
      "    0.08904974]\n",
      "   [0.64660135 0.39320297 0.30787681 ... 0.82491569 0.34993619\n",
      "    0.44058275]\n",
      "   ...\n",
      "   [0.27395864 0.1424815  0.78050104 ... 0.86635183 0.40679156\n",
      "    0.53266775]\n",
      "   [0.17119082 0.0509628  0.55713184 ... 0.4955865  0.00420018\n",
      "    0.95614182]\n",
      "   [0.20751968 0.66358463 0.2365303  ... 0.60663248 0.81781548\n",
      "    0.9981188 ]]]\n",
      "\n",
      "\n",
      " [[[0.16227483 0.38825004 0.72465528 ... 0.11733414 0.01253893\n",
      "    0.61904176]\n",
      "   [0.96869209 0.89856441 0.16328763 ... 0.07370265 0.77236736\n",
      "    0.05605492]\n",
      "   [0.30984214 0.91346751 0.76878719 ... 0.07818186 0.3573494\n",
      "    0.24758201]\n",
      "   ...\n",
      "   [0.64282661 0.15172389 0.88132237 ... 0.30924955 0.63212693\n",
      "    0.6191007 ]\n",
      "   [0.07999775 0.77541931 0.61718874 ... 0.99395047 0.52408597\n",
      "    0.85883528]\n",
      "   [0.61373511 0.54227564 0.45214096 ... 0.09893484 0.17149659\n",
      "    0.50286311]]\n",
      "\n",
      "  [[0.09582466 0.79776541 0.66385211 ... 0.76309002 0.41240101\n",
      "    0.58902335]\n",
      "   [0.23694515 0.60506788 0.23178153 ... 0.16408487 0.18334832\n",
      "    0.56403562]\n",
      "   [0.34476157 0.59719918 0.86686659 ... 0.97801043 0.53567965\n",
      "    0.94142117]\n",
      "   ...\n",
      "   [0.03880545 0.26946813 0.37593275 ... 0.74164219 0.99284952\n",
      "    0.68638571]\n",
      "   [0.76339393 0.5720528  0.65188679 ... 0.34523413 0.87234675\n",
      "    0.92437815]\n",
      "   [0.85264028 0.06472779 0.5520332  ... 0.38517026 0.03400387\n",
      "    0.94539949]]]\n",
      "\n",
      "\n",
      " [[[0.08022225 0.23255985 0.3833118  ... 0.90442519 0.96836205\n",
      "    0.66630949]\n",
      "   [0.72935549 0.92919428 0.56658394 ... 0.0279793  0.76617189\n",
      "    0.91389792]\n",
      "   [0.4028503  0.8111706  0.85795395 ... 0.25293628 0.09613352\n",
      "    0.5307015 ]\n",
      "   ...\n",
      "   [0.04280975 0.45566978 0.74689    ... 0.26119121 0.06430367\n",
      "    0.87724893]\n",
      "   [0.45345365 0.42658609 0.05039206 ... 0.30800607 0.34081123\n",
      "    0.02656048]\n",
      "   [0.43054525 0.14848283 0.84030576 ... 0.76734999 0.61362664\n",
      "    0.09595037]]\n",
      "\n",
      "  [[0.55101471 0.01750182 0.0950692  ... 0.74943337 0.107905\n",
      "    0.46109488]\n",
      "   [0.69657026 0.73522024 0.07540956 ... 0.66789787 0.00884961\n",
      "    0.98713752]\n",
      "   [0.19714211 0.98709831 0.71161242 ... 0.8761453  0.7643307\n",
      "    0.10339237]\n",
      "   ...\n",
      "   [0.16650586 0.00128358 0.60030162 ... 0.9938921  0.62684926\n",
      "    0.62301079]\n",
      "   [0.58434384 0.84537414 0.78204424 ... 0.84882627 0.45499222\n",
      "    0.01832355]\n",
      "   [0.06360657 0.15363379 0.95762705 ... 0.98776042 0.46089245\n",
      "    0.96041716]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.25070579 0.50095717 0.16940788 ... 0.35971028 0.08253078\n",
      "    0.08600554]\n",
      "   [0.16688166 0.48710354 0.7768337  ... 0.43744271 0.97064721\n",
      "    0.37811482]\n",
      "   [0.6644285  0.95609568 0.38209111 ... 0.36008532 0.1086672\n",
      "    0.26983896]\n",
      "   ...\n",
      "   [0.26864762 0.72151873 0.2426151  ... 0.45937566 0.8140504\n",
      "    0.60461513]\n",
      "   [0.66313087 0.57524043 0.94748803 ... 0.53912185 0.67594891\n",
      "    0.75553945]\n",
      "   [0.63651052 0.4510471  0.19999423 ... 0.03499263 0.64691187\n",
      "    0.20557812]]\n",
      "\n",
      "  [[0.84002191 0.18973955 0.43832983 ... 0.54763074 0.51772598\n",
      "    0.98691854]\n",
      "   [0.59983429 0.19638816 0.34928223 ... 0.86043593 0.88376147\n",
      "    0.03792928]\n",
      "   [0.94793126 0.60136474 0.26720202 ... 0.21879943 0.27263119\n",
      "    0.87415945]\n",
      "   ...\n",
      "   [0.40997987 0.25060303 0.61999167 ... 0.1578087  0.38350596\n",
      "    0.94615155]\n",
      "   [0.0374704  0.9551989  0.75596385 ... 0.61094626 0.56578395\n",
      "    0.0243003 ]\n",
      "   [0.89881927 0.70511531 0.74743819 ... 0.81787379 0.74996236\n",
      "    0.7332119 ]]]\n",
      "\n",
      "\n",
      " [[[0.30023228 0.81636265 0.50192436 ... 0.42710837 0.85080218\n",
      "    0.05003318]\n",
      "   [0.83178523 0.98304551 0.24052726 ... 0.99821537 0.02041804\n",
      "    0.79919159]\n",
      "   [0.19674994 0.69216235 0.63095907 ... 0.73416323 0.6582827\n",
      "    0.00690431]\n",
      "   ...\n",
      "   [0.18426677 0.08254467 0.97021999 ... 0.90991472 0.86172114\n",
      "    0.52932759]\n",
      "   [0.57113164 0.58335457 0.31041559 ... 0.45627234 0.22142406\n",
      "    0.84881794]\n",
      "   [0.48717274 0.58123426 0.84376456 ... 0.01460443 0.17784025\n",
      "    0.11155081]]\n",
      "\n",
      "  [[0.25520903 0.61787332 0.31795879 ... 0.93378095 0.01266949\n",
      "    0.56974236]\n",
      "   [0.25643687 0.50406203 0.38492906 ... 0.572969   0.94165265\n",
      "    0.2307019 ]\n",
      "   [0.53840872 0.96317943 0.34037822 ... 0.66083786 0.21180653\n",
      "    0.99049892]\n",
      "   ...\n",
      "   [0.37919339 0.86539831 0.17708584 ... 0.98297008 0.64248088\n",
      "    0.22655929]\n",
      "   [0.08259309 0.64787965 0.79699208 ... 0.98830524 0.52121225\n",
      "    0.79325623]\n",
      "   [0.74051508 0.87273805 0.07834372 ... 0.16269738 0.4341939\n",
      "    0.15804613]]]\n",
      "\n",
      "\n",
      " [[[0.64710857 0.73810497 0.83942376 ... 0.08966645 0.47273767\n",
      "    0.99671776]\n",
      "   [0.87155976 0.46466834 0.81332333 ... 0.83486202 0.62340032\n",
      "    0.08311209]\n",
      "   [0.24644897 0.18543259 0.60760896 ... 0.16374583 0.24710638\n",
      "    0.99372991]\n",
      "   ...\n",
      "   [0.49345484 0.19166939 0.56070182 ... 0.85955847 0.1190385\n",
      "    0.87319493]\n",
      "   [0.30326643 0.7558374  0.47428251 ... 0.9690811  0.7219622\n",
      "    0.07381947]\n",
      "   [0.99988468 0.87409722 0.80515135 ... 0.18416958 0.12722452\n",
      "    0.0854882 ]]\n",
      "\n",
      "  [[0.84162801 0.9984773  0.78539284 ... 0.31437925 0.18081376\n",
      "    0.54129026]\n",
      "   [0.72352397 0.98273774 0.42705479 ... 0.9526791  0.10517175\n",
      "    0.14642697]\n",
      "   [0.18647349 0.53142802 0.70804257 ... 0.61011633 0.73300665\n",
      "    0.72036126]\n",
      "   ...\n",
      "   [0.45123024 0.92645985 0.30152317 ... 0.97853881 0.82017313\n",
      "    0.843049  ]\n",
      "   [0.06436928 0.82618022 0.94320197 ... 0.99850346 0.91849584\n",
      "    0.30398518]\n",
      "   [0.79650267 0.46599475 0.59033587 ... 0.94717082 0.93680124\n",
      "    0.70146916]]]]\n",
      "(2, 5760)\n",
      "(2, 1, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "delta_conv = np.random.rand(10,2,24,24)\n",
    "print(delta_conv)\n",
    "delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "print(delta_conv_reshape.shape)\n",
    "conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3566  172 5211 ... 2156 5327 1344]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 68\u001b[0m\n\u001b[1;32m     64\u001b[0m X_maxpool \u001b[38;5;241m=\u001b[39m maxpool_multiple(X_relu,stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m### Get the indices of maxpool\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m max_indices \u001b[38;5;241m=\u001b[39m \u001b[43mmaxpool_indices_multiple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_relu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m### Flatten the maxpool output\u001b[39;00m\n\u001b[1;32m     71\u001b[0m input_shape, num_channels, input_width, input_height \u001b[38;5;241m=\u001b[39m X_maxpool\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mmaxpool_indices_multiple\u001b[0;34m(input_image, stride, filter_height, filter_width)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Go through each image\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(input_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Add vector of maxpool idx to curr image\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     positional_vector\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmaxpool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfilter_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m positional_vector\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mmaxpool_indices\u001b[0;34m(input_image, stride, filter_height, filter_width)\u001b[0m\n\u001b[1;32m     23\u001b[0m image_square \u001b[38;5;241m=\u001b[39m image_rectangle[:,:,width:width\u001b[38;5;241m+\u001b[39mfilter_width]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Max val within square \u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m a,b,c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munravel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_square\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage_square\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Store map and max val\u001b[39;00m\n\u001b[1;32m     27\u001b[0m positional_vector\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;241m0\u001b[39m,channel,\u001b[38;5;28mint\u001b[39m(b)\u001b[38;5;241m+\u001b[39mheight,\u001b[38;5;28mint\u001b[39m(c)\u001b[38;5;241m+\u001b[39mwidth,\u001b[38;5;241m0\u001b[39m,channel,x,y])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = np.random.randn(2,1,5,5)*np.sqrt(1./5.)\n",
    "W1 = np.random.rand(60,288)/np.sqrt(288)\n",
    "B0 = np.zeros((60,1))/np.sqrt(288)\n",
    "W2 = np.random.rand(10,60)/np.sqrt(60)\n",
    "B1 = np.zeros((10,1))/np.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['Conv1'] = beta1 * momentums.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['Conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['Conv1'] = beta2 * velocities.get('Conv1', np.zeros_like(parameters['Conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['Conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['Conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m one_hot_encoding_train[start:end,:]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m### First Convolutional Layer\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m X_im2col \u001b[38;5;241m=\u001b[39m im2col(X\u001b[38;5;241m=\u001b[39mX_batch, conv1\u001b[38;5;241m=\u001b[39m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m conv1_reshaped \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m X_conv \u001b[38;5;241m=\u001b[39m conv1_reshaped\u001b[38;5;129m@X_im2col\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'conv1'"
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "parameters, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=parameters['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = parameters['conv1'].reshape(parameters['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Define dictionaries for parameters and gradients\n",
    "        parameters = {'W1': W1, 'B0': B0, 'W2': W2, 'B1': B1, 'Conv1': conv1}\n",
    "        grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        parameters, velocities, momentums = update_with_adam(parameters, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters\n",
    "        W1, B0, W2, B1, conv1 = parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
