{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 785)\n",
      "(6000, 785)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import array_api_strict as np\n",
    "\n",
    "## import data set\n",
    "data = pd.read_csv('train.csv')\n",
    "## Data shuffle\n",
    "data = data.sample(frac=1)\n",
    "tmp = pd.DataFrame()\n",
    "\n",
    "## 600 entries per class\n",
    "mid = int(data.shape[0] / 2)\n",
    "data_first_half = data.iloc[:mid]\n",
    "data_second_half = data.iloc[mid:]\n",
    "\n",
    "# Function to get a balanced subset of data with 'n_samples' for each label\n",
    "def get_balanced_data(df, n_samples):\n",
    "    return pd.concat([df[df['label'] == label].head(n_samples) for label in range(10)])\n",
    "\n",
    "# Get 600 data points for each label from the first half\n",
    "data_balanced = get_balanced_data(data_first_half, 600)\n",
    "\n",
    "# Get 100 data points for each label from the second half\n",
    "data_test = get_balanced_data(data_second_half, 100)\n",
    "\n",
    "print(data_test.shape)\n",
    "print(data_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 1, 28, 28)\n",
      "(1000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def flatten_to_image(data, image_height=28, image_width=28):\n",
    "    \"\"\"\n",
    "    Convert flattened input data into image format.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame, the dataset with flattened images.\n",
    "    - image_height: int, the height of the images after reshaping.\n",
    "    - image_width: int, the width of the images after reshaping.\n",
    "\n",
    "    Returns:\n",
    "    - numpy array of shape (N, 1, image_height, image_width), where N is the number of data points.\n",
    "    \"\"\"\n",
    "    # Drop the 'label' column and convert to numpy array\n",
    "    image_data = np.asarray(data.drop('label', axis=1), dtype=np.float32)\n",
    "    \n",
    "    # Reshape data into (N, 1, 28, 28) format\n",
    "    data_array = np.reshape(image_data, (-1, 1, image_height, image_width)) / 255.0\n",
    "    \n",
    "    return data_array\n",
    "\n",
    "# Shuffle and convert both training and testing data\n",
    "data_balanced = data_balanced.sample(frac=1)\n",
    "data_array = flatten_to_image(data_balanced)\n",
    "\n",
    "data_test = data_test.sample(frac=1)\n",
    "data_test_input = flatten_to_image(data_test)\n",
    "\n",
    "print(data_array.shape)\n",
    "print(data_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 3, 5, 2, 8, 9, 5, 9, 5, 7, 7, 0, 6, 2, 6, 6, 6, 0, 9, 6, 1, 1, 2, 7, 0, 9, 3, 8, 7, 2, 3, 0, 1, 0, 8, 7, 7, 5, 9, 9, 6, 0, 9, 9, 9, 5, 8, 6, 8, 8, 4, 3, 0, 1, 9, 3, 8, 1, 7, 8, 4, 7, 6, 6, 0, 1, 2, 5, 9, 0, 3, 7, 4, 2, 1, 6, 1, 3, 9, 4, 5, 7, 5, 4, 6, 8, 4, 3, 9, 2, 4, 1, 7, 6, 0, 5, 7, 2, 7, 8, 4, 6, 8, 2, 0, 2, 8, 6, 0, 9, 0, 2, 4, 2, 2, 6, 3, 0, 0, 2, 8, 0, 6, 9, 7, 4, 2, 7, 9, 4, 7, 3, 5, 8, 3, 3, 2, 9, 8, 0, 9, 6, 4, 6, 9, 6, 5, 2, 1, 8, 2, 4, 1, 2, 9, 8, 2, 4, 8, 1, 8, 3, 6, 6, 3, 6, 2, 8, 9, 5, 7, 2, 6, 3, 6, 4, 2, 8, 8, 7, 8, 2, 6, 6, 7, 0, 2, 8, 3, 3, 3, 7, 7, 0, 0, 2, 5, 8, 7, 1, 2, 1, 7, 1, 1, 9, 9, 6, 7, 6, 4, 3, 9, 7, 1, 0, 2, 2, 7, 6, 5, 2, 6, 0, 8, 2, 8, 1, 4, 3, 2, 4, 3, 8, 7, 3, 6, 0, 1, 3, 9, 9, 7, 1, 2, 3, 7, 5, 2, 5, 5, 8, 0, 1, 4, 2, 9, 3, 3, 1, 6, 2, 7, 4, 5, 3, 9, 0, 2, 9, 8, 9, 9, 8, 9, 3, 2, 3, 2, 8, 0, 7, 5, 0, 1, 2, 7, 6, 3, 1, 5, 1, 1, 8, 7, 5, 5, 4, 1, 5, 7, 5, 0, 1, 4, 2, 5, 0, 4, 5, 4, 9, 9, 4, 3, 0, 3, 9, 6, 7, 3, 3, 1, 5, 4, 9, 7, 7, 2, 2, 5, 0, 7, 7, 9, 6, 6, 9, 2, 7, 7, 7, 8, 2, 6, 0, 2, 7, 0, 3, 7, 0, 5, 3, 9, 1, 7, 8, 9, 8, 6, 6, 0, 0, 3, 9, 8, 1, 5, 5, 1, 0, 4, 7, 8, 6, 5, 4, 7, 2, 8, 2, 0, 0, 6, 2, 1, 6, 7, 5, 5, 3, 8, 6, 9, 0, 1, 8, 9, 3, 0, 3, 9, 2, 5, 6, 0, 6, 6, 9, 4, 2, 5, 1, 4, 4, 6, 4, 1, 5, 0, 0, 1, 3, 5, 5, 4, 7, 9, 6, 4, 4, 8, 4, 2, 0, 8, 6, 4, 9, 6, 8, 6, 2, 5, 3, 7, 4, 0, 3, 0, 7, 7, 2, 8, 1, 8, 2, 7, 3, 1, 8, 9, 3, 4, 8, 6, 9, 5, 1, 7, 3, 9, 9, 3, 9, 5, 4, 1, 7, 4, 5, 8, 6, 5, 1, 2, 9, 9, 7, 5, 2, 0, 3, 9, 1, 0, 8, 3, 8, 2, 9, 8, 0, 2, 7, 6, 9, 4, 9, 6, 8, 2, 2, 2, 4, 5, 3, 9, 2, 8, 0, 9, 9, 4, 4, 6, 4, 7, 7, 8, 0, 2, 7, 1, 3, 9, 3, 1, 6, 1, 3, 8, 1, 1, 7, 9, 8, 6, 9, 8, 9, 2, 1, 0, 9, 7, 3, 6, 1, 4, 6, 8, 3, 2, 6, 6, 5, 0, 5, 4, 1, 8, 4, 1, 1, 1, 2, 4, 8, 2, 2, 5, 8, 7, 1, 2, 5, 7, 5, 8, 0, 6, 9, 6, 8, 5, 7, 0, 3, 1, 7, 2, 2, 6, 6, 0, 6, 3, 0, 0, 3, 8, 7, 5, 5, 8, 8, 6, 1, 8, 5, 1, 9, 2, 9, 8, 2, 8, 5, 4, 8, 6, 7, 0, 2, 5, 6, 1, 8, 1, 3, 6, 9, 4, 4, 4, 1, 2, 3, 5, 7, 9, 3, 4, 4, 2, 6, 0, 4, 3, 3, 8, 0, 6, 9, 2, 3, 4, 6, 7, 4, 2, 4, 6, 6, 4, 7, 8, 3, 0, 7, 1, 7, 6, 9, 6, 3, 5, 0, 1, 3, 8, 0, 6, 5, 2, 5, 1, 1, 3, 1, 2, 1, 6, 2, 1, 8, 3, 8, 0, 1, 0, 9, 7, 2, 2, 1, 3, 9, 6, 1, 1, 2, 1, 2, 3, 2, 7, 0, 0, 5, 8, 9, 1, 6, 2, 4, 1, 7, 7, 5, 9, 8, 0, 1, 6, 9, 2, 4, 6, 3, 0, 6, 2, 2, 4, 9, 2, 1, 2, 1, 7, 8, 7, 4, 6, 8, 9, 8, 7, 5, 9, 3, 9, 0, 0, 1, 0, 3, 5, 3, 2, 8, 2, 6, 5, 3, 5, 0, 3, 1, 0, 2, 9, 5, 3, 8, 9, 7, 3, 1, 8, 9, 8, 3, 5, 2, 8, 6, 6, 8, 0, 1, 3, 7, 0, 1, 3, 2, 8, 1, 9, 1, 1, 8, 3, 1, 9, 1, 5, 0, 6, 4, 4, 3, 8, 7, 1, 0, 7, 0, 7, 6, 1, 2, 1, 0, 3, 6, 4, 8, 9, 2, 2, 0, 7, 1, 5, 5, 3, 3, 5, 7, 8, 4, 4, 4, 7, 2, 5, 0, 4, 9, 3, 3, 6, 5, 9, 6, 2, 8, 7, 2, 8, 0, 7, 1, 0, 7, 2, 5, 4, 1, 5, 0, 0, 5, 8, 0, 2, 2, 1, 0, 5, 8, 3, 1, 2, 6, 8, 8, 4, 8, 4, 9, 9, 2, 4, 7, 2, 9, 1, 4, 9, 9, 0, 1, 4, 3, 6, 5, 4, 4, 8, 5, 9, 9, 3, 8, 0, 0, 6, 2, 9, 8, 9, 1, 2, 9, 8, 7, 5, 0, 1, 3, 7, 2, 7, 2, 9, 4, 3, 6, 9, 3, 6, 6, 5, 5, 6, 0, 6, 9, 2, 7, 3, 2, 9, 6, 6, 3, 3, 2, 0, 3, 0, 0, 3, 7, 8, 1, 1, 2, 4, 6, 0, 8, 8, 5, 9, 5, 0, 0, 5, 5, 1, 5, 5, 8, 7, 7, 0, 5, 2, 1, 1, 6, 7, 1, 8, 6, 8, 5, 2, 3, 3, 6, 1, 1, 5, 6, 2, 7, 7, 6, 7, 2, 0, 2, 3, 8, 9, 8, 5, 1, 6, 6, 8, 8, 1, 2, 6, 0, 2, 1, 6, 9, 2, 4, 8, 9, 3, 2, 4, 1, 3, 0, 5, 2, 5, 7, 0, 1, 7, 4, 8, 8, 4, 5, 4, 4, 6, 5, 8, 8, 2, 4, 6, 8, 9, 6, 4, 2, 4, 8, 8, 8, 3, 0, 4, 0, 8, 1, 4, 5, 9, 4, 2, 5, 7, 9, 0, 3, 8, 7, 7, 4, 0, 3, 2, 0, 0, 5, 2, 4, 9, 8, 6, 9, 8, 4, 8, 0, 2, 1, 3, 1, 2, 2, 7, 2, 7, 8, 8, 5, 9, 6, 8, 2, 1, 5, 3, 0, 0, 1, 6, 0, 0, 0, 4, 5, 2, 4, 7, 2, 7, 8, 3, 3, 0, 1, 8, 1, 0, 3, 6, 1, 4, 6, 8, 5, 1, 7, 3, 6, 8, 2, 4, 3, 2, 4, 9, 8, 4, 6, 7, 0, 8, 9, 8, 0, 0, 1, 5, 5, 0, 1, 6, 7, 8, 7, 3, 5, 0, 0, 3, 3, 4, 3, 1, 4, 0, 3, 3, 4, 0, 0, 7, 3, 4, 2, 6, 9, 5, 2, 2, 9, 8, 4, 7, 3, 8, 9, 5, 1, 9, 7, 3, 6, 5, 2, 5, 1, 7, 1, 9, 4, 7, 8, 2, 3, 7, 6, 4, 0, 0, 0, 1, 9, 6, 4, 6, 9, 3, 9, 9, 5, 8, 0, 2, 8, 0, 9, 5, 5, 4, 9, 9, 9, 8, 2, 9, 7, 9, 6, 3, 6, 4, 3, 1, 0, 6, 3, 6, 9, 8, 3, 1, 1, 6, 5, 3, 3, 9, 2, 6, 4, 7, 1, 1, 1, 8, 9, 6, 7, 3, 0, 6, 1, 3, 6, 5, 7, 8, 5, 4, 0, 3, 5, 2, 8, 3, 0, 3, 7, 2, 0, 7, 1, 7, 0, 8, 0, 9, 3, 8, 8, 8, 6, 9, 9, 4, 2, 9, 5, 2, 7, 8, 6, 9, 3, 0, 3, 4, 0, 1, 3, 7, 3, 4, 5, 1, 7, 1, 6, 8, 0, 3, 3, 9, 6, 3, 6, 5, 8, 6, 1, 0, 3, 5, 9, 5, 1, 1, 3, 4, 6, 7, 1, 9, 7, 9, 0, 9, 7, 4, 6, 0, 9, 5, 9, 6, 3, 0, 8, 1, 6, 2, 1, 3, 5, 3, 8, 6, 2, 0, 8, 5, 6, 7, 4, 3, 5, 7, 5, 7, 0, 9, 9, 3, 4, 8, 9, 1, 4, 4, 4, 4, 6, 9, 9, 7, 9, 8, 5, 7, 4, 7, 4, 9, 2, 8, 6, 6, 7, 0, 4, 3, 8, 5, 7, 6, 1, 5, 0, 5, 2, 5, 7, 7, 6, 7, 9, 4, 3, 3, 5, 0, 9, 8, 8, 7, 0, 6, 4, 9, 4, 3, 1, 6, 0, 2, 2, 7, 2, 2, 5, 0, 8, 2, 2, 5, 4, 5, 7, 4, 3, 8, 5, 1, 4, 9, 3, 8, 4, 8, 3, 1, 2, 1, 6, 2, 0, 1, 2, 8, 5, 1, 6, 9, 7, 3, 3, 0, 7, 8, 4, 7, 8, 9, 3, 8, 1, 9, 5, 9, 2, 0, 7, 9, 5, 9, 5, 1, 9, 7, 2, 3, 1, 6, 8, 6, 2, 9, 5, 7, 9, 2, 7, 4, 2, 0, 5, 7, 9, 5, 5, 6, 6, 5, 3, 7, 6, 4, 7, 0, 2, 4, 6, 6, 7, 8, 8, 7, 0, 3, 5, 4, 6, 0, 5, 0, 7, 0, 4, 4, 4, 7, 4, 7, 9, 3, 8, 6, 5, 1, 7, 1, 0, 5, 1, 7, 3, 6, 3, 7, 0, 5, 1, 9, 2, 9, 4, 2, 1, 5, 2, 4, 7, 4, 0, 3, 9, 9, 5, 1, 5, 0, 6, 0, 3, 2, 3, 7, 8, 8, 9, 6, 7, 7, 6, 8, 4, 1, 2, 3, 1, 5, 2, 2, 9, 0, 4, 9, 7, 4, 8, 9, 5, 6, 1, 0, 4, 1, 8, 3, 1, 8, 7, 7, 7, 7, 5, 6, 4, 2, 7, 0, 5, 5, 1, 2, 6, 2, 5, 5, 2, 4, 3, 0, 5, 9, 8, 1, 3, 2, 6, 8, 8, 3, 7, 0, 4, 2, 5, 2, 9, 8, 3, 4, 2, 4, 2, 8, 2, 7, 5, 3, 0, 6, 3, 8, 7, 8, 7, 8, 4, 1, 4, 6, 4, 1, 0, 5, 1, 4, 2, 9, 9, 4, 9, 0, 4, 5, 5, 5, 2, 7, 1, 5, 3, 1, 7, 6, 2, 4, 8, 3, 6, 1, 0, 3, 3, 7, 3, 5, 1, 8, 4, 8, 3, 8, 0, 1, 5, 2, 2, 3, 0, 1, 3, 4, 4, 1, 3, 4, 5, 4, 5, 2, 6, 8, 0, 6, 5, 8, 0, 7, 4, 0, 0, 0, 3, 3, 5, 5, 1, 5, 5, 4, 0, 2, 1, 7, 0, 4, 8, 0, 4, 6, 8, 8, 6, 7, 9, 1, 8, 6, 7, 0, 4, 4, 1, 9, 0, 4, 8, 5, 5, 1, 4, 5, 3, 1, 5, 4, 0, 4, 4, 5, 1, 8, 4, 1, 3, 7, 6, 6, 1, 3, 8, 9, 9, 6, 6, 6, 4, 0, 7, 1, 6, 1, 9, 5, 7, 9, 3, 2, 9, 5, 9, 7, 9, 7, 9, 8, 7, 4, 9, 7, 0, 5, 2, 9, 9, 6, 9, 4, 7, 1, 7, 3, 7, 7, 1, 8, 0, 4, 9, 8, 1, 9, 4, 3, 9, 1, 6, 4, 2, 0, 0, 1, 5, 5, 4, 3, 6, 7, 6, 1, 0, 2, 4, 2, 7, 3, 5, 4, 0, 4, 3, 6, 3, 1, 1, 1, 5, 1, 6, 3, 5, 3, 0, 3, 5, 8, 8, 4, 3, 1, 8, 5, 4, 0, 1, 1, 3, 4, 3, 0, 2, 5, 0, 3, 8, 0, 8, 8, 7, 5, 4, 0, 8, 8, 2, 4, 3, 8, 6, 4, 1, 1, 6, 8, 5, 3, 2, 5, 3, 9, 9, 5, 9, 6, 3, 7, 7, 4, 7, 7, 6, 4, 8, 9, 0, 2, 5, 6, 6, 9, 5, 1, 8, 9, 7, 2, 5, 5, 4, 1, 8, 7, 9, 9, 3, 9, 1, 7, 0, 9, 4, 1, 4, 2, 2, 0, 7, 0, 1, 2, 3, 5, 6, 4, 2, 3, 4, 9, 6, 7, 4, 6, 1, 0, 5, 1, 5, 8, 3, 6, 3, 5, 7, 2, 6, 4, 7, 3, 0, 6, 0, 6, 0, 8, 8, 3, 5, 5, 4, 4, 4, 2, 6, 4, 0, 8, 8, 7, 1, 6, 4, 0, 6, 5, 0, 8, 3, 0, 6, 8, 7, 3, 3, 0, 5, 2, 9, 8, 9, 1, 2, 7, 3, 1, 6, 6, 2, 2, 6, 2, 7, 2, 9, 2, 7, 6, 5, 6, 5, 0, 8, 6, 5, 7, 9, 3, 0, 8, 4, 1, 6, 3, 5, 5, 6, 6, 9, 5, 2, 9, 5, 9, 4, 4, 1, 3, 5, 0, 8, 3, 5, 3, 0, 7, 3, 8, 0, 9, 4, 4, 7, 4, 3, 1, 2, 5, 9, 5, 9, 2, 9, 0, 1, 5, 6, 4, 6, 1, 6, 2, 8, 9, 1, 1, 6, 6, 9, 9, 4, 5, 6, 1, 7, 0, 7, 0, 9, 2, 2, 8, 0, 4, 5, 8, 4, 9, 5, 2, 3, 2, 9, 5, 9, 7, 2, 5, 2, 1, 6, 2, 9, 8, 7, 7, 9, 9, 1, 2, 8, 4, 6, 5, 8, 8, 7, 6, 6, 9, 1, 8, 1, 6, 8, 7, 9, 1, 3, 7, 4, 7, 9, 5, 4, 9, 1, 6, 7, 9, 7, 0, 2, 8, 2, 0, 2, 4, 7, 8, 1, 2, 8, 8, 5, 5, 6, 9, 9, 7, 2, 7, 6, 1, 3, 9, 4, 5, 5, 5, 4, 2, 8, 6, 5, 2, 0, 1, 0, 2, 7, 7, 9, 2, 7, 4, 9, 2, 4, 7, 6, 3, 6, 1, 6, 4, 3, 0, 8, 5, 3, 2, 1, 9, 7, 0, 3, 9, 0, 3, 4, 6, 9, 3, 0, 2, 8, 8, 9, 5, 9, 1, 3, 3, 1, 2, 3, 0, 4, 5, 6, 5, 5, 3, 3, 2, 1, 2, 2, 1, 1, 8, 2, 6, 8, 8, 4, 4, 0, 8, 8, 6, 8, 2, 0, 2, 5, 2, 4, 4, 8, 5, 1, 8, 3, 1, 6, 5, 8, 4, 9, 4, 2, 9, 4, 1, 1, 8, 8, 9, 4, 9, 5, 4, 8, 1, 9, 7, 2, 5, 4, 0, 8, 4, 6, 7, 6, 4, 7, 1, 1, 7, 1, 5, 2, 1, 1, 2, 5, 0, 2, 6, 0, 0, 6, 4, 2, 4, 8, 0, 5, 4, 0, 5, 8, 0, 0, 9, 0, 1, 4, 6, 0, 2, 5, 5, 3, 7, 8, 4, 7, 1, 4, 1, 7, 2, 9, 3, 4, 1, 6, 8, 3, 5, 5, 4, 3, 6, 0, 2, 7, 7, 3, 4, 9, 3, 4, 9, 0, 4, 8, 2, 4, 8, 5, 1, 3, 9, 1, 9, 0, 8, 0, 5, 8, 9, 9, 7, 9, 2, 4, 5, 3, 0, 3, 3, 2, 2, 2, 6, 9, 5, 9, 5, 8, 4, 1, 2, 6, 9, 0, 3, 2, 4, 3, 4, 3, 6, 6, 4, 0, 3, 3, 7, 5, 1, 7, 6, 4, 8, 7, 5, 4, 5, 5, 9, 7, 5, 1, 8, 7, 7, 4, 3, 0, 4, 2, 5, 3, 7, 9, 5, 4, 7, 2, 7, 9, 0, 1, 9, 0, 1, 4, 7, 9, 7, 1, 2, 4, 6, 8, 1, 3, 7, 0, 7, 3, 5, 1, 3, 3, 8, 3, 5, 7, 4, 6, 0, 5, 5, 8, 7, 9, 7, 6, 8, 0, 5, 6, 8, 6, 8, 3, 0, 7, 0, 0, 5, 9, 3, 3, 7, 8, 0, 3, 5, 3, 8, 4, 0, 5, 8, 5, 5, 1, 8, 6, 9, 4, 5, 3, 6, 5, 2, 7, 3, 9, 6, 5, 4, 5, 4, 0, 8, 0, 9, 8, 6, 3, 7, 6, 6, 9, 2, 4, 2, 6, 8, 3, 0, 0, 9, 0, 3, 0, 2, 0, 1, 5, 8, 5, 1, 0, 4, 2, 5, 3, 7, 5, 9, 8, 0, 2, 3, 7, 6, 2, 2, 7, 7, 4, 9, 1, 5, 1, 9, 9, 9, 3, 3, 5, 3, 0, 2, 1, 3, 9, 3, 2, 3, 0, 9, 2, 2, 7, 9, 4, 1, 0, 0, 7, 7, 1, 5, 3, 7, 2, 5, 0, 9, 3, 3, 8, 4, 7, 2, 0, 3, 5, 8, 5, 1, 8, 3, 2, 4, 9, 5, 5, 4, 2, 5, 1, 5, 0, 2, 8, 1, 9, 0, 1, 9, 2, 6, 8, 3, 1, 8, 2, 5, 7, 6, 5, 5, 9, 4, 5, 7, 6, 7, 8, 4, 1, 1, 0, 4, 4, 6, 7, 0, 5, 2, 1, 5, 4, 6, 1, 5, 7, 3, 2, 3, 5, 6, 3, 6, 1, 0, 0, 1, 9, 3, 1, 9, 0, 6, 7, 8, 3, 7, 4, 8, 1, 5, 0, 5, 5, 2, 7, 9, 1, 8, 7, 7, 0, 0, 5, 2, 1, 6, 9, 1, 7, 8, 3, 0, 1, 1, 1, 2, 3, 2, 8, 9, 9, 5, 5, 9, 6, 9, 7, 9, 4, 9, 7, 2, 2, 5, 6, 5, 7, 6, 0, 0, 7, 8, 9, 3, 9, 7, 5, 5, 7, 1, 1, 0, 1, 6, 4, 9, 1, 3, 3, 0, 2, 3, 1, 8, 2, 1, 2, 1, 5, 6, 1, 8, 5, 9, 5, 1, 3, 8, 0, 2, 1, 4, 4, 0, 8, 4, 1, 5, 3, 0, 4, 0, 6, 0, 8, 5, 2, 0, 7, 2, 0, 5, 8, 3, 8, 5, 8, 4, 5, 3, 5, 2, 2, 7, 7, 5, 4, 3, 5, 2, 5, 1, 8, 7, 0, 4, 5, 5, 0, 2, 1, 3, 8, 0, 1, 0, 8, 5, 7, 0, 3, 2, 3, 2, 8, 1, 0, 0, 6, 8, 0, 7, 3, 7, 3, 5, 6, 0, 8, 4, 5, 3, 3, 6, 8, 6, 3, 5, 7, 5, 8, 2, 6, 5, 2, 3, 6, 3, 1, 9, 6, 5, 0, 2, 1, 6, 8, 0, 5, 4, 6, 5, 5, 7, 6, 7, 7, 7, 5, 9, 7, 1, 8, 7, 1, 3, 7, 3, 2, 5, 6, 8, 0, 4, 8, 5, 3, 4, 6, 0, 2, 1, 3, 0, 2, 0, 0, 1, 7, 9, 1, 6, 6, 0, 6, 6, 0, 1, 7, 5, 0, 6, 1, 9, 1, 7, 4, 1, 1, 1, 0, 5, 9, 0, 0, 5, 5, 7, 6, 6, 0, 1, 9, 9, 8, 4, 5, 2, 5, 7, 6, 1, 1, 0, 1, 4, 3, 0, 0, 0, 2, 9, 8, 0, 1, 8, 1, 2, 4, 9, 4, 7, 6, 4, 7, 9, 2, 5, 0, 0, 6, 7, 5, 4, 3, 3, 3, 4, 3, 3, 6, 3, 7, 8, 0, 3, 7, 2, 2, 9, 0, 3, 5, 7, 3, 0, 3, 1, 8, 8, 0, 9, 2, 8, 8, 1, 6, 1, 5, 8, 8, 3, 1, 9, 8, 5, 4, 0, 4, 1, 7, 4, 6, 6, 1, 6, 6, 8, 2, 0, 5, 6, 5, 4, 1, 3, 7, 1, 0, 9, 3, 9, 1, 0, 9, 6, 5, 9, 0, 7, 2, 9, 8, 9, 9, 9, 7, 2, 8, 2, 3, 5, 2, 7, 0, 7, 6, 6, 3, 6, 9, 7, 5, 0, 7, 2, 7, 1, 7, 4, 2, 7, 1, 6, 3, 2, 4, 0, 7, 4, 0, 7, 0, 0, 2, 3, 1, 2, 0, 7, 8, 8, 0, 7, 4, 4, 2, 1, 0, 5, 6, 2, 5, 3, 4, 3, 7, 1, 4, 4, 9, 6, 2, 0, 5, 9, 7, 2, 8, 7, 6, 7, 6, 2, 7, 9, 9, 6, 4, 4, 1, 4, 8, 2, 7, 8, 9, 7, 3, 3, 4, 4, 1, 3, 5, 8, 0, 7, 6, 0, 2, 7, 1, 9, 8, 3, 3, 8, 9, 9, 8, 7, 4, 9, 2, 4, 5, 9, 2, 3, 3, 1, 5, 4, 2, 1, 4, 5, 9, 7, 8, 7, 7, 7, 4, 8, 0, 3, 8, 3, 7, 6, 9, 4, 2, 5, 9, 3, 5, 0, 4, 8, 8, 6, 0, 1, 1, 6, 4, 6, 9, 2, 6, 4, 6, 9, 2, 8, 2, 6, 9, 6, 1, 7, 0, 0, 9, 7, 7, 6, 9, 6, 8, 2, 2, 2, 1, 3, 8, 6, 9, 2, 2, 9, 8, 7, 9, 3, 7, 2, 4, 2, 9, 1, 9, 8, 7, 5, 5, 8, 1, 3, 5, 1, 9, 5, 6, 7, 9, 4, 4, 5, 2, 2, 3, 4, 9, 9, 8, 0, 8, 9, 2, 3, 1, 1, 1, 2, 3, 2, 1, 7, 0, 7, 5, 8, 1, 8, 2, 7, 7, 6, 8, 4, 8, 4, 3, 5, 2, 9, 1, 9, 8, 5, 4, 8, 6, 3, 6, 8, 4, 3, 7, 5, 8, 6, 0, 1, 6, 6, 8, 1, 5, 7, 4, 5, 7, 0, 8, 3, 1, 3, 6, 2, 3, 8, 7, 7, 4, 7, 6, 1, 2, 4, 2, 0, 3, 1, 7, 7, 7, 6, 1, 3, 8, 1, 0, 3, 5, 9, 2, 4, 4, 4, 8, 6, 6, 6, 2, 3, 5, 0, 0, 3, 5, 7, 5, 9, 6, 8, 4, 8, 3, 0, 8, 6, 0, 4, 1, 8, 6, 2, 7, 7, 4, 2, 4, 3, 5, 4, 1, 2, 0, 4, 9, 0, 0, 6, 7, 6, 6, 5, 5, 4, 4, 9, 7, 5, 1, 3, 0, 4, 1, 2, 3, 3, 5, 5, 8, 5, 4, 3, 5, 7, 0, 6, 7, 6, 2, 9, 0, 9, 8, 0, 0, 8, 4, 2, 4, 3, 8, 3, 0, 9, 8, 8, 3, 3, 4, 1, 7, 9, 7, 3, 6, 3, 1, 7, 0, 2, 7, 2, 3, 3, 5, 1, 6, 7, 6, 3, 7, 1, 7, 0, 2, 7, 3, 9, 9, 9, 4, 3, 1, 4, 9, 5, 6, 8, 1, 9, 5, 7, 5, 4, 7, 2, 4, 7, 0, 3, 2, 8, 9, 2, 8, 3, 7, 9, 5, 3, 0, 7, 8, 2, 2, 2, 0, 0, 4, 0, 9, 1, 9, 0, 9, 2, 7, 4, 3, 3, 3, 5, 2, 0, 5, 7, 3, 1, 8, 0, 8, 1, 1, 4, 2, 8, 3, 8, 2, 6, 0, 1, 1, 0, 1, 9, 1, 2, 7, 0, 4, 9, 7, 2, 8, 3, 3, 1, 9, 0, 0, 9, 0, 2, 8, 0, 7, 1, 7, 9, 8, 3, 8, 9, 2, 1, 4, 0, 8, 5, 2, 6, 1, 1, 3, 5, 7, 5, 0, 6, 4, 6, 1, 6, 3, 2, 4, 6, 3, 7, 1, 8, 0, 9, 6, 1, 1, 3, 1, 5, 4, 5, 4, 3, 9, 0, 0, 1, 6, 1, 3, 2, 9, 3, 8, 0, 7, 4, 5, 9, 9, 8, 8, 7, 9, 3, 2, 3, 2, 4, 6, 2, 1, 3, 8, 4, 2, 1, 4, 9, 8, 5, 5, 5, 0, 3, 1, 1, 1, 4, 5, 5, 6, 3, 1, 6, 3, 1, 0, 9, 6, 3, 7, 4, 2, 9, 2, 1, 3, 0, 8, 0, 0, 9, 0, 8, 6, 1, 5, 3, 0, 3, 0, 7, 0, 8, 2, 9, 4, 5, 4, 7, 4, 4, 0, 1, 2, 4, 4, 7, 2, 1, 8, 5, 1, 2, 9, 8, 7, 8, 2, 6, 2, 3, 3, 2, 0, 8, 9, 4, 8, 2, 6, 1, 6, 7, 9, 8, 4, 9, 8, 5, 3, 4, 6, 8, 1, 6, 4, 1, 8, 1, 9, 9, 4, 8, 3, 6, 0, 3, 5, 6, 6, 5, 0, 6, 8, 3, 4, 2, 5, 6, 9, 5, 6, 6, 9, 3, 7, 5, 1, 5, 0, 1, 0, 8, 7, 2, 8, 3, 5, 4, 1, 2, 9, 0, 5, 3, 9, 7, 3, 6, 4, 9, 7, 0, 3, 3, 9, 0, 9, 0, 8, 1, 1, 0, 0, 0, 9, 9, 3, 4, 4, 3, 4, 5, 2, 7, 5, 2, 1, 1, 3, 2, 9, 7, 1, 3, 2, 6, 2, 0, 7, 5, 4, 4, 7, 6, 1, 5, 4, 6, 4, 1, 1, 8, 9, 0, 6, 6, 2, 6, 2, 7, 2, 6, 2, 7, 9, 2, 5, 2, 1, 1, 1, 2, 2, 2, 6, 7, 3, 9, 1, 9, 1, 1, 3, 2, 6, 4, 5, 1, 5, 5, 9, 7, 3, 8, 6, 6, 7, 0, 9, 3, 8, 9, 6, 3, 2, 9, 2, 7, 4, 2, 0, 2, 5, 8, 7, 7, 6, 3, 4, 3, 2, 6, 4, 2, 8, 2, 0, 8, 1, 9, 5, 6, 4, 1, 4, 4, 9, 2, 1, 5, 0, 9, 6, 7, 0, 9, 4, 2, 6, 8, 8, 3, 6, 6, 9, 6, 7, 9, 9, 8, 8, 0, 7, 5, 3, 6, 3, 4, 6, 5, 9, 8, 7, 1, 6, 0, 7, 3, 6, 7, 6, 9, 3, 8, 4, 1, 9, 7, 5, 2, 1, 7, 6, 6, 9, 0, 3, 7, 9, 5, 9, 6, 9, 4, 8, 2, 0, 9, 0, 6, 1, 2, 7, 6, 3, 9, 4, 0, 3, 5, 4, 9, 6, 2, 0, 6, 3, 4, 5, 2, 0, 3, 1, 1, 0, 3, 8, 7, 3, 3, 3, 5, 4, 8, 6, 5, 0, 0, 6, 5, 5, 6, 8, 1, 6, 3, 3, 1, 8, 9, 4, 8, 1, 8, 1, 0, 9, 6, 1, 8, 0, 5, 4, 9, 5, 8, 4, 1, 7, 2, 6, 9, 2, 9, 0, 6, 1, 8, 2, 1, 2, 7, 6, 2, 5, 0, 0, 6, 3, 8, 9, 0, 6, 9, 2, 4, 0, 4, 7, 8, 9, 6, 5, 5, 0, 6, 8, 1, 8, 8, 0, 8, 4, 6, 0, 4, 7, 7, 7, 0, 2, 7, 1, 3, 8, 2, 5, 2, 8, 6, 2, 0, 8, 1, 9, 6, 0, 5, 0, 5, 2, 3, 0, 6, 3, 1, 4, 5, 1, 0, 0, 3, 6, 0, 1, 4, 1, 4, 1, 3, 1, 0, 5, 8, 7, 9, 1, 0, 9, 2, 8, 4, 2, 8, 1, 6, 4, 1, 9, 8, 2, 4, 3, 3, 9, 6, 6, 2, 5, 5, 0, 6, 9, 2, 0, 2, 4, 4, 0, 4, 2, 1, 7, 0, 9, 1, 8, 1, 7, 5, 4, 9, 0, 6, 0, 4, 7, 1, 5, 2, 2, 0, 5, 5, 2, 7, 1, 2, 7, 4, 6, 9, 2, 4, 3, 7, 8, 0, 4, 1, 9, 6, 8, 3, 4, 8, 0, 9, 7, 6, 5, 3, 7, 0, 3, 8, 1, 0, 3, 7, 7, 5, 1, 9, 8, 3, 8, 8, 6, 5, 3, 9, 0, 4, 4, 9, 6, 0, 2, 4, 5, 8, 4, 4, 1, 3, 1, 6, 7, 9, 8, 8, 2, 2, 2, 0, 7, 6, 6, 1, 6, 8, 2, 7, 8, 9, 8, 0, 3, 2, 0, 1, 8, 3, 8, 9, 5, 2, 2, 7, 6, 6, 7, 9, 7, 0, 5, 5, 7, 1, 7, 4, 3, 5, 3, 4, 0, 5, 9, 7, 1, 6, 6, 2, 0, 2, 8, 5, 6, 1, 8, 8, 7, 9, 3, 1, 4, 0, 1, 7, 9, 3, 3, 1, 3, 8, 3, 7, 6, 0, 9, 1, 5, 1, 6, 1, 1, 1, 3, 4, 3, 1, 1, 2, 4, 8, 1, 9, 4, 4, 8, 2, 8, 3, 8, 2, 9, 2, 8, 8, 6, 1, 4, 7, 9, 9, 6, 9, 8, 0, 4, 2, 8, 4, 6, 5, 9, 7, 6, 9, 5, 8, 1, 5, 0, 3, 6, 1, 3, 1, 4, 6, 1, 3, 9, 6, 6, 7, 0, 0, 1, 8, 9, 0, 9, 4, 2, 4, 8, 5, 7, 9, 9, 8, 5, 0, 3, 8, 7, 7, 6, 2, 8, 7, 2, 8, 0, 9, 2, 0, 7, 0, 8, 5, 9, 3, 8, 0, 0, 3, 0, 7, 1, 6, 5, 1, 5, 0, 1, 4, 4, 4, 2, 7, 8, 8, 1, 5, 1, 9, 8, 0, 9, 9, 7, 0, 7, 7, 6, 9, 2, 1, 2, 9, 5, 7, 7, 0, 2, 6, 9, 8, 2, 9, 6, 0, 5, 3, 6, 4, 7, 8, 7, 8, 5, 8, 4, 0, 9, 7, 9, 1, 9, 6, 4, 0, 9, 4, 1, 0, 2, 8, 9, 4, 2, 6, 7, 2, 9, 2, 8, 0, 9, 0, 4, 9, 9, 4, 6, 5, 3, 3, 8, 6, 7, 7, 2, 5, 8, 5, 8, 7, 0, 2, 6, 3, 6, 2, 2, 8, 0, 9, 0, 8, 2, 5, 9, 6, 8, 4, 5, 8, 5, 4, 2, 7, 4, 7, 6, 3, 7, 2, 9, 4, 5, 9, 1, 4, 3, 7, 4, 9, 2, 3, 4, 9, 8, 0, 9, 4, 6, 0, 8, 5, 6, 3, 3, 0, 9, 2, 8, 8, 7, 6, 1, 6, 3, 8, 5, 2, 1, 8, 4, 4, 1, 5, 8, 1, 3, 4, 0, 8, 6, 2, 9, 7, 5, 6, 5, 4, 1, 9, 2, 3, 6, 6, 6, 2, 0, 0, 5, 4, 4, 7, 8, 2, 8, 0, 9, 0, 1, 9, 5, 8, 7, 0, 6, 7, 1, 7, 3, 3, 2, 9, 4, 2, 2, 2, 6, 6, 9, 9, 8, 1, 4, 5, 6, 0, 8, 4, 9, 1, 4, 5, 5, 1, 4, 2, 8, 6, 4, 3, 5, 0, 5, 5, 5, 8, 6, 4, 3, 0, 8, 1, 6, 6, 6, 8, 5, 1, 1, 0, 0, 4, 8, 6, 5, 6, 2, 7, 9, 4, 8, 7, 3, 8, 7, 6, 6, 7, 3, 1, 7, 3, 6, 0, 4, 7, 0, 6, 6, 6, 8, 3, 6, 4, 5, 5, 1, 3, 5, 1, 4, 6, 1, 4, 4, 8, 4, 9, 5, 0, 7, 2, 7, 3, 3, 2, 3, 5, 5, 3, 4, 4, 8, 2, 4, 2, 5, 8, 6, 1, 3, 0, 4, 6, 3, 7, 0, 4, 7, 1, 5, 4, 5, 8, 2, 3, 0, 9, 2, 0, 4, 4, 3, 9, 9, 9, 0, 8, 9, 8, 9, 5, 2, 8, 3, 8, 8, 9, 4, 1, 9, 7, 2, 1, 4, 5, 8, 3, 3, 6, 4, 0, 8, 7, 8, 4, 0, 7, 8, 6, 4, 1, 7, 3, 1, 8, 4, 2, 7, 1, 7, 3, 1, 0, 1, 4, 8, 6, 3, 0, 3, 5, 5, 4, 5, 1, 3, 8, 4, 9, 2, 6, 1, 0, 0, 7, 1, 6, 4, 8, 8, 9, 8, 6, 2, 7, 8, 9, 2, 6, 4, 6, 8, 7, 8, 5, 2, 9, 9, 3, 5, 7, 3, 9, 0, 5, 8, 6, 6, 9, 8, 9, 3, 0, 7, 1, 0, 3, 7, 7, 3, 0, 3, 6, 8, 9, 6, 8, 9, 1, 0, 5, 4, 5, 0, 5, 6, 3, 9, 2, 4, 3, 5, 5, 5, 0, 8, 4, 7, 2, 2, 5, 7, 2, 4, 4, 9, 6, 0, 6, 2, 7, 4, 1, 5, 0, 6, 5, 0, 4, 4, 3, 0, 7, 5, 3, 9, 0, 8, 9, 2, 5, 2, 2, 0, 2, 9, 6, 0, 7, 7, 0, 5, 3, 9, 9, 9, 5, 4, 4, 9, 7, 2, 6, 8, 4, 8, 5, 7, 8, 7, 2, 5, 3, 2, 4, 4, 1, 0, 0, 0, 6, 7, 8, 2, 9, 1, 0, 4, 7, 6, 1, 6, 9, 1, 5, 6, 1, 1, 5, 6, 6, 6, 1, 7, 1, 7, 3, 8, 2, 8, 4, 2, 7, 7, 1, 2, 2, 6, 9, 5, 0, 3, 2, 4, 8, 7, 2, 4, 5, 7, 9, 3, 0, 3, 1, 3, 9, 9, 5, 1, 9, 1, 9, 2, 0, 1, 9, 6, 8, 5, 0, 6, 8, 7, 5, 8, 1, 6, 9, 9, 5, 6, 9, 7, 8, 7, 0, 8, 9, 6, 4, 6, 4, 8, 4, 6, 5, 5, 3, 8, 1, 1, 7, 4, 7, 7, 7, 7, 9, 2, 2, 1, 7, 9, 7, 4, 9, 1, 3, 3, 3, 5, 4, 1, 3, 4, 9, 2, 2, 1, 8, 7, 7, 7, 7, 6, 9, 6, 8, 6, 4, 3, 7, 3, 5, 4, 5, 9, 2, 3, 5, 6, 7, 6, 3, 2, 4, 6, 6, 6, 4, 4, 6, 9, 4, 3, 2, 8, 2, 8, 8, 9, 7, 9, 2, 3, 5, 8, 1, 5, 4, 4, 7, 2, 1, 6, 2, 9, 3, 5, 7, 2, 4, 1, 1, 6, 0, 3, 9, 9, 9, 9, 4, 0, 8, 2, 0, 4, 0, 9, 3, 4, 9, 1, 1, 5, 4, 3, 8, 6, 2, 3, 8, 9, 7, 3, 5, 0, 1, 5, 0, 0, 7, 1, 7, 4, 9, 3, 4, 3, 6, 5, 2, 5, 3, 2, 4, 5, 4, 3, 2, 7, 4, 4, 1, 6, 4, 8, 6, 8, 3, 2, 6, 8, 4, 6, 6, 2, 3, 1, 2, 7, 3, 5, 9, 6, 1, 5, 7, 1, 7, 2, 2, 1, 0, 8, 5, 7, 3, 6, 5, 6, 4, 3, 5, 7, 3, 1, 0, 2, 0, 3, 0, 5, 6, 2, 7, 2, 5, 0, 0, 9, 7, 1, 0, 2, 5, 3, 6, 9, 2, 4, 7, 8, 6, 6, 9, 1, 2, 3, 2, 9, 6, 1, 2, 3, 1, 3, 8, 7, 4, 5, 0, 5, 0, 9, 5, 8, 8, 6, 4, 8, 7, 1, 0, 9, 9, 4, 2, 4, 7, 3, 7, 6, 2, 2, 3, 0, 6, 8, 4, 6, 4, 1, 0, 1, 2, 7, 5, 0, 7, 4, 5, 6, 4, 2, 6, 1, 9, 7, 5, 4, 5, 9, 7, 1, 8, 8, 6, 9, 5, 3, 1, 6, 3, 6, 6, 1, 8, 7, 9, 2, 0, 9, 3, 5, 3, 0, 4, 9, 2, 0, 4, 4, 7, 6, 0, 7, 2, 2, 7, 4, 2, 0, 3, 1, 7, 1, 9, 3, 5, 3, 1, 1, 7, 1, 7, 0, 7, 5, 5, 4, 3, 1, 5, 6, 1, 5, 2, 5, 3, 5, 5, 3, 3, 2, 0, 1, 0, 4, 6, 9, 1, 2, 7, 9, 7, 1, 7, 9, 1, 4, 8, 5, 3, 7, 0, 8, 8, 5, 1, 5, 4, 4, 4, 4, 0, 5, 9, 4, 1, 9, 5, 5, 1, 0, 1, 3, 4, 5, 3, 0, 1, 7, 5, 9, 7, 8, 7, 2, 9, 3, 7, 8, 5, 3, 4, 9, 4, 9, 4, 4, 3, 5, 4, 4, 6, 7, 8, 2, 4, 7, 0, 6, 8, 4, 4, 7, 9, 8, 0, 0, 7, 7, 3, 2, 4, 0, 9, 9, 3, 2, 2, 1, 8, 3, 8, 6, 2, 6, 1, 6, 6, 9, 6, 9, 7, 9, 4, 5, 1, 6, 9, 0, 5, 3, 6, 1, 0, 6, 2, 1, 6, 6, 6, 5, 5, 0, 2, 1, 3, 3, 0, 1, 4, 2, 9, 5, 4, 9, 6, 3, 0, 2, 8, 1, 2, 2, 2, 4, 3, 1, 3, 7, 4, 4, 6, 9, 9, 5, 5, 3, 6, 7, 2, 5, 2, 6, 4]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def labels_to_one_hot(labels, num_classes=10):\n",
    "    \"\"\"\n",
    "    Convert a list of numeric labels into one-hot encoded format.\n",
    "\n",
    "    Parameters:\n",
    "    - labels: list or numpy array, the list of labels to be converted.\n",
    "    - num_classes: int, the number of unique classes.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array representing the one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    # Initialize the one-hot encoding array with zeros\n",
    "    one_hot_encoding = np.zeros((len(labels), num_classes))\n",
    "    \n",
    "    # Use numpy indexing to set elements to 1\n",
    "    one_hot_encoding[np.arange(len(labels)), labels] = 1\n",
    "    \n",
    "    return one_hot_encoding\n",
    "\n",
    "# Convert 'label' column from the balanced data to a list\n",
    "labels = data_balanced['label'].tolist()\n",
    "print(labels)\n",
    "# Labels --> one hot\n",
    "one_hot_encoding = labels_to_one_hot(labels)\n",
    "print(one_hot_encoding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(data_array[i,0,:,:])\n",
    "    plt.pause(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize, and pixel entries range from 0 to 255\n",
    "# # First 10 cols are targets (ytrain/ytest) and the rest is input data\n",
    "# X_train = np.transpose(data_train.iloc[:, 11:].values / 255)\n",
    "# y_train = np.transpose(data_train.iloc[:, :10].values)\n",
    "# X_test = np.transpose(data_test.iloc[:, 11:].values / 255)\n",
    "# y_test = np.transpose(data_test.iloc[:, :10].values)\n",
    "# X_train_reshape = np.zeros((X_train.shape[1],1,28,28))\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     temp = X_train[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_train_reshape[i,0,:,:] = temp\n",
    "    \n",
    "# X_train= X_train_reshape  \n",
    "\n",
    "# X_test_reshape = np.zeros((X_test.shape[1],1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-shape the input vectors to 28X28 NumPy arrays\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# for i in range(X_test.shape[1]):\n",
    "#     temp = X_test[:,i]\n",
    "#     temp = np.ravel(temp)\n",
    "#     temp = temp.reshape(28,28)\n",
    "#     X_test_reshape[i,0,:,:] = temp\n",
    "\n",
    "# X_test= X_test_reshape\n",
    "\n",
    "# conv1 = np.random.randn(2,1,5,5) * np.sqrt(1. / 5)\n",
    "\n",
    "# stride = 1\n",
    "# filter_h = conv1.shape[2]\n",
    "# filter_w = conv1.shape[3]\n",
    "# new_channels = conv1.shape[0]\n",
    "# ## Get resultant Width and Height of Image\n",
    "\n",
    "# image_data = X_train\n",
    "# result_h = int(((image_data.shape[2]-filter_h)/stride) + 1)\n",
    "# result_w = int(((image_data.shape[3]-filter_w)/stride) + 1)\n",
    "\n",
    "# ## Out 0 matrix\n",
    "# result_conv1 = np.random.rand(image_data.shape[0],new_channels,result_h,result_w)\n",
    "\n",
    "# # Iterate over each image in the dataset\n",
    "# for image_position in range(image_data.shape[0]):\n",
    "#     image_selected = image_data[image_position,:,:,:]\n",
    "    \n",
    "#     # Each filter in conv layer\n",
    "#     for filter_position in range(conv1.shape[0]):\n",
    "#         filter_selected = conv1[filter_position,:,:,:]\n",
    "        \n",
    "#         # Vertical slide across the image\n",
    "#         for i in range(0, image_selected.shape[1], stride):\n",
    "#             # Vertical slice matching filter height\n",
    "#             image_rectangle = image_selected[:,i:i+filter_h,:]\n",
    "#             # If its height is less than the filter's height skip\n",
    "#             if image_rectangle.shape[1] < filter_h:\n",
    "#                 continue\n",
    "            \n",
    "#             # Horizontal slide across the vertical slice\n",
    "#             for j in range(0, image_rectangle.shape[2], stride):\n",
    "#                 # Slice matching the filter's width\n",
    "#                 image_portion = image_rectangle[:,:,j:j+filter_w]\n",
    "#                 # Skip if width less than the filter's width\n",
    "#                 if image_portion.shape[2] < filter_w:\n",
    "#                     continue\n",
    "                \n",
    "#                 # Apply filter to selected image portion\n",
    "#                 convolution_result = np.multiply(filter_selected, image_portion)\n",
    "#                 # Sum convolution output and store it in the result array\n",
    "#                 result_conv1[image_position, filter_position, i, j] = np.sum(convolution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(X, conv1, stride, pad):\n",
    "    # Pad around images to preserve size after convolution\n",
    "    X_padded = np.pad(X, ((0, 0), (0, 0), (pad, pad), (pad, pad)), mode='constant')\n",
    "    X = X_padded\n",
    "    \n",
    "    # Dims of the output post-filter\n",
    "    new_height = int((X.shape[2] - conv1.shape[2]) / stride) + 1\n",
    "    new_width = int((X.shape[3] - conv1.shape[3]) / stride) + 1\n",
    "    \n",
    "    # Arr for unique transformed matrix\n",
    "    im2col_vector = np.zeros((X.shape[1] * conv1.shape[2] * conv1.shape[3], new_width * new_height * X.shape[0]))\n",
    "    c = 0  # Curr column in the output array\n",
    "    \n",
    "    # Iterate over each image in the batch\n",
    "    for position in range(X.shape[0]):\n",
    "        # Current image\n",
    "        image_position = X[position, :, :, :]\n",
    "        \n",
    "        # Vertical slide down the image, with \"stride\" steps \n",
    "        for height in range(0, image_position.shape[1], stride):\n",
    "            # Select a horizontal slice that matches filter height\n",
    "            image_rectangle = image_position[:, height:height + conv1.shape[2], :]\n",
    "            # Next iteration if slice's height < than filter height\n",
    "            if image_rectangle.shape[1] < conv1.shape[2]:\n",
    "                continue\n",
    "            \n",
    "            # Horizontal slide down the image, with \"stride\" steps \n",
    "            for width in range(0, image_rectangle.shape[2], stride):\n",
    "                # Slice portion that matches the filter width\n",
    "                image_square = image_rectangle[:, :, width:width + conv1.shape[3]]\n",
    "                # If portion's width < filter width\n",
    "                if image_square.shape[2] < conv1.shape[3]:\n",
    "                    continue\n",
    "                \n",
    "                # Flatten and store \n",
    "                im2col_vector[:, c:c + 1] = image_square.reshape(-1, 1)\n",
    "                c += 1\n",
    " \n",
    "    return im2col_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch = data_array[0:10,:,:,:]\n",
    "# conv1 = np.random.randn(2,1,5,5)\n",
    "# print(conv1)\n",
    "# X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "# conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "# X_conv = conv1_reshaped@X_im2col\n",
    "# print(np.hsplit(X_conv,X_batch.shape[0]))\n",
    "# X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "# print(X_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def softmax(x):\n",
    "    x_exp = np.exp(x-np.max(x))\n",
    "    return x_exp/np.sum(x_exp,axis=0)\n",
    "\n",
    "def maxpool_multiple(input_image, stride=2):\n",
    "    # This function applies max pooling to a batch of images with a specified stride.\n",
    "    # Calculate the dimensions of the output image\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    \n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output image array with zeros\n",
    "    output_image = np.zeros((input_image.shape[0], input_image.shape[1], output_height, output_width))\n",
    "    # Apply max pooling to each image in the batch\n",
    "    for i in range(output_image.shape[0]):\n",
    "        output_image[i:i+1, :, :, :] = maxpool(input_image[i:i+1, :, :, :], stride=2)\n",
    "    return output_image\n",
    "\n",
    "def maxpool(input_image, stride=2):\n",
    "    # Apply max pooling to a single image with a specified stride and 2x2 pooling filter.\n",
    "    input_width = input_image.shape[3]\n",
    "    input_height = input_image.shape[2]\n",
    "    filter_width = 2\n",
    "    filter_height = 2\n",
    "    n_channels = input_image.shape[1]\n",
    "    num_images = input_image.shape[0]\n",
    "    \n",
    "    # Output dims\n",
    "    output_width = int((input_width - filter_width) / stride) + 1\n",
    "    output_height = int((input_height - filter_height) / stride) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    output = np.zeros((n_channels, output_width * output_height))\n",
    "    c = 0      \n",
    "    # Iteration over input image height\n",
    "    for height in range(0, input_height, stride):\n",
    "        if height + filter_height <= input_height:\n",
    "            # Vertical slice of the image\n",
    "            image_rectangle = input_image[0, :, height:height + filter_height, :]\n",
    "            # Width of the input image\n",
    "            for width in range(0, input_width, stride):\n",
    "                if width + filter_width <= input_width:\n",
    "                    # Square portion of the image\n",
    "                    image_square = image_rectangle[:, :, width:width + filter_width]\n",
    "                    # Flattened square portion and max pool\n",
    "                    image_flatten = image_square.reshape(-1, 1)\n",
    "                    output[:, c:c + 1] = np.array([float(max(i.ravel())) for i in np.split(image_flatten, n_channels)]).reshape(-1, 1)\n",
    "                    c += 1\n",
    "   \n",
    "    # Reshape output to match the expected\n",
    "    final_output = np.array(np.hsplit(output, 1)).reshape((1, n_channels, output_height, output_width))\n",
    "        \n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dReLU(x):\n",
    "    return (x>0)*1.0\n",
    "\n",
    "def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector = []\n",
    "    for channel in range(input_image.shape[1]):\n",
    "        x = -1 # output height counter\n",
    "\n",
    "        # Curr channel\n",
    "        chosen_image_channel = input_image[:,channel,:,:]\n",
    "        # Through height with stride\n",
    "        for height in range(0,chosen_image_channel.shape[1],stride):\n",
    "            if height+stride<=chosen_image_channel.shape[1]:\n",
    "                # Horizontal slice\n",
    "                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]\n",
    "                x = x+1\n",
    "                y = -1 # output width counter\n",
    "                # Go through slide width with stride\n",
    "                for width in range(0,image_rectangle.shape[2],stride):\n",
    "                    if width+stride<= image_rectangle.shape[2]:\n",
    "                        y = y+1\n",
    "                        # Square portion\n",
    "                        image_square = image_rectangle[:,:,width:width+filter_width]\n",
    "                        # Max val within square \n",
    "                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)\n",
    "                        # Store map and max val\n",
    "                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])\n",
    "    return positional_vector\n",
    "\n",
    "def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):\n",
    "    positional_vector =[]\n",
    "    # Go through each image\n",
    "    for i in range(input_image.shape[0]):\n",
    "        # Add vector of maxpool idx to curr image\n",
    "        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))\n",
    "    return positional_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_layer_reshape(error_layer):\n",
    "    test_array = error_layer\n",
    "    # New arr for reshaped data with flattened dims\n",
    "    # New shape is determined by channels (second dimension) and a flattened version of the remaining dimensions\n",
    "    test_array_new = np.zeros((test_array.shape[1], test_array.shape[0] * test_array.shape[2] * test_array.shape[3]))\n",
    "    \n",
    "    # Go through each channel to reshape and flatten the error data\n",
    "    for i in range(test_array_new.shape[0]):\n",
    "        # Flatten each channel's error data and store it\n",
    "        test_array_new[i:i + 1, :] = test_array[:, i:i + 1, :, :].ravel()\n",
    "        \n",
    "    return test_array_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "# delta_conv = np.random.rand(10,2,24,24)\n",
    "# print(delta_conv)\n",
    "# delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "# print(delta_conv_reshape.shape)\n",
    "# conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "# print(conv1_delta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Train Accuracy\n",
      "93.43 %\n",
      "Test Accuracy\n",
      "92.5 %\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py:764\u001b[0m, in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# handle array case.\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     Nsections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices_or_sections\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    765\u001b[0m     div_points \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(indices_or_sections) \u001b[38;5;241m+\u001b[39m [Ntotal]\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m X_relu \u001b[38;5;241m=\u001b[39m ReLU(X_conv)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m### Pass Through Max Pool\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m X_maxpool \u001b[38;5;241m=\u001b[39m \u001b[43mmaxpool_multiple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_relu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m### Get the indices of maxpool\u001b[39;00m\n\u001b[1;32m     67\u001b[0m max_indices \u001b[38;5;241m=\u001b[39m maxpool_indices_multiple(X_relu,stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,filter_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, filter_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mmaxpool_multiple\u001b[0;34m(input_image, stride)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply max pooling to each image in the batch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(output_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 23\u001b[0m     output_image[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :, :] \u001b[38;5;241m=\u001b[39m \u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_image\n",
      "Cell \u001b[0;32mIn[9], line 54\u001b[0m, in \u001b[0;36mmaxpool\u001b[0;34m(input_image, stride)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[38;5;66;03m# Flattened square portion and max pool\u001b[39;00m\n\u001b[1;32m     53\u001b[0m                 image_flatten \u001b[38;5;241m=\u001b[39m image_square\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m                 output[:, c:c \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mmax\u001b[39m(i\u001b[38;5;241m.\u001b[39mravel())) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_flatten\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_channels\u001b[49m\u001b[43m)\u001b[49m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     55\u001b[0m                 c \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Reshape output to match the expected\u001b[39;00m\n",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py:866\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m%\u001b[39m sections:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    865\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray split does not result in an equal division\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_or_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/NumpyExamples/.venv/lib/python3.10/site-packages/numpy/lib/shape_base.py:775\u001b[0m, in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    771\u001b[0m     Neach_section, extras \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(Ntotal, Nsections)\n\u001b[1;32m    772\u001b[0m     section_sizes \u001b[38;5;241m=\u001b[39m ([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    773\u001b[0m                      extras \u001b[38;5;241m*\u001b[39m [Neach_section\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    774\u001b[0m                      (Nsections\u001b[38;5;241m-\u001b[39mextras) \u001b[38;5;241m*\u001b[39m [Neach_section])\n\u001b[0;32m--> 775\u001b[0m     div_points \u001b[38;5;241m=\u001b[39m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43msection_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcumsum()\n\u001b[1;32m    777\u001b[0m sub_arys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    778\u001b[0m sary \u001b[38;5;241m=\u001b[39m _nx\u001b[38;5;241m.\u001b[39mswapaxes(ary, axis, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "conv1 = np.random.randn(2,1,5,5)*np.sqrt(1./5.)\n",
    "W1 = np.random.rand(60,288)/np.sqrt(288)\n",
    "B0 = np.zeros((60,1))/np.sqrt(288)\n",
    "W2 = np.random.rand(10,60)/np.sqrt(60)\n",
    "B1 = np.zeros((10,1))/np.sqrt(60)\n",
    "learning_rate = 0.001\n",
    "## Implementing Adam Optimizer\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "momentum_w1 = 0\n",
    "momentum_w2 = 0\n",
    "momentum_b0 = 0\n",
    "momentum_b1 = 0\n",
    "momentum_conv1 = 0\n",
    "velocity_w1 = 0\n",
    "velocity_w2 = 0\n",
    "velocity_b0 = 0\n",
    "velocity_b1 = 0\n",
    "velocity_conv1 = 0\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)\n",
    "        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "        final_fc = softmax(W2@fc1+B1)\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))\n",
    "        delta_0 = np.multiply(W1.T@delta_1,1.0)\n",
    "        \n",
    "        dW1 = delta_1@X_maxpool_flatten.T\n",
    "        dW2 = delta_2@fc1.T\n",
    "        dB0 = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        dB1 = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)\n",
    "        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)\n",
    "        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)\n",
    "        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)\n",
    "        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)\n",
    "        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)\n",
    "        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)\n",
    "        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)\n",
    "        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)\n",
    "        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)\n",
    "        \n",
    "        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "        epsilon = 1e-6\n",
    "        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    \n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc = softmax(W2@fc1+B1)\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)\n",
    "    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(W1@X_maxpool_flatten+B0)\n",
    "    final_fc_test = softmax(W2@fc1+B1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', (epoch_num + 1))\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_adam(parameters, grads, velocities, momentums, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Update parameters using Adam optimization algorithm.\n",
    "\n",
    "    parameters - Dictionary containing your parameters:\n",
    "                  parameters['W1'], parameters['B0'], parameters['W2'], parameters['B1'], parameters['Conv1']\n",
    "    grads - Dictionary containing your gradients for each parameters\n",
    "    velocities - Dictionary containing the exponentially weighted average of the squared gradient\n",
    "    momentums - Dictionary containing the exponentially weighted average of the gradient\n",
    "    t - Epoch number\n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2  # Number of layers in the neural network\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Moving average of the gradients.\n",
    "        momentums['dW' + str(l+1)] = beta1 * momentums.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta1) * grads['dW' + str(l+1)]\n",
    "        momentums['dB' + str(l)] = beta1 * momentums.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta1) * grads['dB' + str(l)]\n",
    "\n",
    "        # Compute bias-corrected first moment estimate.\n",
    "        mt_dW = momentums['dW' + str(l+1)] / (1 - np.power(beta1, t))\n",
    "        mt_dB = momentums['dB' + str(l)] / (1 - np.power(beta1, t))\n",
    "\n",
    "        # Moving average of the squared gradients.\n",
    "        velocities['dW' + str(l+1)] = beta2 * velocities.get('dW' + str(l+1), np.zeros_like(grads['dW' + str(l+1)])) + (1 - beta2) * np.square(grads['dW' + str(l+1)])\n",
    "        velocities['dB' + str(l)] = beta2 * velocities.get('dB' + str(l), np.zeros_like(grads['dB' + str(l)])) + (1 - beta2) * np.square(grads['dB' + str(l)])\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate.\n",
    "        vt_dW = velocities['dW' + str(l+1)] / (1 - np.power(beta2, t))\n",
    "        vt_dB = velocities['dB' + str(l)] / (1 - np.power(beta2, t))\n",
    "\n",
    "        # Update parameters.\n",
    "        parameters['W' + str(l+1)] -= learning_rate * mt_dW / (np.sqrt(vt_dW) + epsilon)\n",
    "        parameters['B' + str(l)] -= learning_rate * mt_dB / (np.sqrt(vt_dB) + epsilon)\n",
    "\n",
    "    # Convolution layer update\n",
    "    momentums['conv1'] = beta1 * momentums.get('conv1', np.zeros_like(parameters['conv1'])) + (1 - beta1) * grads['dConv1']\n",
    "    mt_Conv1 = momentums['conv1'] / (1 - np.power(beta1, t))\n",
    "    velocities['conv1'] = beta2 * velocities.get('conv1', np.zeros_like(parameters['conv1'])) + (1 - beta2) * np.square(grads['dConv1'])\n",
    "    vt_Conv1 = velocities['conv1'] / (1 - np.power(beta2, t))\n",
    "    parameters['conv1'] -= learning_rate * mt_Conv1 / (np.sqrt(vt_Conv1) + epsilon)\n",
    "\n",
    "    return parameters, velocities, momentums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_optimizers():\n",
    "    params = {\n",
    "        'conv1': np.random.randn(2, 1, 5, 5) * np.sqrt(1. / 5.),\n",
    "        'W1': np.random.rand(60, 288) / np.sqrt(288),\n",
    "        'B0': np.zeros((60, 1)) / np.sqrt(288),\n",
    "        'W2': np.random.rand(10, 60) / np.sqrt(60),\n",
    "        'B1': np.zeros((10, 1)) / np.sqrt(60)\n",
    "    }\n",
    "    momentums = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    velocities = {key: np.zeros_like(value) for key, value in params.items()}\n",
    "    return params, momentums, velocities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simple Architecture for Recognition\n",
    "\n",
    "1) (1,1,28,28)\n",
    "2) Convolution filter (2,1,5,5)\n",
    "3) (Max Pool 2x2)\n",
    "4) Fc layer (1,288)\n",
    "5) Second FC (1,60)\n",
    "6) Output Layer(1,10)\n",
    "\n",
    "'''\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "batches = int(data_array.shape[0]/batch_size)\n",
    "\n",
    "# Initialize parameters and optimizers\n",
    "params, momentums, velocities = initialize_parameters_and_optimizers()\n",
    "# Define dictionaries for parameters and gradients\n",
    "grads = {'dW1': dW1, 'dB0': dB0, 'dW2': dW2, 'dB1': dB1, 'dConv1': conv1_delta}\n",
    "beta1 = 0.9\n",
    "beta2 = 0.995\n",
    "for epoch_num in range(epochs):\n",
    "    \n",
    "    '''\n",
    "    Choose chunks of data based on batch size  \n",
    "    '''\n",
    "    i = 0\n",
    "    permutation = np.random.permutation(data_array.shape[0])\n",
    "    data_array_train = data_array[permutation,:,:,:]\n",
    "    one_hot_encoding_train = one_hot_encoding[permutation,:]\n",
    "    for i in range(batches):\n",
    "        start = i*batch_size\n",
    "        end = min(start+batch_size,data_array.shape[0]-1)\n",
    "        X_batch = data_array_train[start:end,:,:,:]\n",
    "        y_batch = one_hot_encoding_train[start:end,:].T\n",
    "        ### First Convolutional Layer\n",
    "        #X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)\n",
    "        X_im2col = im2col(X=X_batch, conv1=params['conv1'], stride=1, pad=0)\n",
    "        conv1_reshaped = params['conv1'].reshape(params['conv1'].shape[0], -1)\n",
    "        X_conv = conv1_reshaped@X_im2col\n",
    "        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))\n",
    "        \n",
    "        ### Pass through ReLU\n",
    "        \n",
    "        X_relu = ReLU(X_conv)\n",
    "        \n",
    "        ### Pass Through Max Pool\n",
    "        \n",
    "        X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "        \n",
    "        ### Get the indices of maxpool\n",
    "        \n",
    "        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)\n",
    "        \n",
    "        ### Flatten the maxpool output\n",
    "        input_shape, num_channels, input_width, input_height = X_maxpool.shape\n",
    "        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "        for image in range(input_shape):\n",
    "            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)\n",
    "        \n",
    "        ### Getting into fully connected layers\n",
    "        fc1 = ReLU(params['W1']@X_maxpool_flatten+params['B0'])\n",
    "        final_fc = softmax(params['W2']@fc1+params['B1'])\n",
    "        # print('Sum of Final FC')\n",
    "        # print(np.sum(final_fc))\n",
    "        # print(final_fc)\n",
    "#         break\n",
    "        # print('Loss:')\n",
    "        # print(cross_entropy(y=y_batch,y_hat=final_fc))\n",
    "\n",
    "        ### Calculating Loss Through Backprop\n",
    "        \n",
    "        delta_2 = (final_fc-y_batch)\n",
    "        delta_1 = np.multiply(params['W2'].T@delta_2,dReLU(params['W1']@X_maxpool_flatten+params['B0']))\n",
    "        delta_0 = np.multiply(params['W1'].T@delta_1,1.0)\n",
    "        \n",
    "        grads['dW1'] = delta_1@X_maxpool_flatten.T\n",
    "        grads['dW2'] = delta_2@fc1.T\n",
    "        grads['dB0'] = np.sum(delta_1,axis=1,keepdims=True)\n",
    "        grads['dB1'] = np.sum(delta_2,axis=1,keepdims=True)\n",
    "        # print('Delta 2')\n",
    "        # print(delta_2)\n",
    "        \n",
    "        ### Calculating Error for Last Layer before flattening\n",
    "        \n",
    "        delta_maxpool = delta_0.reshape(X_maxpool.shape)\n",
    "        \n",
    "        ### Calculating Error for previous convolutional layer\n",
    "        \n",
    "        delta_conv = np.zeros(X_conv.shape)\n",
    "        for image in range(len(max_indices)):\n",
    "            indices = max_indices[image]\n",
    "            for p in indices:\n",
    "                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]\n",
    "        delta_conv = np.multiply(delta_conv,dReLU(X_conv))\n",
    "        \n",
    "        ### using Im2col\n",
    "        X_batch_im2col = im2col(X=X_batch,conv1=params['conv1'], stride=1, pad=0)\n",
    "        delta_conv_reshape = error_layer_reshape(delta_conv)\n",
    "        grads['conv1_delta'] = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)\n",
    "        \n",
    "        # Update parameters with Adam optimizer\n",
    "        params, velocities, momentums = update_with_adam(params, grads, velocities, momentums, epoch_num+1, learning_rate, beta1, beta2, epsilon)\n",
    "\n",
    "        # Extract updated parameters        \n",
    "        #conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)\n",
    "        #print('conv1 delta done')\n",
    "        ## Update Weights\n",
    "\n",
    "        # epsilon = 1e-6\n",
    "        # conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+epsilon)\n",
    "        # W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+epsilon)\n",
    "        # W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+epsilon)\n",
    "        # B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+epsilon)\n",
    "        # B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+epsilon)\n",
    "\n",
    "        #print('Back Prop Done!')\n",
    "        #i+=1\n",
    "    X = data_array\n",
    "    y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=params['conv1'],stride=1,pad=0)\n",
    "    conv1_reshaped = params['conv1'].reshape(params['conv1'].shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],params['conv1'].shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(params['W1']@X_maxpool_flatten+params['B0'])\n",
    "    final_fc = softmax(params['W2']@fc1+params['B1'])\n",
    "    \n",
    "    #### Test Data\n",
    "    X = data_test_input\n",
    "    #y = one_hot_encoding.T\n",
    "    X_im2col = im2col(X=X,conv1=params['conv1'],stride=1,pad=0)\n",
    "    conv1_reshaped = params['conv1'].reshape(params['conv1'].shape[0],-1)\n",
    "    X_conv = conv1_reshaped@X_im2col\n",
    "    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],params['conv1'].shape[0],24,24))\n",
    "        \n",
    "        \n",
    "    ### Pass through ReLU\n",
    "        \n",
    "    X_relu = ReLU(X_conv)\n",
    "        \n",
    "    ### Pass Through Max Pool\n",
    "        \n",
    "    X_maxpool = maxpool_multiple(X_relu,stride=2)\n",
    "    input_shape = X_maxpool.shape[0]\n",
    "    num_channels = X_maxpool.shape[1]\n",
    "    input_width = X_maxpool.shape[2]\n",
    "    input_height = X_maxpool.shape[3]\n",
    "    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))\n",
    "    for image in range(input_shape):\n",
    "        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  \n",
    "    ### Getting into fully connected layers\n",
    "    fc1 = ReLU(params['W1']@X_maxpool_flatten+params['B0'])\n",
    "    final_fc = softmax(params['W2']@fc1+params['B1'])\n",
    "    \n",
    "    if epoch_num % 1  == 0:\n",
    "        ### Getting accuracy\n",
    "        print('Epoch :', epoch_num + 1)\n",
    "        labels_predict = np.argmax(final_fc,axis=0)\n",
    "        labels_df  = data_balanced[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Train Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        \n",
    "        ### Test Accuracy\n",
    "        \n",
    "        labels_predict = np.argmax(final_fc_test,axis=0)\n",
    "        labels_df  = data_test[['label']]\n",
    "        labels_predict = labels_predict.tolist()\n",
    "        labels_predict = [int(value) for value in labels_predict]\n",
    "        labels_df.insert(1,'label_predict',labels_predict)\n",
    "        #labels_df.loc[:,'label_predict'] = labels_predict\n",
    "        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]\n",
    "        print('Test Accuracy')\n",
    "        print(round(accuracy*100,2),\"%\")\n",
    "        print('-------------------------')\n",
    "        \n",
    "#       print(cross_entropy(y=y,y_hat=final_fc))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
